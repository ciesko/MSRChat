[
    {
        "id": 1035171,
        "date": "2024-05-22T08:08:11",
        "date_gmt": "2024-05-22T15:08:11",
        "guid": {
            "rendered": ""
        },
        "modified": "2024-05-22T09:01:34",
        "modified_gmt": "2024-05-22T16:01:34",
        "slug": "gigapath-whole-slide-foundation-model-for-digital-pathology",
        "status": "publish",
        "type": "post",
        "link": "https://www.microsoft.com/en-us/research/blog/gigapath-whole-slide-foundation-model-for-digital-pathology/",
        "title": {
            "rendered": "GigaPath: Whole-Slide Foundation Model for Digital Pathology"
        },
        "content": {
            "rendered": "\n<figure class=\"wp-block-image aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1400\" height=\"788\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero.png\" alt=\"Digital pathology helps decode tumor microenvironments for precision immunotherapy. GigaPath is a novel vision transformer that can scale to gigapixel whole-slide images by adapting dilated attention for digital pathology. In joint work with Providence and UW, we’re sharing Prov-GigaPath, the first whole-slide pathology foundation model pretrained on large-scale real-world data, for advancing clinical research and discovery.\" class=\"wp-image-1038840\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero.png 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-1280x720.png 1280w\" sizes=\"(max-width: 1400px) 100vw, 1400px\" /><figcaption class=\"wp-element-caption\"><em>Image: Ella Maru Studio</em></figcaption></figure>\n\n\n\n<p>The confluence of digital transformation in biomedicine and the current generative AI revolution creates an unprecedented opportunity for drastically accelerating progress in precision health. Digital pathology is emblematic of this exciting frontier. In cancer care, whole-slide imaging has become routinely available, which transforms a microscopy slide of tumor tissue into a high-resolution digital image. Such whole-slide images contain key information for deciphering the tumor microenvironment, which is critical for precision immunotherapy (for example differentiating hot versus cold tumors based on lymphocyte infiltration). Digital pathology can also be combined with other multimodal, longitudinal patient information in multimodal generative AI for scaling population-level, real-world evidence generation.&nbsp;</p>\n\n\n\n<p>This is an exciting time, tempered by the reality that digital pathology poses unique computational challenges, as a standard gigapixel slide may be thousands of times larger than typical natural images in both width and length. Conventional vision transformers struggle with such an enormous size as computation for self-attention grows dramatically with the input length. Consequently, prior work in digital pathology often ignores the intricate interdependencies across image tiles in each slide, thus missing important slide-level context for key applications such as modeling the tumor microenvironment.&nbsp;</p>\n\n\n\n<p>In this blog post, we introduce <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://www.nature.com/articles/s41586-024-07441-w\">GigaPath<span class=\"sr-only\"> (opens in new tab)</span></a>, a novel vision transformer that attains whole-slide modeling by leveraging dilated self-attention to keep computation tractable. In joint work with Providence Health System and the University of Washington, we have developed <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"http://aka.ms/prov-gigapath\" target=\"_blank\" rel=\"noreferrer noopener\">Prov-GigaPath<span class=\"sr-only\"> (opens in new tab)</span></a>, an open-access whole-slide pathology foundation model pretrained on more than one billion 256 X 256 pathology images tiles in more than 170,000 whole slides from real-world data at Providence.  All computation was conducted within Providence’s private tenant, approved by Providence Institutional Review Board (IRB).  </p>\n\n\n\n<p>To our knowledge, this is the first whole-slide foundation model for digital pathology with large-scale pretraining on real-world data. Prov-GigaPath attains state-of-the-art performance on standard cancer classification and pathomics tasks, as well as vision-language tasks. This demonstrates the importance of whole-slide modeling on large-scale real-world data and opens new possibilities to advance patient care and accelerate clinical discovery.</p>\n\n\n\n\t<div class=\"border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide\" data-bi-aN=\"promo\" data-bi-id=\"1002645\">\n\t\t\n\n\t\t<p class=\"msr-promo__label text-gray-800 text-center text-uppercase\">\n\t\t<span class=\"px-4 bg-white display-inline-block font-weight-semibold small\">Spotlight: AI-POWERED EXPERIENCE</span>\n\t</p>\n\t\n\t<div class=\"row pt-3 pb-4 align-items-center\">\n\t\t\t\t\t\t<div class=\"msr-promo__media col-12 col-md-5\">\n\t\t\t\t<a class=\"bg-gray-300\" href=\"https://aka.ms/research-copilot/?OCID=msr_researchforum_Copilot_MCR_Blog_Promo\" aria-label=\"Microsoft research copilot experience\" data-bi-cN=\"Microsoft research copilot experience\" target=\"_blank\">\n\t\t\t\t\t<img decoding=\"async\" class=\"w-100 display-block\" src=\"https://www.microsoft.com/en-us/research/uploads/prod/2024/01/MSR-Chat-Promo.png\" alt=\"\" />\n\t\t\t\t</a>\n\t\t\t</div>\n\t\t\t\n\t\t\t<div class=\"msr-promo__content p-3 px-5 col-12 col-md\">\n\n\t\t\t\t\t\t\t\t\t<h2 class=\"h4\">Microsoft research copilot experience</h2>\n\t\t\t\t\n\t\t\t\t\t\t\t\t<p class=\"large\">Discover more about research at Microsoft through our AI-powered experience</p>\n\t\t\t\t\n\t\t\t\t\t\t\t\t<div class=\"wp-block-buttons justify-content-center justify-content-md-start\">\n\t\t\t\t\t<div class=\"wp-block-button\">\n\t\t\t\t\t\t<a href=\"https://aka.ms/research-copilot/?OCID=msr_researchforum_Copilot_MCR_Blog_Promo\" class=\"btn btn-brand glyph-append glyph-append-chevron-right\" aria-label=\"Microsoft research copilot experience\" data-bi-cN=\"Microsoft research copilot experience\" target=\"_blank\">\n\t\t\t\t\t\t\tStart now\t\t\t\t\t\t</a>\n\t\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t\t\t\t</div><!--/.msr-promo__content-->\n\t</div><!--/.msr-promo__inner-wrap-->\n<span id=\"label-external-link\" class=\"sr-only\" aria-hidden=\"true\">Opens in a new tab</span>\t</div><!--/.msr-promo-->\n\t\n\n\n<h2 class=\"wp-block-heading\" id=\"adapting-dilated-attention-and-longnet-to-digital-pathology\">Adapting dilated attention and LongNet to digital pathology</h2>\n\n\n\n<figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1532\" height=\"1404\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-1-color-adjust.jpg\" alt=\"Figure 1: Overview of GigaPath. a, Flow chart showing the model architecture of Prov-GigaPath. Prov-GigaPath first serializes each input WSI into a sequence of 256 × 256 image tiles in row-major order and uses an image tile-level encoder to convert each image tile into a visual embedding. Then Prov-GigaPath applies a slide-level encoder based on the LongNet architecture to generate contextualized embeddings, which can serve as the basis for various downstream applications. b, Image tile-level pretraining using DINOv2. c, Slide-level pretraining with LongNet using masked autoencoder.\" class=\"wp-image-1038756\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-1-color-adjust.jpg 1532w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-1-color-adjust-300x275.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-1-color-adjust-1024x938.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-1-color-adjust-768x704.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-1-color-adjust-196x180.jpg 196w\" sizes=\"(max-width: 1532px) 100vw, 1532px\" /><figcaption class=\"wp-element-caption\">Figure 1: Overview of GigaPath. a, Flow chart showing the model architecture of Prov-GigaPath. Prov-GigaPath first serializes each input WSI into a sequence of 256 × 256 image tiles in row-major order and uses an image tile-level encoder to convert each image tile into a visual embedding. Then Prov-GigaPath applies a slide-level encoder based on the LongNet architecture to generate contextualized embeddings, which can serve as the basis for various downstream applications. b, Image tile-level pretraining using DINOv2. c, Slide-level pretraining with LongNet using masked autoencoder.</figcaption></figure>\n\n\n\n<p>GigaPath adopts two-stage curriculum learning comprising tile-level pretraining using DINOv2 and slide-level pretraining using masked autoencoder with <a href=\"https://www.microsoft.com/en-us/research/publication/longnet-scaling-transformers-to-1000000000-tokens/\" target=\"_blank\" rel=\"noreferrer noopener\">LongNet</a> (see Figure 1). DINOv2 is a standard self-supervision method that combines contrastive loss and masked reconstruction loss in training teacher and student vision transformers. However, due to the computational challenge for self-attention, its application is limited to small images such as 256 × 256 tiles. For slide-level modeling, we adapt dilated attention from <a href=\"https://www.microsoft.com/en-us/research/publication/longnet-scaling-transformers-to-1000000000-tokens/\" target=\"_blank\" rel=\"noreferrer noopener\">LongNet</a> to digital pathology (see Figure 2). To handle the long sequence of image tiles for a whole slide, we introduce a series of increasing sizes for subdividing the tile sequence into segments of the given size. For larger segments, we introduce sparse attention with sparsity proportional to segment length, thus canceling out the quadratic growth. The largest segment would cover the entire slide, though with sparsely subsampled self-attention. This enables us to capture long-range dependencies in a systematic way while maintaining tractability in computation (linear in context length).</p>\n\n\n\n<figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"2042\" height=\"1786\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-2-color-adjust.jpg\" alt=\"Figure 2: Illustration of dilated attention. Dilated attention introduces a series of increasing sizes for subdividing the tile sequence into segments of the given size. For larger segments, we introduce sparse attention with sparsity proportional to segment length, thus canceling out the quadratic growth. This enables us to capture long-range dependencies in a systematic way while maintaining tractability in computation (linear in context length). \" class=\"wp-image-1038762\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-2-color-adjust.jpg 2042w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-2-color-adjust-300x262.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-2-color-adjust-1024x896.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-2-color-adjust-768x672.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-2-color-adjust-1536x1343.jpg 1536w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-2-color-adjust-206x180.jpg 206w\" sizes=\"(max-width: 2042px) 100vw, 2042px\" /><figcaption class=\"wp-element-caption\">Figure 2: Illustration of dilated attention. Dilated attention introduces a series of increasing sizes for subdividing the tile sequence into segments of the given size. For larger segments, we introduce sparse attention with sparsity proportional to segment length, thus canceling out the quadratic growth. This enables us to capture long-range dependencies in a systematic way while maintaining tractability in computation (linear in context length).</figcaption></figure>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"gigapath-on-cancer-classification-and-pathomics-tasks\">GigaPath on cancer classification and pathomics tasks</h2>\n\n\n\n<p>We construct a digital pathology benchmark comprising nine cancer subtyping tasks and 17 pathomics tasks, using both Providence and TCGA data. With large-scale pretraining and whole-slide modeling, Prov-GigaPath attains state-of-the-art performance on 25 out of 26 tasks, with significant improvement over the second-best model on 18 tasks.</p>\n\n\n\n<figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1532\" height=\"1149\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-3-color-adjust.jpg\" alt=\"Figure 3: Comparison on cancer subtyping. Bar plots comparing cancer subtyping performance in terms of AUROC (a,c,e) and balanced accuracy (b,d,f) on nine cancer types. Data are mean ± s.e.m. across n = 10 independent experiments. The listed P value indicates the significance for Prov-GigaPath outperforming the best comparison approach, with one-sided Wilcoxon test. BACC, balanced accuracy. BRCA, breast invasive carcinoma; CNS, central nervous system; COADREAD, colorectal adenocarcinoma; DIFG, diffuse intrinsic pontine glioma; EGC, early gastric cancer; HB, hepatobiliary; NSCLC, non-small cell lung cancer; OVT, ovarian tumor; RCC, renal cell cancer. \" class=\"wp-image-1038771\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-3-color-adjust.jpg 1532w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-3-color-adjust-300x225.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-3-color-adjust-1024x768.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-3-color-adjust-768x576.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-3-color-adjust-80x60.jpg 80w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-3-color-adjust-240x180.jpg 240w\" sizes=\"(max-width: 1532px) 100vw, 1532px\" /><figcaption class=\"wp-element-caption\">Figure 3: Comparison on cancer subtyping. Bar plots comparing cancer subtyping performance in terms of AUROC (a,c,e) and balanced accuracy (b,d,f) on nine cancer types. Data are mean ± s.e.m. across n = 10 independent experiments. The listed P value indicates the significance for Prov-GigaPath outperforming the best comparison approach, with one-sided Wilcoxon test. BACC, balanced accuracy. BRCA, breast invasive carcinoma; CNS, central nervous system; COADREAD, colorectal adenocarcinoma; DIFG, diffuse intrinsic pontine glioma; EGC, early gastric cancer; HB, hepatobiliary; NSCLC, non-small cell lung cancer; OVT, ovarian tumor; RCC, renal cell cancer.&nbsp;</figcaption></figure>\n\n\n\n<p>On cancer subtyping, the goal is to classify fine-grained subtypes based on the pathology slide. For example, for ovarian cancer, the model needs to differentiate among six subtypes: Clear Cell Ovarian Cancer, Endometrioid Ovarian Cancer, High-Grade Serous Ovarian Cancer, Low-Grade Serous Ovarian Cancer, Mucinous Ovarian Cancer, and Ovarian Carcinosarcoma. Prov-GigaPath attained state-of-the-art performance in all nine tasks, with significant improvement over the second best in six out of nine tasks (see Figure 3). For six cancer types (breast, kidney, liver, brain, ovarian, central nervous system), Prov-GigaPath attains an AUROC of 90% or higher. This bodes well for downstream applications in precision health such as cancer diagnostics and prognostics.&nbsp;</p>\n\n\n\n<figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1532\" height=\"1616\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-4-color-adjust.jpg\" alt=\"Figure 4: Comparison on gene mutation prediction. a−j, Bar plots comparing the AUROC and AUPRC scores of Prov-GigaPath and competing methods on pan-cancer 18-biomarker (a,f), LUAD-specific 5-gene mutation prediction (b,g), pan-cancer 5-gene mutation prediction (c,h), LUAD-specific 5-gene mutation prediction on TCGA (d,i) and pan-cancer TMB prediction (e,j). k, Bar plot showing AUROC for each gene on LUAD-specific five-gene mutation prediction on TCGA. a−k, Data are mean ± s.e.m. across n = 10 independent experiments. The listed P value indicates the significance for Prov-GigaPath outperforming the best comparison approach, with one-sided Wilcoxon test. l, Comparison of AUROC scores for individual biomarkers in pan-cancer 18-biomarker predictions. \" class=\"wp-image-1038780\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-4-color-adjust.jpg 1532w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-4-color-adjust-284x300.jpg 284w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-4-color-adjust-971x1024.jpg 971w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-4-color-adjust-768x810.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-4-color-adjust-1456x1536.jpg 1456w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-4-color-adjust-171x180.jpg 171w\" sizes=\"(max-width: 1532px) 100vw, 1532px\" /><figcaption class=\"wp-element-caption\">Figure 4: Comparison on gene mutation prediction. a−j, Bar plots comparing the AUROC and AUPRC scores of Prov-GigaPath and competing methods on pan-cancer 18-biomarker (a,f), LUAD-specific 5-gene mutation prediction (b,g), pan-cancer 5-gene mutation prediction (c,h), LUAD-specific 5-gene mutation prediction on TCGA (d,i) and pan-cancer TMB prediction (e,j). k, Bar plot showing AUROC for each gene on LUAD-specific five-gene mutation prediction on TCGA. a−k, Data are mean ± s.e.m. across n = 10 independent experiments. The listed P value indicates the significance for Prov-GigaPath outperforming the best comparison approach, with one-sided Wilcoxon test. l, Comparison of AUROC scores for individual biomarkers in pan-cancer 18-biomarker predictions.</figcaption></figure>\n\n\n\n<p>On pathomics tasks, the goal is to classify whether the tumor exhibits specific clinically relevant genetic mutations based on the slide image alone. This may uncover meaningful connections between tissue morphology and genetic pathways that are too subtle to be picked up by human observation. Aside from a few well-known pairs of specific cancer type and gene mutations, it is unclear how much signal there exists from the slide alone. Moreover, in some experiments, we consider the pan-cancer scenario, where we are trying to identify universal signals for a gene mutation across all cancer types and very diverse tumor morphologies. In such challenging scenarios, Prov-GigaPath once again attained state-of-the-art performance in 17 out of 18 tasks, significantly outperforming the second best in 12 out of 18 tasks (see Figure 4). For example, in the pan-cancer 5-gene analysis, Prov-GigaPath outperformed the best competing methods by 6.5% in AUROC and 18.7% in AUPRC. We also conducted head-to-head comparison on TCGA data to assess the generalizability of Prov-GigaPath and found that Prov-GigaPath similarly outperformed all competing methods there. This is all the more remarkable given that the competing methods were all pretrained on TCGA. That Prov-Gigapath can extract genetically linked pan-cancer and subtype-specific morphological features at the whole-slide level highlights the biological relevance of the underlying learned embeddings, and opens the door to using real-world data for future research directions around the complex biology of the tumor microenvironment.&nbsp;</p>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"gigapath-on-vision-language-tasks\">GigaPath on vision-language tasks</h2>\n\n\n\n<figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1532\" height=\"1447\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-5-color-adjust.jpg\" alt=\"Figure 5: Comparison on vision-language tasks. a, Flow chart showing the fine-tuning of Prov-GigaPath using pathology reports. Real-world pathology reports are processed using GPT-3.5 from OpenAI to remove information irrelevant to cancer diagnosis. We performed the CLIP-based contrastive learning to align Prov-GigaPath and PubMedBERT. b, The fine-tuned Prov[1]GigaPath can then be used to perform zero-shot cancer subtyping and mutation prediction. The input of Prov-GigaPath is a sequence of tiles segmented from a WSI, and the inputs of the text encoder PubMedBERT are manually designed prompts representing cancer types and mutations. Based on the output of Prov-GigaPath and PubMedBERT, we can calculate the probability of the input WSI being classified into specific cancer subtypes and mutations. c, Bar plots comparing zero-shot subtyping performance on NSCLC and COADREAD in terms of BACC, precision and f 1. d, Bar plots comparing the performance on mutation prediction using the fine-tuned model for six genes. c,d, Data are mean ± s.e.m. across n = 50 experiments. The listed P value indicates the significance for Prov-GigaPath outperforming the best comparison approach, with one-sided Wilcoxon test. e, Scatter plots comparing the performance between Prov-GigaPath and MI-Zero in terms of BACC on zero-shot cancer subtyping. Each dot indicates one trial with a particular set of text query formulations. \" class=\"wp-image-1038786\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-5-color-adjust.jpg 1532w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-5-color-adjust-300x283.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-5-color-adjust-1024x967.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-5-color-adjust-768x725.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure-5-color-adjust-191x180.jpg 191w\" sizes=\"(max-width: 1532px) 100vw, 1532px\" /><figcaption class=\"wp-element-caption\">Figure 5: Comparison on vision-language tasks. a, Flow chart showing the fine-tuning of Prov-GigaPath using pathology reports. Real-world pathology reports are processed using GPT-3.5 from OpenAI to remove information irrelevant to cancer diagnosis. We performed the CLIP-based contrastive learning to align Prov-GigaPath and PubMedBERT. b, The fine-tuned Prov-GigaPath can then be used to perform zero-shot cancer subtyping and mutation prediction. The input of Prov-GigaPath is a sequence of tiles segmented from a WSI, and the inputs of the text encoder PubMedBERT are manually designed prompts representing cancer types and mutations. Based on the output of Prov-GigaPath and PubMedBERT, we can calculate the probability of the input WSI being classified into specific cancer subtypes and mutations. c, Bar plots comparing zero-shot subtyping performance on NSCLC and COADREAD in terms of BACC, precision and f 1. d, Bar plots comparing the performance on mutation prediction using the fine-tuned model for six genes. c,d, Data are mean ± s.e.m. across n = 50 experiments. The listed P value indicates the significance for Prov-GigaPath outperforming the best comparison approach, with one-sided Wilcoxon test. e, Scatter plots comparing the performance between Prov-GigaPath and MI-Zero in terms of BACC on zero-shot cancer subtyping. Each dot indicates one trial with a particular set of text query formulations.</figcaption></figure>\n\n\n\n<p>We further demonstrate the potential of GigaPath on vision-language tasks by incorporating the pathology reports. Prior work on pathology vision-language pretraining tends to focus on small images at the tile level. We instead explore slide-level vision-language pretraining. By continuing pretraining on slide-report pairs, we can leverage the report semantics to align the pathology slide representation, which can be used for downstream prediction tasks without supervised fine-tuning (e.g., zero-shot subtyping). Specifically, we use Prov-GigaPath as the whole-slide image encoder and PubMedBERT as the text encoder, and conduct contrastive learning using the slide-report pairs. This is considerably more challenging than traditional vision-language pretraining, as we do not have fine-grained alignment information between individual image tiles and text snippets. Prov-GigaPath substantially outperforms three state-of-the-art pathology vision-language models in standard vision-language tasks, such as zero-shot cancer subtyping and gene mutation prediction, demonstrating the potential for Prov-GigaPath in whole-slide vision-language modeling (see Figure 5).</p>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"gigapath-is-a-promising-step-toward-multimodal-generative-ai-for-precision-health\">GigaPath is a promising step toward multimodal generative AI for precision health</h2>\n\n\n\n<p>We have conducted thorough ablation studies to establish the best practices in whole-slide pretraining and vision-language modeling. We also observed early indications of the scaling law in digital pathology, where larger-scale pretraining generally improved downstream performance, although our experiments were still limited due to computational constraints.</p>\n\n\n\n<p>Going forward, there are many opportunities for progress. Prov-GigaPath attained state-of-the-art performance compared to prior best models, but there is still significant growth space in many downstream tasks. While we have conducted initial exploration on pathology vision-language pretraining, there is still a long way to go to pursue the potential of a multimodal conversational assistant, specifically by incorporating advanced multimodal frameworks such as <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://aka.ms/llava-med\" target=\"_blank\" rel=\"noreferrer noopener\">LLaVA-Med<span class=\"sr-only\"> (opens in new tab)</span></a>. Most importantly, we have yet to explore the impact of GigaPath and whole-slide pretraining in many key precision health tasks such as modeling tumor microenvironment and predicting treatment response.</p>\n\n\n\n<p>GigaPath is joint work with Providence Health System and the University of Washington&#8217;s Paul G. Allen School of Computer Science & Engineering, and brings collaboration from multiple teams within Microsoft*. It reflects Microsoft’s larger commitment on advancing multimodal generative AI for precision health, with exciting progress in other digital pathology research collaborations such as <a href=\"https://www.microsoft.com/en-us/research/blog/scaling-early-detection-of-esophageal-cancer-with-ai/\" target=\"_blank\" rel=\"noreferrer noopener\">Cyted<span class=\"sr-only\"> (opens in new tab)</span></a>, <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://www.businesswire.com/news/home/20240326651392/en/Volastra-Therapeutics-Announces-New-and-Expanded-Partnerships-with-AI-and-Precision-Medicine-Leaders-to-Broaden-Potential-of-KIF18A-Inhibitors-Across-Cancer\" target=\"_blank\" rel=\"noreferrer noopener\">Volastra<span class=\"sr-only\"> (opens in new tab)</span></a>, and <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://paige.ai/paige-announces-collaboration-with-microsoft-to-build-the-worlds-largest-image-based-ai-model-to-fight-cancer/\" target=\"_blank\" rel=\"noreferrer noopener\">Paige<span class=\"sr-only\"> (opens in new tab)</span></a> as well as other technical advances such as <a href=\"https://www.microsoft.com/en-us/research/publication/large-scale-domain-specific-pretraining-for-biomedical-vision-language-processing/\" target=\"_blank\" rel=\"noreferrer noopener\">BiomedCLIP<span class=\"sr-only\"> (opens in new tab)</span></a>, <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://arxiv.org/abs/2403.08002\" target=\"_blank\" rel=\"noreferrer noopener\">LLaVA-Rad<span class=\"sr-only\"> (opens in new tab)</span></a>, <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://arxiv.org/abs/2310.10765\" target=\"_blank\" rel=\"noreferrer noopener\">BiomedJourney<span class=\"sr-only\"> (opens in new tab)</span></a>, <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://aka.ms/biomedparse-paper\" target=\"_blank\" rel=\"noreferrer noopener\">BiomedParse<span class=\"sr-only\"> (opens in new tab)</span></a>, <a href=\"https://www.microsoft.com/en-us/research/project/project-maira/\" target=\"_blank\" rel=\"noreferrer noopener\">MAIRA<span class=\"sr-only\"> (opens in new tab)</span></a>, <a href=\"https://www.microsoft.com/en-us/research/publication/rad-dino-exploring-scalable-medical-image-encoders-beyond-text-supervision/\" target=\"_blank\" rel=\"noreferrer noopener\">Rad-DINO<span class=\"sr-only\"> (opens in new tab)</span></a>, <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://arxiv.org/pdf/2309.07778v5\" target=\"_blank\" rel=\"noreferrer noopener\">Virchow<span class=\"sr-only\"> (opens in new tab)</span></a>.&nbsp;</p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n\n\n\n<p>(Acknowledgment footnote) *: Within Microsoft, it is a wonderful collaboration among Health Futures, MSRA, MSR Deep Learning, and Nuance.<br><br>Paper co-authors: Hanwen Xu, Naoto Usuyama, Jaspreet Bagga, Sheng Zhang, Rajesh Rao, Tristan Naumann, Cliff Wong, Zelalem Gero, Javier Gonz ́alez, Yu Gu, Yanbo Xu, Mu Wei, Wenhui Wang, Shuming Ma, Furu Wei, Jianwei Yang, Chunyuan Li, Jianfeng Gao, Jaylen Rosemon, Tucker Bower, Soohee Lee, Roshanthi Weerasinghe, Bill J. Wright, Ari Robicsek, Brian Piening, Carlo Bifulco, Sheng Wang, Hoifung Poon.&nbsp;</p>\n<span id=\"label-external-link\" class=\"sr-only\" aria-hidden=\"true\">Opens in a new tab</span>",
            "protected": false
        },
        "excerpt": {
            "rendered": "<p>Digital pathology helps decode tumor microenvironments for precision immunotherapy. In joint work with Providence and UW, we’re sharing Prov-GigaPath, the first whole-slide pathology foundation model, for advancing clinical research.</p>\n",
            "protected": false
        },
        "author": 42735,
        "featured_media": 1038840,
        "comment_status": "closed",
        "ping_status": "closed",
        "sticky": false,
        "template": "",
        "format": "standard",
        "meta": {
            "msr-url-field": "",
            "msr-podcast-episode": "",
            "msrModifiedDate": "",
            "msrModifiedDateEnabled": false,
            "ep_exclude_from_search": false,
            "footnotes": ""
        },
        "categories": [
            1
        ],
        "tags": [],
        "research-area": [
            13553
        ],
        "msr-region": [],
        "msr-event-type": [],
        "msr-post-option": [
            243984
        ],
        "msr-impact-theme": [],
        "msr-promo-type": [],
        "msr-podcast-series": [],
        "msr_event_details": {
            "start": "",
            "end": "",
            "location": ""
        },
        "podcast_url": "",
        "podcast_episode": "",
        "msr_research_lab": [
            849856
        ],
        "msr_impact_theme": [],
        "related-publications": [],
        "related-downloads": [],
        "related-videos": [],
        "related-academic-programs": [],
        "related-groups": [],
        "related-projects": [],
        "related-events": [
            999411
        ],
        "related-researchers": [
            {
                "type": "user_nicename",
                "value": "Hoifung Poon",
                "user_id": 32016,
                "display_name": "Hoifung Poon",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/hoifung/\" aria-label=\"Visit the profile page for Hoifung Poon\">Hoifung Poon</a>",
                "is_active": false,
                "last_first": "Poon, Hoifung",
                "people_section": 0,
                "alias": "hoifung"
            },
            {
                "type": "user_nicename",
                "value": "Naoto Usuyama",
                "user_id": 38670,
                "display_name": "Naoto Usuyama",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/naotous/\" aria-label=\"Visit the profile page for Naoto Usuyama\">Naoto Usuyama</a>",
                "is_active": false,
                "last_first": "Usuyama, Naoto",
                "people_section": 0,
                "alias": "naotous"
            }
        ],
        "msr_type": "Post",
        "featured_image_thumbnail": "<img width=\"960\" height=\"540\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-960x540.png\" class=\"img-object-cover\" alt=\"Digital pathology helps decode tumor microenvironments for precision immunotherapy. GigaPath is a novel vision transformer that can scale to gigapixel whole-slide images by adapting dilated attention for digital pathology. In joint work with Providence and UW, we’re sharing Prov-GigaPath, the first whole-slide pathology foundation model pretrained on large-scale real-world data, for advancing clinical research and discovery.\" decoding=\"async\" loading=\"lazy\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero-1280x720.png 1280w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/1-hero.png 1400w\" sizes=\"(max-width: 960px) 100vw, 960px\" />",
        "byline": "<a href=\"https://www.microsoft.com/en-us/research/people/hoifung/\" title=\"Go to researcher profile for Hoifung Poon\" aria-label=\"Go to researcher profile for Hoifung Poon\" data-bi-type=\"byline author\" data-bi-cN=\"Hoifung Poon\">Hoifung Poon</a> and <a href=\"https://www.microsoft.com/en-us/research/people/naotous/\" title=\"Go to researcher profile for Naoto Usuyama\" aria-label=\"Go to researcher profile for Naoto Usuyama\" data-bi-type=\"byline author\" data-bi-cN=\"Naoto Usuyama\">Naoto Usuyama</a>",
        "formattedDate": "May 22, 2024",
        "formattedExcerpt": "Digital pathology helps decode tumor microenvironments for precision immunotherapy. In joint work with Providence and UW, we’re sharing Prov-GigaPath, the first whole-slide pathology foundation model, for advancing clinical research.",
        "_links": {
            "self": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1035171"
                }
            ],
            "collection": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts"
                }
            ],
            "about": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/types/post"
                }
            ],
            "author": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/users/42735"
                }
            ],
            "replies": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/comments?post=1035171"
                }
            ],
            "version-history": [
                {
                    "count": 30,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1035171/revisions"
                }
            ],
            "predecessor-version": [
                {
                    "id": 1039170,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1035171/revisions/1039170"
                }
            ],
            "wp:featuredmedia": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/media/1038840"
                }
            ],
            "wp:attachment": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/media?parent=1035171"
                }
            ],
            "wp:term": [
                {
                    "taxonomy": "category",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/categories?post=1035171"
                },
                {
                    "taxonomy": "post_tag",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/tags?post=1035171"
                },
                {
                    "taxonomy": "msr-research-area",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/research-area?post=1035171"
                },
                {
                    "taxonomy": "msr-region",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-region?post=1035171"
                },
                {
                    "taxonomy": "msr-event-type",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-event-type?post=1035171"
                },
                {
                    "taxonomy": "msr-post-option",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-post-option?post=1035171"
                },
                {
                    "taxonomy": "msr-impact-theme",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-impact-theme?post=1035171"
                },
                {
                    "taxonomy": "msr-promo-type",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-promo-type?post=1035171"
                },
                {
                    "taxonomy": "msr-podcast-series",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-podcast-series?post=1035171"
                }
            ],
            "curies": [
                {
                    "name": "wp",
                    "href": "https://api.w.org/{rel}",
                    "templated": true
                }
            ]
        }
    },
    {
        "id": 1034046,
        "date": "2024-05-20T13:15:09",
        "date_gmt": "2024-05-20T20:15:09",
        "guid": {
            "rendered": ""
        },
        "modified": "2024-05-20T13:15:11",
        "modified_gmt": "2024-05-20T20:15:11",
        "slug": "abstracts-may-20-2024",
        "status": "publish",
        "type": "post",
        "link": "https://www.microsoft.com/en-us/research/podcast/abstracts-may-20-2024/",
        "title": {
            "rendered": "Abstracts: May 20, 2024"
        },
        "content": {
            "rendered": "\n<figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"576\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Episode-12_Abstracts_Hero_Feature_No_Text_1400x788-1024x576.png\" alt=\"Microsoft Research Podcast - Abstracts | May 20, 2024 | Andrey Kolobov\" class=\"wp-image-1038528\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Episode-12_Abstracts_Hero_Feature_No_Text_1400x788-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Episode-12_Abstracts_Hero_Feature_No_Text_1400x788-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Episode-12_Abstracts_Hero_Feature_No_Text_1400x788-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Episode-12_Abstracts_Hero_Feature_No_Text_1400x788-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Episode-12_Abstracts_Hero_Feature_No_Text_1400x788-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Episode-12_Abstracts_Hero_Feature_No_Text_1400x788-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Episode-12_Abstracts_Hero_Feature_No_Text_1400x788-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Episode-12_Abstracts_Hero_Feature_No_Text_1400x788-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Episode-12_Abstracts_Hero_Feature_No_Text_1400x788-1280x720.png 1280w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Episode-12_Abstracts_Hero_Feature_No_Text_1400x788.png 1400w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /></figure>\n\n\n<div class=\"wp-block-msr-podcast-container\">\n\t<iframe loading=\"lazy\" src=\"https://player.blubrry.com/?podcast_id=132574534&modern=1\" class=\"podcast-player\" frameborder=\"0\" height=\"164px\" width=\"100%\" scrolling=\"no\" title=\"Podcast Player\"></iframe>\n</div>\n\n\n\n<p>Members of the research community at Microsoft work continuously to advance their respective fields. <em>Abstracts</em> brings its audience to the cutting edge with them through short, compelling conversations about new and noteworthy achievements.&nbsp;</p>\n\n\n\n<p>In this episode, Principal Research Manager&nbsp;<a href=\"https://www.microsoft.com/en-us/research/people/akolobov/\" target=\"_blank\" rel=\"noreferrer noopener\">Andrey Kolobov</a> joins host Gretchen Huizinga to discuss “<a href=\"https://www.microsoft.com/en-us/research/publication/windseer-real-time-volumetric-wind-prediction-over-complex-terrain-aboard-a-small-uav/\" target=\"_blank\" rel=\"noreferrer noopener\">WindSeer: Real-time volumetric wind prediction over complex terrain aboard a small uncrewed aerial vehicle</a>,” or <em>sUAV</em>.&nbsp;sUAVs can fly farther and more safely if they can reason about the terrain-affected wind in their vicinity. Traditional wind predictions ignore small-terrain features and work at the scale of hours and miles, far too coarsely for sUAVs. WindSeer can estimate the terrain-dependent wind field around an sUAV in flight, with limited onboard compute and measurement data, paving the way for safer and more energy-efficient autonomous drone operation.</p>\n\n\n\n<div class=\"wp-block-buttons is-layout-flex wp-block-buttons-is-layout-flex\">\n<div class=\"wp-block-button\"><a data-bi-type=\"button\" class=\"wp-block-button__link wp-element-button\" href=\"https://www.microsoft.com/en-us/research/publication/windseer-real-time-volumetric-wind-prediction-over-complex-terrain-aboard-a-small-uav/\">Read the paper</a></div>\n\n\n\n<div class=\"wp-block-button is-style-fill-github\"><a data-bi-type=\"button\" class=\"wp-block-button__link wp-element-button\" href=\"https://github.com/ethz-asl/WindSeer\" target=\"_blank\" rel=\"noreferrer noopener\">Get the code</a></div>\n</div>\n\n\n\n<h4 class=\"wp-block-heading\" id=\"learn-more\">Learn More:</h4>\n\n\n\n<p><a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://youtu.be/SRKmbexGg3U?si=ZCuPf9tFCrDg29UB\" target=\"_blank\" rel=\"noreferrer noopener\">WindSeer: Real-time volumetric wind prediction over complex terrain aboard a small UAV<span class=\"sr-only\"> (opens in new tab)</span></a></p>\n\n\n\n<section class=\"wp-block-msr-subscribe-to-podcast subscribe-to-podcast\">\n\t<div class=\"subscribe-to-podcast__inner border-top border-bottom border-width-2\">\n\t\t<h2 class=\"h5 subscribe-to-podcast__heading\">\n\t\t\tSubscribe to the <a href=\"https://www.microsoft.com/en-us/research/podcast\">Microsoft Research Podcast</a>:\t\t</h2>\n\t\t<ul class=\"subscribe-to-podcast__list list-unstyled\">\n\t\t\t\t\t\t\t<li class=\"subscribe-to-podcast__list-item\">\n\t\t\t\t\t<a class=\"subscribe-to-podcast__link\" href=\"https://itunes.apple.com/us/podcast/microsoft-research-a-podcast/id1318021537?mt=2\" target=\"_blank\" rel=\"noreferrer noopener\">\n\t\t\t\t\t\t<svg class=\"subscribe-to-podcast__svg\" xmlns=\"http://www.w3.org/2000/svg\" fill=\"black\" viewBox=\"0 0 32 32\">  <path d=\"M7.12 0c-3.937-0.011-7.131 3.183-7.12 7.12v17.76c-0.011 3.937 3.183 7.131 7.12 7.12h17.76c3.937 0.011 7.131-3.183 7.12-7.12v-17.76c0.011-3.937-3.183-7.131-7.12-7.12zM15.817 3.421c3.115 0 5.932 1.204 8.079 3.453 1.631 1.693 2.547 3.489 3.016 5.855 0.161 0.787 0.161 2.932 0.009 3.817-0.5 2.817-2.041 5.339-4.317 7.063-0.812 0.615-2.797 1.683-3.115 1.683-0.12 0-0.129-0.12-0.077-0.615 0.099-0.792 0.192-0.953 0.64-1.141 0.713-0.296 1.932-1.167 2.677-1.911 1.301-1.303 2.229-2.932 2.677-4.719 0.281-1.1 0.244-3.543-0.063-4.672-0.969-3.595-3.907-6.385-7.5-7.136-1.041-0.213-2.943-0.213-4 0-3.636 0.751-6.647 3.683-7.563 7.371-0.245 1.004-0.245 3.448 0 4.448 0.609 2.443 2.188 4.681 4.255 6.015 0.407 0.271 0.896 0.547 1.1 0.631 0.447 0.192 0.547 0.355 0.629 1.14 0.052 0.485 0.041 0.62-0.072 0.62-0.073 0-0.62-0.235-1.199-0.511l-0.052-0.041c-3.297-1.62-5.407-4.364-6.177-8.016-0.187-0.943-0.224-3.187-0.036-4.052 0.479-2.323 1.396-4.135 2.921-5.739 2.199-2.319 5.027-3.543 8.172-3.543zM16 7.172c0.541 0.005 1.068 0.052 1.473 0.14 3.715 0.828 6.344 4.543 5.833 8.229-0.203 1.489-0.713 2.709-1.619 3.844-0.448 0.573-1.537 1.532-1.729 1.532-0.032 0-0.063-0.365-0.063-0.803v-0.808l0.552-0.661c2.093-2.505 1.943-6.005-0.339-8.296-0.885-0.896-1.912-1.423-3.235-1.661-0.853-0.161-1.031-0.161-1.927-0.011-1.364 0.219-2.417 0.744-3.355 1.672-2.291 2.271-2.443 5.791-0.348 8.296l0.552 0.661v0.813c0 0.448-0.037 0.807-0.084 0.807-0.036 0-0.349-0.213-0.683-0.479l-0.047-0.016c-1.109-0.885-2.088-2.453-2.495-3.995-0.244-0.932-0.244-2.697 0.011-3.625 0.672-2.505 2.521-4.448 5.079-5.359 0.547-0.193 1.509-0.297 2.416-0.281zM15.823 11.156c0.417 0 0.828 0.084 1.131 0.24 0.645 0.339 1.183 0.989 1.385 1.677 0.62 2.104-1.609 3.948-3.631 3.005h-0.015c-0.953-0.443-1.464-1.276-1.475-2.36 0-0.979 0.541-1.828 1.484-2.328 0.297-0.156 0.709-0.235 1.125-0.235zM15.812 17.464c1.319-0.005 2.271 0.463 2.625 1.291 0.265 0.62 0.167 2.573-0.292 5.735-0.307 2.208-0.479 2.765-0.905 3.141-0.589 0.52-1.417 0.667-2.209 0.385h-0.004c-0.953-0.344-1.157-0.808-1.553-3.527-0.452-3.161-0.552-5.115-0.285-5.735 0.348-0.823 1.296-1.285 2.624-1.291z\"/></svg>\n\t\t\t\t\t\t<span class=\"subscribe-to-podcast__link-text\">Apple Podcasts</span>\n\t\t\t\t\t</a>\n\t\t\t\t</li>\n\t\t\t\n\t\t\t\t\t\t\t<li class=\"subscribe-to-podcast__list-item\">\n\t\t\t\t\t<a class=\"subscribe-to-podcast__link\" href=\"https://subscribebyemail.com/www.blubrry.com/feeds/microsoftresearch.xml\" target=\"_blank\" rel=\"noreferrer noopener\">\n\t\t\t\t\t\t<svg class=\"subscribe-to-podcast__svg\" xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 32 32\"><path fill=\"currentColor\" d=\"M6.4 6a2.392 2.392 0 00-2.372 2.119L16 15.6l11.972-7.481A2.392 2.392 0 0025.6 6H6.4zM4 10.502V22.8a2.4 2.4 0 002.4 2.4h19.2a2.4 2.4 0 002.4-2.4V10.502l-11.365 7.102a1.2 1.2 0 01-1.27 0L4 10.502z\"/></svg>\n\t\t\t\t\t\t<span class=\"subscribe-to-podcast__link-text\">Email</span>\n\t\t\t\t\t</a>\n\t\t\t\t</li>\n\t\t\t\n\t\t\t\t\t\t\t<li class=\"subscribe-to-podcast__list-item\">\n\t\t\t\t\t<a class=\"subscribe-to-podcast__link\" href=\"https://subscribeonandroid.com/www.blubrry.com/feeds/microsoftresearch.xml\" target=\"_blank\" rel=\"noreferrer noopener\">\n\t\t\t\t\t\t<svg class=\"subscribe-to-podcast__svg\" xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 32 32\"><path fill=\"currentColor\" d=\"M12.414 4.02c-.062.012-.126.023-.18.06a.489.489 0 00-.12.675L13.149 6.3c-1.6.847-2.792 2.255-3.18 3.944h13.257c-.388-1.69-1.58-3.097-3.179-3.944l1.035-1.545a.489.489 0 00-.12-.675.492.492 0 00-.675.135l-1.14 1.68a7.423 7.423 0 00-2.55-.45c-.899 0-1.758.161-2.549.45l-1.14-1.68a.482.482 0 00-.494-.195zm1.545 3.824a.72.72 0 110 1.44.72.72 0 010-1.44zm5.278 0a.719.719 0 110 1.44.719.719 0 110-1.44zM8.44 11.204A1.44 1.44 0 007 12.644v6.718c0 .795.645 1.44 1.44 1.44.168 0 .33-.036.48-.09v-9.418a1.406 1.406 0 00-.48-.09zm1.44 0V21.76c0 .793.646 1.44 1.44 1.44h10.557c.793 0 1.44-.647 1.44-1.44V11.204H9.878zm14.876 0c-.169 0-.33.035-.48.09v9.418c.15.052.311.09.48.09a1.44 1.44 0 001.44-1.44v-6.719a1.44 1.44 0 00-1.44-1.44zM11.8 24.16v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84zm5.759 0v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84z\"/></svg>\n\t\t\t\t\t\t<span class=\"subscribe-to-podcast__link-text\">Android</span>\n\t\t\t\t\t</a>\n\t\t\t\t</li>\n\t\t\t\n\t\t\t\t\t\t\t<li class=\"subscribe-to-podcast__list-item\">\n\t\t\t\t\t<a class=\"subscribe-to-podcast__link\" href=\"https://open.spotify.com/show/4ndjUXyL0hH1FXHgwIiTWU\" target=\"_blank\" rel=\"noreferrer noopener\">\n\t\t\t\t\t\t<svg class=\"subscribe-to-podcast__svg\" xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 32 32\"><path fill=\"currentColor\" d=\"M16 4C9.383 4 4 9.383 4 16s5.383 12 12 12 12-5.383 12-12S22.617 4 16 4zm5.08 17.394a.781.781 0 01-1.086.217c-1.29-.86-3.477-1.434-5.303-1.434-1.937.002-3.389.477-3.403.482a.782.782 0 11-.494-1.484c.068-.023 1.71-.56 3.897-.562 1.826 0 4.365.492 6.171 1.696.36.24.457.725.217 1.085zm1.56-3.202a.895.895 0 01-1.234.286c-2.338-1.457-4.742-1.766-6.812-1.747-2.338.02-4.207.466-4.239.476a.895.895 0 11-.488-1.723c.145-.041 2.01-.5 4.564-.521 2.329-.02 5.23.318 7.923 1.995.419.26.547.814.286 1.234zm1.556-3.745a1.043 1.043 0 01-1.428.371c-2.725-1.6-6.039-1.94-8.339-1.942h-.033c-2.781 0-4.923.489-4.944.494a1.044 1.044 0 01-.474-2.031c.096-.023 2.385-.55 5.418-.55h.036c2.558.004 6.264.393 9.393 2.23.497.292.663.931.371 1.428z\"/></svg>\n\t\t\t\t\t\t<span class=\"subscribe-to-podcast__link-text\">Spotify</span>\n\t\t\t\t\t</a>\n\t\t\t\t</li>\n\t\t\t\n\t\t\t\t\t\t\t<li class=\"subscribe-to-podcast__list-item\">\n\t\t\t\t\t<a class=\"subscribe-to-podcast__link\" href=\"https://www.blubrry.com/feeds/microsoftresearch.xml\" target=\"_blank\" rel=\"noreferrer noopener\">\n\t\t\t\t\t\t<svg class=\"subscribe-to-podcast__svg\" xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 32 32\"><path fill=\"currentColor\" d=\"M6.667 4a2.676 2.676 0 00-2.612 2.13v.003c-.036.172-.055.35-.055.534v18.666c0 .183.019.362.055.534v.003a2.676 2.676 0 002.076 2.075h.002c.172.036.35.055.534.055h18.666A2.676 2.676 0 0028 25.333V6.667a2.676 2.676 0 00-2.13-2.612h-.003A2.623 2.623 0 0025.333 4H6.667zM8 8h1.333C17.42 8 24 14.58 24 22.667V24h-2.667v-1.333c0-6.618-5.382-12-12-12H8V8zm0 5.333h1.333c5.146 0 9.334 4.188 9.334 9.334V24H16v-1.333A6.674 6.674 0 009.333 16H8v-2.667zM10 20a2 2 0 11-.001 4.001A2 2 0 0110 20z\"/></svg>\n\t\t\t\t\t\t<span class=\"subscribe-to-podcast__link-text\">RSS Feed</span>\n\t\t\t\t\t</a>\n\t\t\t\t</li>\n\t\t\t\t\t</ul>\n\t</div>\n</section>\n\n\n<div class=\"wp-block-msr-show-more\">\n\t<div class=\"bg-neutral-100 p-5\">\n\t\t<div class=\"show-more-show-less\" data-mount=\"show-more-show-less\">\n\t\t\t<div>\n\t\t\t\t<span>\n\t\t\t\t\t\n\n<h3 class=\"wp-block-heading\" id=\"transcript\">Transcript&nbsp;</h3>\n\n\n\n<p>[MUSIC]&nbsp;</p>\n\n\n\n<p><strong>GRETCHEN HUIZINGA: </strong>Welcome to <em>Abstracts</em>, a Microsoft Research Podcast that puts the spotlight on world-class research in brief. I’m Dr. Gretchen Huizinga. In this series, members of the research community at Microsoft give us a quick snapshot—or a <em>podcast abstract</em>—of their new and noteworthy papers.&nbsp;&nbsp;</p>\n\n\n\n<p>[MUSIC FADES]&nbsp;</p>\n\n\n\n<p>I&#8217;m here today with Dr. Andrey Kolobov, a principal research manager at Microsoft Research. Dr. Kolobov is coauthor of a paper called “WindSeer: Real-time volumetric wind prediction over complex terrain aboard a small uncrewed aerial vehicle,” otherwise known as an <em>sUAV</em>. Andrey Kolobov, great to have you on <em>Abstracts</em>!&nbsp;</p>\n\n\n\n\t\t\t\t</span>\n\t\t\t\t<span id=\"show-more-show-less-toggle-1\" class=\"show-more-show-less-toggleable-content\">\n\t\t\t\t\t\n\n\n\n<p><strong>ANDREY KOLOBOV: </strong>Thank you for having me!</p>\n\n\n\n<p><strong>HUIZINGA:</strong> So let&#8217;s start with a sort of abstract of your abstract. In just a few sentences, tell us about the problem your research addresses and more importantly, why we should care about it.&nbsp;</p>\n\n\n\n<p><strong>KOLOBOV:</strong> Right, so the overarching goal of this work—and I have to thank my collaborators from ETH Zürich, without whom this work would have been impossible—so the overarching goal of our work was to give drones the ability to stay aloft longer, safer, and cover larger distances. The reason why this is important is because drones’ potential for, for instance, quick delivery of small goods has long been understood, but in practice, their usefulness has been limited by the time they can spend in the air, by how quickly they drain their battery. And lifting these limitations brings the reality of getting the stuff that you order on the internet delivered to you quickly by drones closer.&nbsp;</p>\n\n\n\n<p><strong>HUIZINGA:</strong> Is that the core problem, is drone delivery?&nbsp;</p>\n\n\n\n<p><strong>KOLOBOV:</strong> Of course, when we were starting this project, we were not interested in any one application. We were interested in implications of AI for drone flight. The limitations of drones’ time aloft ultimately come from drone flight technology, which is very well established, very well understood, and ultimately relies on drones actively fighting forces of nature, such as gravity and wind, and because of this draining their batteries quickly. So within the framework of that technology, it&#8217;s difficult to get around these limitations. So what we&#8217;re aiming to show is that using AI, drones can reason about their environment in ways that allow them to embrace these forces of nature rather than actively fight them and thereby save a lot on energy and increase their time in the air.</p>\n\n\n\n<p><strong>HUIZINGA:</strong> Right, so are we conflating drones with sUAVs, as it were, small uncrewed aerial vehicle?&nbsp;</p>\n\n\n\n<p><strong>KOLOBOV:</strong> Yes, this work, we are somewhat conflating them, but this work focused specifically on <em>small</em> UAVs, <em>small</em> drones, because these drones&#8217; ability to fight forces of nature is quite limited. Their battery life is way more limited than that of larger drones, and for them, this work is especially important.&nbsp;</p>\n\n\n\n<p><strong>HUIZINGA:</strong> OK, and I&#8217;m assuming it&#8217;s not a new problem and also assuming that you&#8217;re not entering a field with no previous research! [LAUGHTER] So what&#8217;s been done in this area before, and what gap in the literature or the practice does your research fill?&nbsp;</p>\n\n\n\n<p><strong>KOLOBOV:</strong> Yeah, of course. Certainly, many other very, very smart people have thought about this area. What we have tried doing and what we have accomplished differs from previous efforts in how much compute, how little data at inference time, our method requires and also the fine scale at which it makes its predictions. Obviously, there are weather models that model various aspects of the atmosphere, and they can predict wind, but they can do this at the scales of hours, at spatial scales of tens of miles, which is way too crude to be useful for drone flights at low altitudes. And also, these models do this at much higher altitudes, not where drones fly close to the ground, where it&#8217;s very important for them to know about wind to avoid collision with terrain potentially, but very high up in the air. The tool that could solve the same problem that we were trying to solve conceptually are computational fluid dynamics simulations, so-called CFD simulations. However, they&#8217;re very expensive. They cannot run on the drone. And so if you want the drone to be fully autonomous, they&#8217;re not really a feasible solution.&nbsp;</p>\n\n\n\n<p><strong>HUIZINGA:</strong> So how would you describe then how you attacked this problem? What methodology did you use for this work, and how did you go about conducting the research?</p>\n\n\n\n<p><strong>KOLOBOV:</strong> So one thing that people reading about this work might find funny is this déjà vu feeling of seeing the overarching technical insight that we had in a completely different context, in the context of training models such as Phi, Microsoft&#8217;s Phi. The reason why it&#8217;s funny is because we were trying to solve an entirely different problem in a project that started in a different era, <em>research era</em>, in the pre-large model era, and yet we came up with something quite similar. And this overarching technical insight is this: if you want to build a small but powerful model, one way of doing this is to find a powerful but potentially computationally expensive—or expensive in some other way—generative data source, generate data from that source in a very carefully controlled manner, and use this carefully constructed dataset to train your model. This is exactly what we did. In our case, this powerful but expensive generative data source were the computational fluid dynamic simulations, which we used in combination with 3D terrain maps that are publicly available on the internet to generate a lot of high-quality data, throw in a few more tricks, and get the model that we wanted.&nbsp;</p>\n\n\n\n<p><strong>HUIZINGA:</strong> Can you talk about the “few more tricks”? [LAUGHS]&nbsp;</p>\n\n\n\n<p><strong>KOLOBOV:</strong> [LAUGHS] Well, so we needed to train this model to make predictions based on very little data. Computational fluid dynamics simulations typically need a lot of data at prediction time. And so the so-called boundary conditions essentially need to know the wind at many locations in order to be able to predict it at the location that you&#8217;re interested in. And so we had to structure the data generation in a way that allowed us to avoid this limitation.&nbsp;</p>\n\n\n\n<p><strong>HUIZINGA:</strong> Talk to me a little bit more about the datasets that you used.&nbsp;</p>\n\n\n\n<p><strong>KOLOBOV:</strong> Yes, so all the data was synthetically generated.&nbsp;</p>\n\n\n\n<p><strong>HUIZINGA:</strong> All of it?&nbsp;</p>\n\n\n\n<p><strong>KOLOBOV:</strong> All of it! All of it was generated from computational fluid dynamics simulations.&nbsp;</p>\n\n\n\n<p><strong>HUIZINGA:</strong> Um, and was this methodology unique and new, or is it, uh, kind of building on other ways of doing things?&nbsp;</p>\n\n\n\n<p><strong>KOLOBOV:</strong> So the idea of using high-quality data sources under various guises had been known in the community, to various research communities in any case. Some would refer to it as distillation. Some would refer to it as data simulation. So in the context of these predictive weather models, it would be known as data simulation. But none of them were doing what we were trying to do, again which is getting a model that will make predictions on a very limited compute with a very limited amount of data at inference time.&nbsp;</p>\n\n\n\n<p><strong>HUIZINGA:</strong> Well, let&#8217;s move from research methods to research findings. Give us a quick overview of how things worked out for you and what you found.&nbsp;</p>\n\n\n\n<p><strong>KOLOBOV:</strong> So in a nutshell, as trivial as it sounds, the surprising finding was that it works! [LAUGHTER] Again, the reason why it&#8217;s surprising is, again, we used only synthetic data to predict something very, very real and something that people have put a lot of thinking into modeling as part of weather models, for instance. And it turned out that using just synthetic data, you can get a small model that, as the drone is flying through the air and as it&#8217;s measuring wind at its current location, this model allows you to predict that there is a downdraft 300 feet away from the drone on the other side of the hill. It&#8217;s just amazing that something so small can do something so complex and powerful.&nbsp;</p>\n\n\n\n<p><strong>HUIZINGA:</strong> Right. Well, let&#8217;s drill in there and, kind of, talk about real-world impact here because this is really important for a lot of wind-prediction scenarios. How does this impact real-world scenarios? <em>Who</em> benefits most from the kinds of applications that you might get from this?</p>\n\n\n\n<p><strong>KOLOBOV:</strong> Yeah, so there is a number of scenarios where it&#8217;s valuable to have a drone—usually a fixed-wing drone that, due to its inherent characteristics, can stay in the air longer than a copter drone—where it&#8217;s beneficial to have such a drone stay in the air for long periods of time, silently observing something. So the applications range from agriculture to environment conservation, where you want to track the movements, migrations of animals, to security. And of course, the technology that we develop does not have to be applied to fixed-wing drones. It can also be applied to copter drones, which is the drone model that is usually considered for use in drone delivery, and those drones can also benefit from it, especially in city conditions, where presumably they will have to fly around skyscrapers and take into account the effects that the skyscrapers and other buildings and structures have on the wind near terrain.&nbsp;</p>\n\n\n\n<p><strong>HUIZINGA:</strong> So one more question on the real-world impact. In your paper, you talked a little bit about wind farming and other places where understanding how wind works and being able to predict it matters. Is that one? Are there others?&nbsp;</p>\n\n\n\n<p><strong>KOLOBOV:</strong> It for sure is one area. Again, in this work, we focused mostly on applications of wind prediction that have to do with drones.&nbsp;&nbsp;</p>\n\n\n\n<p><strong>HUIZINGA: </strong>OK.&nbsp;&nbsp;</p>\n\n\n\n<p><strong>KOLOBOV: </strong>Besides time aloft, one application is safety. In many places around rough terrain, you know, in the mountains, predicting wind, predicting downdrafts and updrafts, has safety implications because drones fly so close to terrain, and the winds, the airflow, can be so strong in some places over such terrain that it can basically drag the drone into the ground no matter what [the] drone does. It can do it very, very quickly. So again, predicting such phenomena there becomes a matter of drone safety. The same applies, or will apply, in city conditions, where drones will be flying among buildings and wind can be so strong that it can carry a drone into a building or into another obstacle.&nbsp;&nbsp;</p>\n\n\n\n<p><strong>HUIZINGA:</strong> Well, I assume you didn&#8217;t solve everything with this paper and that there might still be some open questions remaining in the field! So what are some of the big outstanding challenges people still face here, and what&#8217;s next on <em>your</em> research agenda to overcome them?&nbsp;</p>\n\n\n\n<p><strong>KOLOBOV:</strong> Of course, this work is, in some sense, just the beginning. This work is about helping drones make sense of the environment around them. But this ability to make sense is not by itself useful without drones being able to use the results of this estimation in order to plan how to fly in a safer and more energy-efficient way and to adapt their plans as the environment around them changes. So this is a natural next steps: have drones take their predictions into account when planning their actions.&nbsp;</p>\n\n\n\n<p><strong>HUIZINGA:</strong> Well, Andrey Kolobov, thanks for joining us today, and to our listeners, thanks for tuning in. If you want to read this paper, you can find a link at <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://aka.ms/abstracts\" target=\"_blank\" rel=\"noreferrer noopener\">aka.ms/abstracts<span class=\"sr-only\"> (opens in new tab)</span></a> or you can find one on arXiv. You can also read it on <em>Nature Communications</em> in Volume 15, April 25. See you next time on <em>Abstracts</em>!&nbsp;</p>\n\n\n\n<p>[MUSIC]</p>\n\n\t\t\t\t</span>\n\t\t\t</div>\n\t\t\t<button\n\t\t\t\tclass=\"action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle\"\n\t\t\t\taria-expanded=\"false\"\n\t\t\t\tdata-show-less-text=\"Show less\"\n\t\t\t\ttype=\"button\"\n\t\t\t\taria-controls=\"show-more-show-less-toggle-1\"\n\t\t\t\taria-label=\"Show more content\"\n\t\t\t\tdata-alternate-aria-label=\"Show less content\">\n\t\t\t\tShow more\t\t\t</button>\n\t\t</div>\n\t</div>\n</div>\n<span id=\"label-external-link\" class=\"sr-only\" aria-hidden=\"true\">Opens in a new tab</span>",
            "protected": false
        },
        "excerpt": {
            "rendered": "<p>Andrey Kolobov discusses WindSeer, a small CNN capable of estimating the wind field around an sUAV in flight more finely and with less compute and data than traditional models. The advancement can help support longer and safer autonomous flights.</p>\n",
            "protected": false
        },
        "author": 42735,
        "featured_media": 1038528,
        "comment_status": "closed",
        "ping_status": "closed",
        "sticky": false,
        "template": "",
        "format": "standard",
        "meta": {
            "msr-url-field": "https://player.blubrry.com/id/132574534",
            "msr-podcast-episode": "",
            "msrModifiedDate": "",
            "msrModifiedDateEnabled": false,
            "ep_exclude_from_search": false,
            "footnotes": ""
        },
        "categories": [
            240054
        ],
        "tags": [],
        "research-area": [
            13556
        ],
        "msr-region": [],
        "msr-event-type": [],
        "msr-post-option": [
            243990
        ],
        "msr-impact-theme": [],
        "msr-promo-type": [],
        "msr-podcast-series": [
            268128
        ],
        "msr_event_details": {
            "start": "",
            "end": "",
            "location": ""
        },
        "podcast_url": "https://player.blubrry.com/id/132574534",
        "podcast_episode": "",
        "msr_research_lab": [
            992148
        ],
        "msr_impact_theme": [],
        "related-publications": [],
        "related-downloads": [],
        "related-videos": [],
        "related-academic-programs": [],
        "related-groups": [
            862206
        ],
        "related-projects": [
            502862
        ],
        "related-events": [],
        "related-researchers": [
            {
                "type": "user_nicename",
                "value": "Andrey Kolobov",
                "user_id": 30910,
                "display_name": "Andrey Kolobov",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/akolobov/\" aria-label=\"Visit the profile page for Andrey Kolobov\">Andrey Kolobov</a>",
                "is_active": false,
                "last_first": "Kolobov, Andrey",
                "people_section": 0,
                "alias": "akolobov"
            },
            {
                "type": "guest",
                "value": "gretchen-huizinga-2",
                "user_id": "444834",
                "display_name": "Gretchen Huizinga",
                "author_link": "<a href=\"https://www.linkedin.com/in/gretchen-huizinga-phd-3a4b2921?trk=people-guest_people_search-card\" aria-label=\"Visit the profile page for Gretchen Huizinga\">Gretchen Huizinga</a>",
                "is_active": true,
                "last_first": "Huizinga, Gretchen",
                "people_section": 0,
                "alias": "gretchen-huizinga-2"
            }
        ],
        "msr_type": "Post",
        "featured_image_thumbnail": "<img width=\"960\" height=\"540\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Episode-12_Abstracts_Hero_Feature_No_Text_1400x788-960x540.png\" class=\"img-object-cover\" alt=\"Microsoft Research Podcast - Abstracts | May 20, 2024 | Andrey Kolobov\" decoding=\"async\" loading=\"lazy\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Episode-12_Abstracts_Hero_Feature_No_Text_1400x788-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Episode-12_Abstracts_Hero_Feature_No_Text_1400x788-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Episode-12_Abstracts_Hero_Feature_No_Text_1400x788-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Episode-12_Abstracts_Hero_Feature_No_Text_1400x788-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Episode-12_Abstracts_Hero_Feature_No_Text_1400x788-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Episode-12_Abstracts_Hero_Feature_No_Text_1400x788-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Episode-12_Abstracts_Hero_Feature_No_Text_1400x788-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Episode-12_Abstracts_Hero_Feature_No_Text_1400x788-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Episode-12_Abstracts_Hero_Feature_No_Text_1400x788-1280x720.png 1280w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Episode-12_Abstracts_Hero_Feature_No_Text_1400x788.png 1400w\" sizes=\"(max-width: 960px) 100vw, 960px\" />",
        "byline": "<a href=\"https://www.microsoft.com/en-us/research/people/akolobov/\" title=\"Go to researcher profile for Andrey Kolobov\" aria-label=\"Go to researcher profile for Andrey Kolobov\" data-bi-type=\"byline author\" data-bi-cN=\"Andrey Kolobov\">Andrey Kolobov</a> and <a href=\"https://www.linkedin.com/in/gretchen-huizinga-phd-3a4b2921?trk=people-guest_people_search-card\" title=\"Go to researcher profile for Gretchen Huizinga\" aria-label=\"Go to researcher profile for Gretchen Huizinga\" data-bi-type=\"byline author\" data-bi-cN=\"Gretchen Huizinga\">Gretchen Huizinga</a>",
        "formattedDate": "May 20, 2024",
        "formattedExcerpt": "Andrey Kolobov discusses WindSeer, a small CNN capable of estimating the wind field around an sUAV in flight more finely and with less compute and data than traditional models. The advancement can help support longer and safer autonomous flights.",
        "_links": {
            "self": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1034046"
                }
            ],
            "collection": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts"
                }
            ],
            "about": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/types/post"
                }
            ],
            "author": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/users/42735"
                }
            ],
            "replies": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/comments?post=1034046"
                }
            ],
            "version-history": [
                {
                    "count": 11,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1034046/revisions"
                }
            ],
            "predecessor-version": [
                {
                    "id": 1038657,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1034046/revisions/1038657"
                }
            ],
            "wp:featuredmedia": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/media/1038528"
                }
            ],
            "wp:attachment": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/media?parent=1034046"
                }
            ],
            "wp:term": [
                {
                    "taxonomy": "category",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/categories?post=1034046"
                },
                {
                    "taxonomy": "post_tag",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/tags?post=1034046"
                },
                {
                    "taxonomy": "msr-research-area",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/research-area?post=1034046"
                },
                {
                    "taxonomy": "msr-region",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-region?post=1034046"
                },
                {
                    "taxonomy": "msr-event-type",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-event-type?post=1034046"
                },
                {
                    "taxonomy": "msr-post-option",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-post-option?post=1034046"
                },
                {
                    "taxonomy": "msr-impact-theme",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-impact-theme?post=1034046"
                },
                {
                    "taxonomy": "msr-promo-type",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-promo-type?post=1034046"
                },
                {
                    "taxonomy": "msr-podcast-series",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-podcast-series?post=1034046"
                }
            ],
            "curies": [
                {
                    "name": "wp",
                    "href": "https://api.w.org/{rel}",
                    "templated": true
                }
            ]
        }
    },
    {
        "id": 1021077,
        "date": "2024-05-16T06:00:00",
        "date_gmt": "2024-05-16T13:00:00",
        "guid": {
            "rendered": "https://www.microsoft.com/en-us/research/?p=1021077"
        },
        "modified": "2024-05-15T12:34:59",
        "modified_gmt": "2024-05-15T19:34:59",
        "slug": "whats-your-story-jacki-oneill",
        "status": "publish",
        "type": "post",
        "link": "https://www.microsoft.com/en-us/research/podcast/whats-your-story-jacki-oneill/",
        "title": {
            "rendered": "What’s Your Story: Jacki O’Neill"
        },
        "content": {
            "rendered": "\n<figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1400\" height=\"788\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki-ONeill_WYS_Hero_Feature_1400x788.png\" alt=\"Circle photo of Jacki O'Neill, director of the Microsoft Africa Research Institute (MARI), with a microphone in the corner on a blue and green gradient background\" class=\"wp-image-1021107\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki-ONeill_WYS_Hero_Feature_1400x788.png 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki-ONeill_WYS_Hero_Feature_1400x788-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki-ONeill_WYS_Hero_Feature_1400x788-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki-ONeill_WYS_Hero_Feature_1400x788-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki-ONeill_WYS_Hero_Feature_1400x788-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki-ONeill_WYS_Hero_Feature_1400x788-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki-ONeill_WYS_Hero_Feature_1400x788-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki-ONeill_WYS_Hero_Feature_1400x788-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki-ONeill_WYS_Hero_Feature_1400x788-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki-ONeill_WYS_Hero_Feature_1400x788-1280x720.png 1280w\" sizes=\"(max-width: 1400px) 100vw, 1400px\" /></figure>\n\n\n<div class=\"wp-block-msr-podcast-container\">\n\t<iframe loading=\"lazy\" src=\"https://player.blubrry.com/?podcast_id=131869304&modern=1\" class=\"podcast-player\" frameborder=\"0\" height=\"164px\" width=\"100%\" scrolling=\"no\" title=\"Podcast Player\"></iframe>\n</div>\n\n\n\n<p>In the Microsoft Research Podcast series <em>What’s Your Story</em>, Johannes Gehrke explores the <em>who</em> behind the technical and scientific advancements helping to reshape the world. A systems expert whose 10 years with Microsoft spans research and product, Gehrke talks to members of the company’s research community about what motivates their work and how they got where they are today.</p>\n\n\n\n<p>In this episode, Gehrke is joined by <a href=\"https://www.microsoft.com/en-us/research/people/jaoneil/\">Jacki O&#8217;Neill</a>, director of Microsoft Research Africa, Nairobi (formerly the Microsoft Africa Research Institute, or MARI) in Kenya. O’Neill pitched the idea for the lab after seeing an opportunity to expand the Microsoft research portfolio. She shares how a desire to build tech that can have <em>global </em>societal impact and a familial connection to the continent factored into the decision; how a belief that life is meant to be exciting has allowed her to take big personal and professional swings; and how her team in Nairobi is applying their respective expertise in human-computer interaction, machine learning, and data science to pursue globally equitable AI.</p>\n\n\n\n<p>To learn more about the global impact of AI, efforts to make AI more equitable, and related topics, <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://researchforum.microsoft.com/\" target=\"_blank\" rel=\"noreferrer noopener\">register for Microsoft Research Forum<span class=\"sr-only\"> (opens in new tab)</span></a>, a series of panel discussions and lightning talks around science and technology research in the era of general AI.</p>\n\n\n\n<figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1600\" height=\"462\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki_ONeill_Through_The_Years_Banner.png\" alt=\"Photos of Jacki O'Neill, director of the Microsoft Africa Research Institute (MARI), throughout her life.\" class=\"wp-image-1021104\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki_ONeill_Through_The_Years_Banner.png 1600w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki_ONeill_Through_The_Years_Banner-300x87.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki_ONeill_Through_The_Years_Banner-1024x296.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki_ONeill_Through_The_Years_Banner-768x222.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki_ONeill_Through_The_Years_Banner-1536x444.png 1536w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki_ONeill_Through_The_Years_Banner-240x69.png 240w\" sizes=\"(max-width: 1600px) 100vw, 1600px\" /></figure>\n\n\n\n<div class=\"wp-block-group msr-pattern-link-list is-layout-flow wp-block-group-is-layout-flow\">\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n\n\n\n<h2 class=\"wp-block-heading h5\" id=\"learn-more-1\">Learn more:</h2>\n\n\n\n<ul class=\"list-unstyled\">\n<li><a href=\"https://www.microsoft.com/en-us/research/people/jaoneil/\">Jacki O&#8217;Neill at Microsoft Research</a></li>\n\n\n\n<li><a href=\"https://www.microsoft.com/en-us/research/group/microsoft-africa-research-institute-mari/\">Microsoft Research Africa, Nairobi (formerly MARI)</a></li>\n</ul>\n\n\n\n<section class=\"wp-block-msr-subscribe-to-podcast subscribe-to-podcast\">\n\t<div class=\"subscribe-to-podcast__inner border-top border-bottom border-width-2\">\n\t\t<h2 class=\"h5 subscribe-to-podcast__heading\">\n\t\t\tSubscribe to the <a href=\"https://www.microsoft.com/en-us/research/podcast\">Microsoft Research Podcast</a>:\t\t</h2>\n\t\t<ul class=\"subscribe-to-podcast__list list-unstyled\">\n\t\t\t\t\t\t\t<li class=\"subscribe-to-podcast__list-item\">\n\t\t\t\t\t<a class=\"subscribe-to-podcast__link\" href=\"https://itunes.apple.com/us/podcast/microsoft-research-a-podcast/id1318021537?mt=2\" target=\"_blank\" rel=\"noreferrer noopener\">\n\t\t\t\t\t\t<svg class=\"subscribe-to-podcast__svg\" xmlns=\"http://www.w3.org/2000/svg\" fill=\"black\" viewBox=\"0 0 32 32\">  <path d=\"M7.12 0c-3.937-0.011-7.131 3.183-7.12 7.12v17.76c-0.011 3.937 3.183 7.131 7.12 7.12h17.76c3.937 0.011 7.131-3.183 7.12-7.12v-17.76c0.011-3.937-3.183-7.131-7.12-7.12zM15.817 3.421c3.115 0 5.932 1.204 8.079 3.453 1.631 1.693 2.547 3.489 3.016 5.855 0.161 0.787 0.161 2.932 0.009 3.817-0.5 2.817-2.041 5.339-4.317 7.063-0.812 0.615-2.797 1.683-3.115 1.683-0.12 0-0.129-0.12-0.077-0.615 0.099-0.792 0.192-0.953 0.64-1.141 0.713-0.296 1.932-1.167 2.677-1.911 1.301-1.303 2.229-2.932 2.677-4.719 0.281-1.1 0.244-3.543-0.063-4.672-0.969-3.595-3.907-6.385-7.5-7.136-1.041-0.213-2.943-0.213-4 0-3.636 0.751-6.647 3.683-7.563 7.371-0.245 1.004-0.245 3.448 0 4.448 0.609 2.443 2.188 4.681 4.255 6.015 0.407 0.271 0.896 0.547 1.1 0.631 0.447 0.192 0.547 0.355 0.629 1.14 0.052 0.485 0.041 0.62-0.072 0.62-0.073 0-0.62-0.235-1.199-0.511l-0.052-0.041c-3.297-1.62-5.407-4.364-6.177-8.016-0.187-0.943-0.224-3.187-0.036-4.052 0.479-2.323 1.396-4.135 2.921-5.739 2.199-2.319 5.027-3.543 8.172-3.543zM16 7.172c0.541 0.005 1.068 0.052 1.473 0.14 3.715 0.828 6.344 4.543 5.833 8.229-0.203 1.489-0.713 2.709-1.619 3.844-0.448 0.573-1.537 1.532-1.729 1.532-0.032 0-0.063-0.365-0.063-0.803v-0.808l0.552-0.661c2.093-2.505 1.943-6.005-0.339-8.296-0.885-0.896-1.912-1.423-3.235-1.661-0.853-0.161-1.031-0.161-1.927-0.011-1.364 0.219-2.417 0.744-3.355 1.672-2.291 2.271-2.443 5.791-0.348 8.296l0.552 0.661v0.813c0 0.448-0.037 0.807-0.084 0.807-0.036 0-0.349-0.213-0.683-0.479l-0.047-0.016c-1.109-0.885-2.088-2.453-2.495-3.995-0.244-0.932-0.244-2.697 0.011-3.625 0.672-2.505 2.521-4.448 5.079-5.359 0.547-0.193 1.509-0.297 2.416-0.281zM15.823 11.156c0.417 0 0.828 0.084 1.131 0.24 0.645 0.339 1.183 0.989 1.385 1.677 0.62 2.104-1.609 3.948-3.631 3.005h-0.015c-0.953-0.443-1.464-1.276-1.475-2.36 0-0.979 0.541-1.828 1.484-2.328 0.297-0.156 0.709-0.235 1.125-0.235zM15.812 17.464c1.319-0.005 2.271 0.463 2.625 1.291 0.265 0.62 0.167 2.573-0.292 5.735-0.307 2.208-0.479 2.765-0.905 3.141-0.589 0.52-1.417 0.667-2.209 0.385h-0.004c-0.953-0.344-1.157-0.808-1.553-3.527-0.452-3.161-0.552-5.115-0.285-5.735 0.348-0.823 1.296-1.285 2.624-1.291z\"/></svg>\n\t\t\t\t\t\t<span class=\"subscribe-to-podcast__link-text\">Apple Podcasts</span>\n\t\t\t\t\t</a>\n\t\t\t\t</li>\n\t\t\t\n\t\t\t\t\t\t\t<li class=\"subscribe-to-podcast__list-item\">\n\t\t\t\t\t<a class=\"subscribe-to-podcast__link\" href=\"https://subscribebyemail.com/www.blubrry.com/feeds/microsoftresearch.xml\" target=\"_blank\" rel=\"noreferrer noopener\">\n\t\t\t\t\t\t<svg class=\"subscribe-to-podcast__svg\" xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 32 32\"><path fill=\"currentColor\" d=\"M6.4 6a2.392 2.392 0 00-2.372 2.119L16 15.6l11.972-7.481A2.392 2.392 0 0025.6 6H6.4zM4 10.502V22.8a2.4 2.4 0 002.4 2.4h19.2a2.4 2.4 0 002.4-2.4V10.502l-11.365 7.102a1.2 1.2 0 01-1.27 0L4 10.502z\"/></svg>\n\t\t\t\t\t\t<span class=\"subscribe-to-podcast__link-text\">Email</span>\n\t\t\t\t\t</a>\n\t\t\t\t</li>\n\t\t\t\n\t\t\t\t\t\t\t<li class=\"subscribe-to-podcast__list-item\">\n\t\t\t\t\t<a class=\"subscribe-to-podcast__link\" href=\"https://subscribeonandroid.com/www.blubrry.com/feeds/microsoftresearch.xml\" target=\"_blank\" rel=\"noreferrer noopener\">\n\t\t\t\t\t\t<svg class=\"subscribe-to-podcast__svg\" xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 32 32\"><path fill=\"currentColor\" d=\"M12.414 4.02c-.062.012-.126.023-.18.06a.489.489 0 00-.12.675L13.149 6.3c-1.6.847-2.792 2.255-3.18 3.944h13.257c-.388-1.69-1.58-3.097-3.179-3.944l1.035-1.545a.489.489 0 00-.12-.675.492.492 0 00-.675.135l-1.14 1.68a7.423 7.423 0 00-2.55-.45c-.899 0-1.758.161-2.549.45l-1.14-1.68a.482.482 0 00-.494-.195zm1.545 3.824a.72.72 0 110 1.44.72.72 0 010-1.44zm5.278 0a.719.719 0 110 1.44.719.719 0 110-1.44zM8.44 11.204A1.44 1.44 0 007 12.644v6.718c0 .795.645 1.44 1.44 1.44.168 0 .33-.036.48-.09v-9.418a1.406 1.406 0 00-.48-.09zm1.44 0V21.76c0 .793.646 1.44 1.44 1.44h10.557c.793 0 1.44-.647 1.44-1.44V11.204H9.878zm14.876 0c-.169 0-.33.035-.48.09v9.418c.15.052.311.09.48.09a1.44 1.44 0 001.44-1.44v-6.719a1.44 1.44 0 00-1.44-1.44zM11.8 24.16v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84zm5.759 0v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84z\"/></svg>\n\t\t\t\t\t\t<span class=\"subscribe-to-podcast__link-text\">Android</span>\n\t\t\t\t\t</a>\n\t\t\t\t</li>\n\t\t\t\n\t\t\t\t\t\t\t<li class=\"subscribe-to-podcast__list-item\">\n\t\t\t\t\t<a class=\"subscribe-to-podcast__link\" href=\"https://open.spotify.com/show/4ndjUXyL0hH1FXHgwIiTWU\" target=\"_blank\" rel=\"noreferrer noopener\">\n\t\t\t\t\t\t<svg class=\"subscribe-to-podcast__svg\" xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 32 32\"><path fill=\"currentColor\" d=\"M16 4C9.383 4 4 9.383 4 16s5.383 12 12 12 12-5.383 12-12S22.617 4 16 4zm5.08 17.394a.781.781 0 01-1.086.217c-1.29-.86-3.477-1.434-5.303-1.434-1.937.002-3.389.477-3.403.482a.782.782 0 11-.494-1.484c.068-.023 1.71-.56 3.897-.562 1.826 0 4.365.492 6.171 1.696.36.24.457.725.217 1.085zm1.56-3.202a.895.895 0 01-1.234.286c-2.338-1.457-4.742-1.766-6.812-1.747-2.338.02-4.207.466-4.239.476a.895.895 0 11-.488-1.723c.145-.041 2.01-.5 4.564-.521 2.329-.02 5.23.318 7.923 1.995.419.26.547.814.286 1.234zm1.556-3.745a1.043 1.043 0 01-1.428.371c-2.725-1.6-6.039-1.94-8.339-1.942h-.033c-2.781 0-4.923.489-4.944.494a1.044 1.044 0 01-.474-2.031c.096-.023 2.385-.55 5.418-.55h.036c2.558.004 6.264.393 9.393 2.23.497.292.663.931.371 1.428z\"/></svg>\n\t\t\t\t\t\t<span class=\"subscribe-to-podcast__link-text\">Spotify</span>\n\t\t\t\t\t</a>\n\t\t\t\t</li>\n\t\t\t\n\t\t\t\t\t\t\t<li class=\"subscribe-to-podcast__list-item\">\n\t\t\t\t\t<a class=\"subscribe-to-podcast__link\" href=\"https://www.blubrry.com/feeds/microsoftresearch.xml\" target=\"_blank\" rel=\"noreferrer noopener\">\n\t\t\t\t\t\t<svg class=\"subscribe-to-podcast__svg\" xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 32 32\"><path fill=\"currentColor\" d=\"M6.667 4a2.676 2.676 0 00-2.612 2.13v.003c-.036.172-.055.35-.055.534v18.666c0 .183.019.362.055.534v.003a2.676 2.676 0 002.076 2.075h.002c.172.036.35.055.534.055h18.666A2.676 2.676 0 0028 25.333V6.667a2.676 2.676 0 00-2.13-2.612h-.003A2.623 2.623 0 0025.333 4H6.667zM8 8h1.333C17.42 8 24 14.58 24 22.667V24h-2.667v-1.333c0-6.618-5.382-12-12-12H8V8zm0 5.333h1.333c5.146 0 9.334 4.188 9.334 9.334V24H16v-1.333A6.674 6.674 0 009.333 16H8v-2.667zM10 20a2 2 0 11-.001 4.001A2 2 0 0110 20z\"/></svg>\n\t\t\t\t\t\t<span class=\"subscribe-to-podcast__link-text\">RSS Feed</span>\n\t\t\t\t\t</a>\n\t\t\t\t</li>\n\t\t\t\t\t</ul>\n\t</div>\n</section>\n\n\n<div class=\"wp-block-msr-show-more\">\n\t<div class=\"bg-neutral-100 p-5\">\n\t\t<div class=\"show-more-show-less\" data-mount=\"show-more-show-less\">\n\t\t\t<div>\n\t\t\t\t<span>\n\t\t\t\t\t\n\n<p><strong><em>Editor’s note, May 16, 2024<em><strong>&nbsp;–</strong></em></em></strong><em> Since the recording of this podcast episode, the name of the Microsoft Africa Research Institute (MARI) has changed. The name of the lab is now Microsoft Research Africa, Nairobi.</em></p>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"transcript-1\">Transcript</h2>\n\n\n\n<p>[TEASER]&nbsp;</p>\n\n\n\n<p>[MUSIC PLAYS UNDER DIALOGUE]&nbsp;</p>\n\n\n\n<p><strong>JACKI</strong> <strong>O’NEILL:</strong> I love living in different places, and those experiences are what help us innovate better and design things that are, like, taking another point of view, more creative, I think. Just sparks things in your, in your head. And, I mean, it&#8217;s so much fun.</p>\n\n\n\n<p>[TEASER ENDS]&nbsp;</p>\n\n\n\n<p><strong>JOHANNES GEHRKE:</strong> Microsoft Research works at the cutting edge. But how much do we know about the people behind the science and technology that we create? This is <em>What’s Your Story</em>, and I’m Johannes Gehrke. In my 10 years with Microsoft, across product and research, I’ve been continuously excited and inspired by the people I work with, and I’m curious about how they became the talented and passionate people they are today. So I sat down with some of them. Now, I’m sharing their stories with you. In this podcast series, you’ll hear from them about how they grew up, the critical choices that shaped their lives, and their advice to others looking to carve a similar path.</p>\n\n\n\n<p>[MUSIC FADES]&nbsp;</p>\n\n\n\n<p>In this episode, I’m talking with Jacki O&#8217;Neill, director of the Microsoft Africa Research Institute—or <em>MARI</em>, for short—in Nairobi, Kenya. Jacki’s decadelong career at Microsoft began at the company’s India research lab, where she applied her ethnographic and human-computer interaction expertise to advancing equity in the country.</p>\n\n\n\n<p>After the opening of two Microsoft software engineering centers in Africa, Jacki made the case for a research lab on the continent. She now leads the MARI team in making technology more inclusive, a role that allows her to pursue her goal of positive local change with global impact. Here’s my conversation with Jacki, beginning with her time growing up in Plymouth, England.</p>\n\n\n\n\t\t\t\t</span>\n\t\t\t\t<span id=\"show-more-show-less-toggle-2\" class=\"show-more-show-less-toggleable-content\">\n\t\t\t\t\t\n\n\n\n<p><strong>GEHRKE: </strong>We just had a discussion maybe a couple of years ago, right, when you were just in transition to Africa. So it’s really great to have you here and both learn a little bit what’s happening there, but also to learn a bit more about your story. Where did you grow up, and how did you end up here at Microsoft?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yeah, thanks for asking that. I&#8217;ve had a very, well, it&#8217;s definitely not been a straight road to get here, but the windy roads are the most interesting ones. I grew up in Plymouth, which is a dockyard and naval town in the southwest of England, so a socially deprived working-class town. So when I was growing up, it was a thriving working-class town, but of course with those industries, you know, they didn&#8217;t, they didn&#8217;t pass so well through those years. So, you know, by the time I was leaving school, it was quite a deprived city and still is. I think that it&#8217;s really important to be in those type of places, though, because you get a very rich view of life, and I left them as soon as I could, [LAUGHS] so &#8230;</p>\n\n\n\n<p><strong>GEHRKE:</strong> When you went to university?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Went to, well, I went and I was a cook for a year in the Lake District, which is a very beautiful part of the UK, and then went to university.</p>\n\n\n\n<p><strong>GEHRKE:</strong> Where&#8217;s the Lake District?</p>\n\n\n\n<p><strong>O’NEILL:</strong> It is northwest, and it&#8217;s all hills. It&#8217;s, like, Wordsworth Country. It&#8217;s all hills and poetry and beautiful houses. And, yeah, it was a fantastic time working as a cook there. And then I went to Manchester to do my degree.</p>\n\n\n\n<p><strong>GEHRKE:</strong> OK. And what is your degree in?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Ah, so, yes, I had, I did a social science degree to start with. I started at the time when you could get a degree in anything and get any job at the end of it. But by the time I came out of my degree, it was a recession.</p>\n\n\n\n<p><strong>GEHRKE:</strong> But did you have, did you have specific plans while you were studying of what you want, you know, what profession you wanted to go into?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Not really. I didn&#8217;t. I think I&#8217;d, I think like many young people, I didn&#8217;t really know, but I felt that I would find something interesting when I came out. And then, you know, I just worked lots of different jobs. [LAUGHS]</p>\n\n\n\n<p><strong>GEHRKE:</strong> What is your favorite college course?</p>\n\n\n\n<p><strong>O’NEILL:</strong> My <em>favorite</em> college course—in my degree? Gosh, that&#8217;s a good question. It was all so long ago. [LAUGHS]</p>\n\n\n\n<p><strong>GEHRKE: </strong>OK …<strong></strong></p>\n\n\n\n<p><strong>O’NEILL: </strong>My favorite, I guess, yeah, no, I, so, I did &#8230; my degree was in psychology. I worked, and then I did my master&#8217;s in computer science and then my PhD in human-computer interaction.</p>\n\n\n\n<p><strong>GEHRKE:</strong> That&#8217;s quite a change, right, from psychology into computer science, then.</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yes, yes. And I just, you know, I&#8217;d always just wanted to do computing, but when I was at school, it was &#8230; we had one computer in the school, and so it was, like, a computer at home or you don&#8217;t do computer science. So, you know, I didn&#8217;t do it.</p>\n\n\n\n<p><strong>GEHRKE: </strong>Right.</p>\n\n\n\n<p><strong>O’NEILL: </strong>So then as computers became more prominent, more available, you know, I was working in libraries, and they started computerizing, and I worked on that project, and then that led me to do a master&#8217;s. And so I was like, hey, this is the opportunity to really get into this area, and I loved it. It was fantastic. And Manchester&#8217;s computer science department is one of the top departments, and I had an amazing &#8230; Carole Goble was my thesis supervisor. She was absolutely amazing and strong for women in computing. But at the end of it, I was like, OK, so I didn&#8217;t want to do pure social science and I didn&#8217;t want to do pure computer science. What I want to do is do human-computer science, so where you really merge the two. And that&#8217;s how I got into HCI, and I think that&#8217;s where I started finding my favorite courses. You know, I loved the research methods. I loved those types of things.</p>\n\n\n\n<p><strong>GEHRKE:</strong> And what is your PhD about?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Ooh, it was very boring. [LAUGHTER] My PhD was in computer-supported cooperative work [CSCW], and &#8230;</p>\n\n\n\n<p><strong>GEHRKE:</strong> OK. Oh, yeah. Very relevant now, right?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yeah, very relevant now. And that was a really exciting time for CSCW, as well, because there were so many different labs. There were Sun Systems, there was Xerox, there was Microsoft—all doing really cool, like, collaborative technologies. So it seemed like a brilliant area to go into. But I was looking at, can we support networking events for businesses?</p>\n\n\n\n<p><strong>GEHRKE:</strong> Wow. Uh-huh …</p>\n\n\n\n<p><strong>O’NEILL: </strong>So it was just at the time of the first, you know, things like Webex and things, you know, the first collaborative seminar-y &#8230;</p>\n\n\n\n<p><strong>GEHRKE:</strong> Yeah, so you&#8217;re way ahead of the social networks, right, and everything, right?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yeah, yeah.</p>\n\n\n\n<p><strong>GEHRKE:</strong> And there was a whole conference at that point in time, right? CSCW, I think I remember. Wasn&#8217;t there &#8230;</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yes, yes, yes.</p>\n\n\n\n<p><strong>GEHRKE: </strong>So it was and still is, I think, a really big field.</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yes, it&#8217;s a, it&#8217;s a, it&#8217;s really interesting. And I think one of the things that&#8217;s interesting with the foundational models now is many of the things that people like me, HCI people, have been wanting to happen—&#8221;Oh, if only we can enable people to interact with technology like this&#8221;—are now suddenly possible, which is quite exciting.</p>\n\n\n\n<p><strong>GEHRKE:</strong> Yeah, so we&#8217;ll get to that in a little bit because I think, you know, as you said, the whole field of HCI is now changing with foundational models and what the interfaces are, will be. I think it&#8217;s a really interesting, deep research question right now. So, so, OK, so you got your PhD; you&#8217;re in Manchester. What&#8217;s the next step in your career? Where did you go next?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yeah, I actually got a job before I finished my PhD. So I took quite a long time to do my PhD. I think it was seven years in the end, partly because I was teaching. When I was doing—like, lecturing when I was doing my PhD, and I also had a job as a consultant occasionally, working with, I think, I worked with the Co-op Bank. I worked with some usability companies, and you could, I could make enough money to live for a term on, like, two weeks&#8217; consultancy because I didn&#8217;t have very high costs. [LAUGHS]</p>\n\n\n\n<p><strong>GEHRKE:</strong> Right. You lived as a grad student, right?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yes. Yeah. Yeah. And, actually, you know, I was living in Manchester. I was living in a squat, so I wasn&#8217;t paying any rent, [LAUGHS] so &#8230;</p>\n\n\n\n<p><strong>GEHRKE:</strong> Oh, really?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yes. So I didn&#8217;t have very many costs.</p>\n\n\n\n<p><strong>GEHRKE:</strong> OK.</p>\n\n\n\n<p><strong>O’NEILL:</strong> Which was very handy. So I didn&#8217;t have any real incentive to finish my PhD until I got a job, you know. When I finished my master&#8217;s, I looked at the job market, and with my computer science master&#8217;s, the main job was database manager, [LAUGHS] which didn&#8217;t appeal.</p>\n\n\n\n<p><strong>GEHRKE:</strong> That sounds now really interesting. [LAUGHTER]</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yeah. So I, actually, that&#8217;s why I ended up doing a PhD, because I was like, I don&#8217;t want to go back to work yet. You know, I&#8217;ve been working for five years before. So, so, yeah, I just was enjoying doing a PhD and doing pieces of work here and there. And then I got a job at Xerox in Cambridge, and then that&#8217;s when I got motivated to finish my PhD because working and doing a PhD at the same time is not much fun.</p>\n\n\n\n<p><strong>GEHRKE:</strong> Right, right. So you got your PhD, had your job lined up, and then you&#8217;re starting at Xerox. What were you doing in Xerox?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Human-computer interaction. Yeah, it was a really exciting time. There was so much going on in the industry. I was so delighted. It was like my dream job to be in industry and to maybe create cool interfaces and, you know, cool collaborative systems. So &#8230; and then they closed the lab [LAUGHS] within six months. It wasn&#8217;t my fault.</p>\n\n\n\n<p><strong>GEHRKE:</strong> So quickly?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Mm-hmm.</p>\n\n\n\n<p><strong>GEHRKE:</strong> Wow. And what did you do then? I mean, this is your first big job, and &#8230;</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yes &#8230;</p>\n\n\n\n<p><strong>GEHRKE:</strong> &#8230; such a quick setback.</p>\n\n\n\n<p><strong>O’NEILL:</strong> They offered me a job in their lab in France. So I stayed in the UK for a while and worked half in France, half in the UK, and then I shifted to France full time.</p>\n\n\n\n<p><strong>GEHRKE:</strong> OK. Oh, wow. So do you &#8230; where in France did you live then?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Grenoble.</p>\n\n\n\n<p><strong>GEHRKE:</strong> OK, yeah. In the middle of &#8230;</p>\n\n\n\n<p><strong>O’NEILL:</strong> In the French Alps.</p>\n\n\n\n<p><strong>GEHRKE:</strong> &#8230; the French Alps. Exactly. Beautiful place.</p>\n\n\n\n<p><strong>O’NEILL:</strong> Absolutely &#8230; yes. Yeah. Skiing, climbing, hiking. So much fun.</p>\n\n\n\n<p><strong>GEHRKE:</strong> And, OK, so you&#8217;re at Xerox PARC in the French Alps. What&#8217;s, what&#8217;s next?</p>\n\n\n\n<p><strong>O’NEILL:</strong> They were opening, Xerox was opening a research lab in India. And I&#8217;d always wanted to travel. You know, I&#8217;d always wanted &#8230; and I never really had the money or the opportunity to travel. So when they said they were opening it, I just went to my boss and said, hey, I don&#8217;t know what you&#8217;d want me to do, but if there&#8217;s any opportunities for me to do anything to help …</p>\n\n\n\n<p><strong>GEHRKE: </strong>Wow.</p>\n\n\n\n<p><strong>O’NEILL: </strong>… the opening of India, I&#8217;d love to. And I went out for a month and then I went out for three months.</p>\n\n\n\n<p><strong>GEHRKE:</strong> I mean, both of these sound like really bold steps to me. First of all, I mean, Grenoble is probably pure French speaking, right? And, I don&#8217;t know, did you have high school French or you were good &#8230; [LAUGHS]</p>\n\n\n\n<p><strong>O’NEILL:</strong> I had high school French, yes, and then we drove, we drove from the UK to Grenoble listening to &#8220;learn French&#8221; tapes [LAUGHS] …</p>\n\n\n\n<p><strong>GEHRKE:</strong> OK, wow … [LAUGHS]</p>\n\n\n\n<p><strong>O’NEILL: </strong>…in the car. Yeah.</p>\n\n\n\n<p><strong>GEHRKE:</strong> Wow. And that was enough then to get by with a daily &#8230;</p>\n\n\n\n<p><strong>O’NEILL:</strong> Actually, so it was great in France because they expect you to learn the language, so you have French lessons at work. And then, actually, I did an evening class, as well, that was paid for by work, a really intensive one-month, like two hours a night, every night of the week. And that really helped. Yeah, it was, it&#8217;s fantastic.</p>\n\n\n\n<p><strong>GEHRKE:</strong> Wow, that&#8217;s really great. And then, and then you took the even bigger step to move to India, right. How was that like, and what was your experience there?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yeah, India is just magical. You know, initially, I just went for one month, then three months, and it was just—the people, the culture, the work I was doing, the research I was doing was like no research &#8230; you know, I’d spent a lot of time in call centers around Europe doing studies, ethnographic studies, and designing technology. Lots of time looking at photocopiers because I was with Xerox. [LAUGHS] And then so going to India, suddenly, you know, I&#8217;m looking at social enterprises. I&#8217;m looking at all sorts of businesses and different ways of life and different people. And it was just so rich and so amazing that I was like, OK, I really want to do this. And that&#8217;s actually when I applied to Microsoft because Microsoft had the Technology for Emerging Markets group there, which is world-class research in that space. So I was like, OK, if I want to keep on doing this, then that&#8217;s what I&#8217;m going to apply to. And luckily enough, I got the job, and that&#8217;s how I joined Microsoft.</p>\n\n\n\n<p><strong>GEHRKE:</strong> Wow. So, so, OK, so you&#8217;re now at Microsoft in India. That was in Bangalore, right, where our research lab there is?</p>\n\n\n\n<p><strong>O’NEILL: </strong>Mm-hmm.</p>\n\n\n\n<p><strong>GEHRKE:</strong> And so what, what were you working on there for the next few years?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yeah. So initially, I looked at a few different things. I joined some existing projects. So I was on MEC, which was the educational platform, looking at whether we could bring the power of MOOCs [Massive Open Online Courses] to Indian education to improve the level of education because they have amazing colleges at the top, but, actually, the vast majority of students go to these intermediate colleges, and the teaching level really varies. And so the idea was, can you help with blended learning? Can you help the teachers teach better? That turns out to be really challenging. And, actually, the system ended up being used by the students to teach themselves.</p>\n\n\n\n<p><strong>GEHRKE:</strong> Oh, like for independent learning?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Mm-hmm. Mm-hmm. And that was really, so that was interesting, doing some studies there. I looked at &#8230; Indrani [Medhi Thies] had done an amazing project where they&#8217;d built &#8220;Facebook for Farmers.&#8221; So I did a study of that, which was really, really fun. And then I worked in financial inclusion, one of my big areas. I spent about five years working with auto-rickshaw drivers in Bangalore, designing technologies to help them understand the loans they&#8217;d taken out, which was really, really fun. They&#8217;re a very great community to work [with]. You don&#8217;t get any nonsense from an auto-rickshaw driver. [LAUGHS]</p>\n\n\n\n<p><strong>GEHRKE:</strong> Well, I was just thinking, what was it like to, like, live in India and just move there and start out there?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Uh, it was, I mean, it was fantastic. It&#8217;s a great place to live. The people are amazing. The food is amazing. Moving with Microsoft makes it very easy because Microsoft takes care of you when you move so you&#8217;re not, you know, some of the stresses that you might have around the move are taken care of. I had a young family. I had a 2-year-old son when we moved out there and within a year had another one, which was not 100 percent planned, because you don&#8217;t usually move to a new company and then have a baby. You&#8217;re like, oh, sorry. [LAUGHS] But that was all fine. Yeah.</p>\n\n\n\n<p><strong>GEHRKE:</strong> And, and, you know, you worked with all of these different communities in India, right. How did you connect to the communities? I mean, these were teachers …</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yeah, you need to, you really need to go with people, so you have to convince some organization that what you&#8217;re going to do is going to be beneficial to them and useful for them. And then if they&#8217;re trusted by the community, they give you access. And that&#8217;s really great because you do have access that you wouldn&#8217;t otherwise have. You know, if you&#8217;re really wanting to build technologies to support people, you really need to understand what they care about—what do they want help <em>with</em>?—and you only get that if you&#8217;ve got a trusted relationship with them. So we worked with, there was one organization that worked with the auto-rickshaw drivers&#8217; wives. It was about empowering women, and we got access to the drivers initially through that organization.</p>\n\n\n\n<p><strong>GEHRKE:</strong> That&#8217;s amazing. I mean, you know, I&#8217;ve visited India many times, but I can only imagine how it is to live there, actually. So do you have some of the stories of what is, sort of, most surprising for you given that you&#8217;ve lived there?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yeah … what&#8217;s most surprising? I think, so one thing is, one thing is people want to tell you what they think you want to hear. So if you&#8217;re lost, you need to ask quite a few people for directions and then make some sort of assessment about whether the person was just saying &#8220;yes, yes, that way&#8221; because he knew the way or &#8220;yes, yes that way&#8221; because he just didn&#8217;t want to tell you that he didn&#8217;t know. And so you have to, sort of, judge. [LAUGHS] So that&#8217;s one, like, useful piece of &#8230;</p>\n\n\n\n<p><strong>GEHRKE:</strong> So the first few times you went in the wrong direction? [LAUGHS]</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yes, exactly. And then you&#8217;re like, &#8220;But they said &#8230;&#8221;; you ask someone else, and they&#8217;re like, &#8220;No, it&#8217;s over there.&#8221; And then someone &#8230; so that&#8217;s … the most useful piece of advice I could give to anyone who&#8217;s visiting India, is when you cross the road, just find someone else who&#8217;s already crossing the road and cross with them.</p>\n\n\n\n<p><strong>GEHRKE:</strong> Because it&#8217;s so dangerous if you go by yourself potentially?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yes, yeah. You get used to it quite quickly, and there&#8217;s obviously something that changes in you when you&#8217;ve been there a while. You know, when you first go there, all the auto-rickshaw drivers are going to overcharge you and drive around the block twice and all of those things. And I find after about four to five weeks when you&#8217;ve been there, they know, like, there must be something that changes in your attitude because they actually know that you&#8217;re there longer term and you&#8217;re not going to take any nonsense.</p>\n\n\n\n<p><strong>GEHRKE:</strong> So, so do you behave differently? What&#8217;s the change there?</p>\n\n\n\n<p><strong>O’NEILL:</strong> I don&#8217;t know. That&#8217;s, I&#8217;ve tried to think about this, but I think, I don&#8217;t know, it must be just an air of confidence or an air of certainty or something. But, yeah, it&#8217;s like something just clicks or changes.</p>\n\n\n\n<p><strong>GEHRKE:</strong> That&#8217;s so interesting. Is it only for the drivers, or is it in other aspects of your life, as well, where, sort of, you get treated differently because you suddenly have become a native?</p>\n\n\n\n<p><strong>O’NEILL:</strong> I think you notice it most in the drivers because they&#8217;re the ones that you&#8217;re interacting so much with to get about, you know, to get &#8230; you&#8217;re always getting a tuk-tuk to go from here to there. And they really do, you know, if they can make extra money out of you, they <em>are</em> going to make extra money out of you.</p>\n\n\n\n<p><strong>GEHRKE:</strong> They smell it, that you&#8217;re a tourist.</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yeah, yeah, yes. [LAUGHS]</p>\n\n\n\n<p><strong>GEHRKE:</strong> And then so you were in India and then another opportunity came along. So tell us a little bit about that opportunity, where you ended up now.</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yes, yes. So when I heard that the ADCs were opening—the Africa Development Center, so our software engineering center in Nairobi and Lagos—I thought that that was a great time to pitch for research in Africa for Microsoft. It seemed like a bit of a hole in our portfolio. I have family connections to Africa. So, actually, one of the reasons for joining Microsoft was partly because I thought there might be opportunities eventually in Africa because we had a great Africa startup program, for example. So, you know, but there wasn&#8217;t any research there. And so when I heard the ADCs were open, I just put together a, like, pitch for setting up research in Africa within the ADCs, and, you know, all sorts of people really helped me hone that pitch. And then I flew at the end of February 2020. I flew &#8230;</p>\n\n\n\n<p><strong>GEHRKE:</strong> Oh, just right before the pandemic.</p>\n\n\n\n<p><strong>O’NEILL:</strong> Mm-hmm. I flew to &#8230; I was in Barcelona for a Future of Work event, and then I flew to Nairobi and then Lagos to meet the people who were running the ADCs and to think about where, which one I would want to set up research in if such a thing were to happen. And I did that. I decided that Nairobi was the right one. And when I went there, Jack Ngare ran the ADC, and he was so enthusiastic about having research there. So I did a pitch and got some funding <em>just</em>—I think if it had been two weeks later, I&#8217;m not sure. But, you know, it was just before we knew how bad COVID was going to be, so I was very lucky with timing.</p>\n\n\n\n<p><strong>GEHRKE:</strong> And, I mean, you&#8217;ve made these amazing moves throughout your career, right. You, sort of, raised your hand for India when the lab was open; now here in Africa. Why, and how? I&#8217;m just, I mean, so curious because people make the most unexpected turns in their careers from time to time. But it&#8217;s more like because, you know, they lose their current job or they, their manager moves away and they really think about their career. But you, like, raise your hand from time to time and make these really bold and amazing moves.</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yeah, I mean, life&#8217;s meant to be exciting, isn&#8217;t it?</p>\n\n\n\n<p><strong>GEHRKE: </strong>OK …<strong></strong></p>\n\n\n\n<p><strong>O’NEILL:</strong> I think. You know, life&#8217;s meant to be exciting. I love living in different places and, you know, as an ethnographer, as a person interested in human-computer interaction, it&#8217;s, like, those experiences are what help us innovate better and design things that are, like, taking another point of view, more creative, I think. Like, just sparks things in your, in your head. And, I mean, it&#8217;s so much fun. Like, I don&#8217;t understand why everyone doesn&#8217;t do it. [LAUGHS]</p>\n\n\n\n<p><strong>GEHRKE:</strong> So it&#8217;s just really amazing. So if I think about, you know, India, where you said, right, the experience for you was that the drivers were treating you suddenly differently. Did you have a similar experience in Africa, or what is one of the or a few of the defining experiences and stories there?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yeah, I think &#8230; so the animals are amazing in Kenya. They&#8217;ve done such an amazing job at conservation. I imagine that they would, you would only see, like, these big animals in the national parks, but—they&#8217;re not everywhere. They&#8217;re not going to be, you&#8217;re not going to find a hippo walking down the road in Nairobi. But they are all over the place. So you can go camping in Lake Naivasha, which is just an hour and a half from Nairobi, and I was camping with a friend, and the kids were in their tent, and my friend was in her tent, and I was just sitting by the fire. It&#8217;s about 10 o&#8217;clock. I said, yeah, I might go to bed in a minute. And then I just heard this snort, and I get up with my torch, and I look, and there&#8217;s a hippo, [LAUGHS] like, probably less than a meter and a half …</p>\n\n\n\n<p><strong>GEHRKE: </strong>Wow …</p>\n\n\n\n<p><strong>O’NEILL: </strong>… away from me. So I carefully went and sat back down by the fire and waited for a while before I moved. [LAUGHS]</p>\n\n\n\n<p><strong>GEHRKE:</strong> So are they dangerous in that aspect, if you&#8217;ve startled them or so &#8230; ?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yeah, I think &#8230; they say that you should never get between a hippo and the water. So, luckily, I was on the other side of the, [LAUGHS] of the hippo and the water. But they are <em>big</em>. I mean, they can be very grumpy.</p>\n\n\n\n<p><strong>GEHRKE:</strong> And so you should, just, shouldn&#8217;t startle them or &#8230; ? I&#8217;m just trying to understand&nbsp;what&#8217;s the recommended behavior. Don&#8217;t get between the hippo and the water.</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yes, that&#8217;s recommended, and don&#8217;t, yeah, don&#8217;t startle them, and just, you know, stay very, stay very calm. So, actually, when you&#8217;re camping, if you don&#8217;t have an electric fence around the campsite, then you shouldn&#8217;t come out of your tent at night. So don&#8217;t drink too much beer before you go to bed, [LAUGHTER] because it&#8217;s the &#8220;zip.&#8221; When you unzip it, you can really startle &#8230; If there&#8217;s any wild animals, lions, or whatever around, then you can really scare them. And you don&#8217;t want to scare a lion.</p>\n\n\n\n<p><strong>GEHRKE:</strong> Yeah, I was thinking, just, actually, about the lions or so, right. I mean, they could be probably even more dangerous than the hippos or, or not really?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Hippos are actually more dangerous than lions. Yeah, lions will generally not attack you. And apparently, the thing—I haven&#8217;t had to try this, I&#8217;m glad to say—but the thing you should do if you encounter a lion is just look them in the eye, and then they&#8217;ll go off.</p>\n\n\n\n<p><strong>GEHRKE:</strong> Stare them down.</p>\n\n\n\n<p><strong>O’NEILL: </strong>Mm-hmm.</p>\n\n\n\n<p><strong>GEHRKE:</strong> OK.</p>\n\n\n\n<p><strong>O’NEILL:</strong> I hope I never have to try that because they are quite scary … [LAUGHS]</p>\n\n\n\n<p><strong>GEHRKE:</strong> I hope I never have to do that but good advice …</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yes, yeah, yeah. I think hippos are more likely to charge at you. Like, a lion&#8217;s more likely to go off in the other direction.</p>\n\n\n\n<p><strong>GEHRKE:</strong> And what&#8217;s the daily life like, you know, living in Nairobi, right? I mean, is it, I mean, it must be very, very different from living in both India, as well as, you know, Great Britain or here.</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yeah. I mean it is very different. The traffic&#8217;s bad but not as crazy as India. Like, I drive in Kenya. I didn&#8217;t drive in India because it was a bit too scary with the bikes and everything. It&#8217;s a really, it&#8217;s a really nice pace, I think, in Nairobi. It&#8217;s a beautiful city. There&#8217;s nightlife, and there&#8217;s cafes and restaurants, but you&#8217;ve got countryside so close. You know, compared to Bangalore, it&#8217;s quite a small city. And the weather is amazing, and the people are really friendly and kind, and, you know, it&#8217;s just, it&#8217;s a very nice, it&#8217;s a very nice place to live.</p>\n\n\n\n<p><strong>GEHRKE:</strong> That&#8217;s amazing, and you now are leading the Microsoft Africa Research Institute there, right?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yes.</p>\n\n\n\n<p><strong>GEHRKE:</strong> What is the focus of the institute, and what are you studying there?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Mm-hmm. Yeah, we&#8217;re mainly focused on foundational models. It won&#8217;t be a surprise to anybody. [LAUGHS] Which actually, you know, it&#8217;s worked out very well for us because, you know, we have a mixed disciplinary team. We have HCI and AI and ML and data science.</p>\n\n\n\n<p><strong>GEHRKE:</strong> And all local?</p>\n\n\n\n<p><strong>O’NEILL:</strong> All local. Yeah. And, yeah, we&#8217;re looking at multilingual languages in models. So we&#8217;re working with MSR [Microsoft Research] India, thinking about how can you benchmark these models for different languages. And we&#8217;re thinking all the way along the scale from your high-resource, you know, French and German, to your mid-resource Swahili, Hindi, all the way to your low-resource languages because, you know, the vast majority of training data is in English. So we&#8217;ve been working a lot. That&#8217;s nice because we&#8217;re having, you know, in a very short amount of time, you know, four or five months, we&#8217;re having both scientific impact with papers but also product impact, working with the Copilot Language Globalization team as they&#8217;re rolling out Copilot in different languages.</p>\n\n\n\n<p><strong>GEHRKE:</strong> I see. So the research that you have will go into, let&#8217;s say, Word or PowerPoint or so to make it available in some of the languages from the continent.</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yes, exactly. Because it&#8217;s not just about translation. It&#8217;s also if you think about RAI, responsible AI, you know, a lot of that is language based. And so how do &#8230; you can&#8217;t just translate this to words. You have to find the right list of words in those languages. And then what about things like tone and stuff? So that&#8217;s one area. And then related to that, it&#8217;s in a much bigger space of equity, the models and equity. You know, what&#8217;s going to happen to the digital divide with these models? In some ways, you could imagine that they may be flattening it, but in other ways, they could be increasing it. So we really are trying to map out how … the different elements of the digital divide as it plays out in these models. Because you obviously have your traditional things like access to devices, access to, you know, infrastructure, and things like that. But there&#8217;s also the data divide. So not only is most of the training material in English; it&#8217;s also mostly from America and the Global North. So it embodies very particular world views. And if you think about data on Africa, data on Africa tends to be collected by particular organizations. So there&#8217;s lots of data on poverty and disease and forced migration and things like that. Not much data on, like, the stories, the creativity, wealth, innovation. So what does that mean? Even if the models can speak perfectly, which they can&#8217;t yet, but they&#8217;ll eventually get quite good at, you know, even smaller languages like Luo, if that model is just translating English content into Luo, that&#8217;s not necessarily what we want from a model. So there&#8217;s some really interesting questions there to be answered.</p>\n\n\n\n<p><strong>GEHRKE:</strong> Well, it seems to me like it&#8217;s clearly also a question of, like, getting the right kind of data. So where do you get the data, and how do you get the data?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yeah, that&#8217;s a big question. And it was already a challenge, you know, before these models. You know, many people have been working with Masakhane, which is one of the African NLP communities which is around creating datasets in African languages for training the models. So that was, you know, getting good quality training data is already a challenge. Sriram [Rajamani] from MSR India, though, was telling me of a really interesting project they&#8217;ve got going on in India with the Indian government where they are trying to collect data from each region of India so that they can use it to train the OpenAI models, which would be really cool. And we should think about, is that what we can do for different African countries and contexts?</p>\n\n\n\n<p><strong>GEHRKE:</strong> Exactly. It seems to be very much like a citizen science project, right, where you, sort of, involve the citizens that speak different dialects and then involve them in collecting the right kind of data.</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yeah, yeah. And maybe collecting the stories, you know, and the cultural attributes and assets from different places.</p>\n\n\n\n<p><strong>GEHRKE:</strong> That&#8217;ll be really, really exciting probably also about preservation of the culture and history, right.</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yes, yes. But challenging.</p>\n\n\n\n<p><strong>GEHRKE:</strong> But challenging. [LAUGHTER]</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yeah.</p>\n\n\n\n<p><strong>GEHRKE:</strong> So that&#8217;s one big aspect of the work. Anything else that&#8217;s happening there?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yeah. So we&#8217;re doing a lot of work, you&#8217;ll be unsurprised to hear, on Future of Work and AI. And so we&#8217;ve got a project on modern work and LLMs, so looking at the work that enterprise workers, frontline and knowledge workers, are doing and then what bits of their job they would like to get rid of if they could and what bits they would keep and how we can use LLMs to support them. And we&#8217;ve also, like, Maxamed [Axmed] on my team, also worked with The Garage to train them up in foundational models, both the LLMs and the vision models, and then they&#8217;ve introduced them to a whole load of small businesses in Kenya.</p>\n\n\n\n<p><strong>GEHRKE:</strong> Oh, wow.</p>\n\n\n\n<p><strong>O’NEILL:</strong> So that&#8217;s really interesting. You got everyone from like car salespeople to lawyers who are now using, like, LLMs as part of their everyday work, which is amazing.</p>\n\n\n\n<p><strong>GEHRKE:</strong> As part of like composing messages or part of &#8230; what&#8217;s &#8230;</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yeah. Writing contracts, sales documents for cars, all sorts of really interesting things.</p>\n\n\n\n<p><strong>GEHRKE:</strong> Oh, wow.</p>\n\n\n\n<p><strong>O’NEILL:</strong> So we&#8217;re going to go out and look at what they&#8217;re doing and think about how, you know, what else is needed, what, what more do they need.</p>\n\n\n\n<p><strong>GEHRKE:</strong> What&#8217;s the prevalent form factor in terms of if I think about, like, a computer there? Is it my, is it a mobile phone? Is it a tablet?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yeah.</p>\n\n\n\n<p><strong>GEHRKE:</strong> It&#8217;s a mobile phone?</p>\n\n\n\n<p><strong>O’NEILL:</strong> It&#8217;s a mobile phone. Yeah.</p>\n\n\n\n<p><strong>GEHRKE:</strong> So you have to rethink also, probably, all the interfaces.</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yes, I mean &#8230;&nbsp;</p>\n\n\n\n<p><strong>GEHRKE:</strong> You mentioned that early on, right, as you think about the next generation of HCI <em>with AI in it</em>, right.</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yes, yes. I mean conversational interfaces. The idea that you can talk to your phone or enter existing text, you know. If you look at small businesses, a lot of their interactions with customers are on chat. If you can enter that chat into an LLM and extract structured data from it, then suddenly you&#8217;ve got all this data that&#8217;s been lost to the business becomes usable. So it&#8217;s a really exciting space, and I think voice interfaces are going to become really, really, really big. And that&#8217;s why there&#8217;s opportunities for leapfrogging, because suddenly everyone with a mobile phone potentially has a really powerful office productivity tool in their hand and can do things &#8230; you know, many of the small businesses, they don&#8217;t employ a designer; they don&#8217;t employ an accountant. But now they could maybe have an accountant or a designer in their pocket, which enables them to do more, which is definitely the more positive side of the future of work than some of the &#8230;</p>\n\n\n\n<p><strong>GEHRKE:</strong> Right. You know, this whole enablement story of people is just really amazing, what you can do with LLMs and especially with voice interfaces, as well. Let me conclude maybe with a question about your career. I mean, it seems like you&#8217;ve always amazingly managed to somewhat align your career moves with your passion. You moved to India because you&#8217;re just excited to live in India. You moved then to, you know, Microsoft Research, but then you moved to Africa again for, what I hear, is a little bit the adventure, as well, right?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yes.</p>\n\n\n\n<p><strong>GEHRKE:</strong> So what&#8217;s your advice for people who want to, sort of, align these two and who want to not only work but also want to work on something they&#8217;re really passionate about? How do you manage to create that alignment?</p>\n\n\n\n<p><strong>O’NEILL:</strong> That is a good question. I don&#8217;t know. It just, sort of, happens. I mean, I think you have to, you have to be passionate about it; you have to talk about it and decide what you want to do. You know, I never really imagined MARI would happen. But I just started talking to people, and people were saying, before I did the pitch, people were saying to me, oh, what would you like to do in five years, Jacki? And I was like, oh, you know what? If I had my way, I&#8217;d love to run a research center in Africa. And then within a couple of years … it was nothing more than an idea in my head. So I think that you have to have the ideas, verbalize it, and maybe it can happen.</p>\n\n\n\n<p><strong>GEHRKE:</strong> And why a research center in Africa? What&#8217;s personal for you there?</p>\n\n\n\n<p><strong>O’NEILL:</strong> So my children are African; my children are Cameroonian. So I wanted them to grow, spend some time on the continent, and, you know, as a family, we&#8217;d always had that idea of moving to the continent eventually. So that was part, that was a personal motivation in there as well as the passion. Yeah.</p>\n\n\n\n<p><strong>GEHRKE:</strong> So it&#8217;s, well, sort of, the confluence of, I guess, opportunity but then also drive on your side? Because that&#8217;s what I&#8217;ve heard. Very often in careers, that it&#8217;s not only about, well, this is what I finally want to do but also watching out for that opportunity.</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yes.</p>\n\n\n\n<p><strong>GEHRKE:</strong> So it seems like that played a big role here, as well. And so when you heard about, you know, that there was an Africa Development Center, how did you, what were your next steps then? I mean, you must have been excited, but you also had to take some action.</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yeah, I mean, I created, [LAUGHS] I created a small pitch, a small set of slides, and then I just started talking to everybody I knew who was doing anything. I didn&#8217;t have any contact with the ADCs.</p>\n\n\n\n<p><strong>GEHRKE:</strong> So you created that energy and excitement about it?</p>\n\n\n\n<p><strong>O’NEILL:</strong> I just started to, you know, every time anyone would come to India, you know, I was just like, oh, this is what I&#8217;d like to do. And you just almost talk it into being, I think.</p>\n\n\n\n<p><strong>GEHRKE:</strong> And were there some setbacks, or was it just like a straight line from, sort of, the excitement all the way up to realization?</p>\n\n\n\n<p><strong>O’NEILL:</strong> No, I mean, I didn&#8217;t, I don&#8217;t think I ever really imagined it would happen, you know. But you&#8217;re just doing it, and you&#8217;re plugging away, and then taking the, you know, taking the advice of people.</p>\n\n\n\n<p><strong>GEHRKE:</strong> Really an awesome story. So maybe as a last question, where do you see the center being in like three to five years? I mean, you&#8217;re starting off right now, but I&#8217;m sure you have really big ambitions for the center, and there&#8217;s so much to do on the whole continent.</p>\n\n\n\n<p><strong>O’NEILL:</strong> No, absolutely. I think that I have a few ambitions. So the most important, I think, I want it to be really established as this thing that&#8217;s really beneficial to Microsoft, that Microsoft is like, really, &#8220;Yeah, the guys at MARI, they&#8217;re doing great research. We really like them.&#8221; So that it, sort of, exists without me, you know. At the moment, I think I&#8217;m the driver of it. I would …</p>\n\n\n\n<p><strong>GEHRKE:</strong> So you want to grow the next generation that is basically going to be the next generation of leaders?</p>\n\n\n\n<p><strong>O’NEILL:</strong> Yes, exactly, exactly. And then I think also grow, I would love to help in growing Microsoft&#8217;s market in Africa. We don&#8217;t have a particularly big market in Africa, but I think there&#8217;s a lot of opportunity, especially now with these, with these large language models. I think that we &#8230; so that would be really exciting, you know, if we can help. I don&#8217;t see our success only being about growing the African market, but I think it&#8217;s part of what we can do, and if we can grow that market, as well as do research that&#8217;s relevant for Redmond and relevant globally, that&#8217;s really, that&#8217;s really exciting, I think, you know. So everything we do, I think, has to have a relevance globally. And I think, you know, at the beginning I was talking about different ways of viewing the world and how that leads to innovation. I think by having researchers who are African, based in Africa, doing this great research, we can create better products for everyone.</p>\n\n\n\n<p><strong>GEHRKE:</strong> That&#8217;s such a great finishing note. Thank you so much for the great conversation, Jacki.</p>\n\n\n\n<p><strong>O’NEILL:</strong> Thank you, Johannes. It&#8217;s been fun.</p>\n\n\n\n<p>[MUSIC]</p>\n\n\n\n<p>To learn more about Jacki or to see photos of Jacki living and working abroad, visit <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"http://aka.ms/ResearcherStories\">aka.ms/ResearcherStories<span class=\"sr-only\"> (opens in new tab)</span></a>.</p>\n\n\n\n<p>[MUSIC FADES]</p>\n\n\t\t\t\t</span>\n\t\t\t</div>\n\t\t\t<button\n\t\t\t\tclass=\"action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle\"\n\t\t\t\taria-expanded=\"false\"\n\t\t\t\tdata-show-less-text=\"Show less\"\n\t\t\t\ttype=\"button\"\n\t\t\t\taria-controls=\"show-more-show-less-toggle-2\"\n\t\t\t\taria-label=\"Show more content\"\n\t\t\t\tdata-alternate-aria-label=\"Show less content\">\n\t\t\t\tShow more\t\t\t</button>\n\t\t</div>\n\t</div>\n</div>\n</div>\n<span id=\"label-external-link\" class=\"sr-only\" aria-hidden=\"true\">Opens in a new tab</span>",
            "protected": false
        },
        "excerpt": {
            "rendered": "<p>Jacki O&#8217;Neill saw an opportunity to expand Microsoft research efforts to Africa. She now leads Microsoft Research Africa, Nairobi (formerly MARI). O&#8217;Neill talks about the choices that got her there, the lab’s impact, and how living abroad is good for innovation. </p>\n",
            "protected": false
        },
        "author": 37583,
        "featured_media": 1021107,
        "comment_status": "closed",
        "ping_status": "closed",
        "sticky": false,
        "template": "",
        "format": "standard",
        "meta": {
            "msr-url-field": "https://player.blubrry.com/id/131869304",
            "msr-podcast-episode": "",
            "msrModifiedDate": "",
            "msrModifiedDateEnabled": false,
            "ep_exclude_from_search": false,
            "footnotes": ""
        },
        "categories": [
            240054
        ],
        "tags": [],
        "research-area": [
            13556,
            13554,
            13559,
            13568
        ],
        "msr-region": [],
        "msr-event-type": [],
        "msr-post-option": [
            243990
        ],
        "msr-impact-theme": [],
        "msr-promo-type": [],
        "msr-podcast-series": [
            268149
        ],
        "msr_event_details": {
            "start": "",
            "end": "",
            "location": ""
        },
        "podcast_url": "https://player.blubrry.com/id/131869304",
        "podcast_episode": "",
        "msr_research_lab": [
            1021599
        ],
        "msr_impact_theme": [],
        "related-publications": [],
        "related-downloads": [],
        "related-videos": [],
        "related-academic-programs": [],
        "related-groups": [
            371909,
            643845
        ],
        "related-projects": [],
        "related-events": [
            999417
        ],
        "related-researchers": [
            {
                "type": "user_nicename",
                "value": "Johannes Gehrke",
                "user_id": 32364,
                "display_name": "Johannes Gehrke",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/johannes/\" aria-label=\"Visit the profile page for Johannes Gehrke\">Johannes Gehrke</a>",
                "is_active": false,
                "last_first": "Gehrke, Johannes",
                "people_section": 0,
                "alias": "johannes"
            },
            {
                "type": "user_nicename",
                "value": "Jacki O&#039;Neill",
                "user_id": 32172,
                "display_name": "Jacki O&#039;Neill",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/jaoneil/\" aria-label=\"Visit the profile page for Jacki O&#039;Neill\">Jacki O&#039;Neill</a>",
                "is_active": false,
                "last_first": "O'Neill, Jacki",
                "people_section": 0,
                "alias": "jaoneil"
            }
        ],
        "msr_type": "Post",
        "featured_image_thumbnail": "<img width=\"960\" height=\"540\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki-ONeill_WYS_Hero_Feature_1400x788-960x540.png\" class=\"img-object-cover\" alt=\"Circle photo of Jacki O&#039;Neill, director of the Microsoft Africa Research Institute (MARI), with a microphone in the corner on a blue and green gradient background\" decoding=\"async\" loading=\"lazy\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki-ONeill_WYS_Hero_Feature_1400x788-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki-ONeill_WYS_Hero_Feature_1400x788-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki-ONeill_WYS_Hero_Feature_1400x788-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki-ONeill_WYS_Hero_Feature_1400x788-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki-ONeill_WYS_Hero_Feature_1400x788-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki-ONeill_WYS_Hero_Feature_1400x788-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki-ONeill_WYS_Hero_Feature_1400x788-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki-ONeill_WYS_Hero_Feature_1400x788-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki-ONeill_WYS_Hero_Feature_1400x788-1280x720.png 1280w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/Jacki-ONeill_WYS_Hero_Feature_1400x788.png 1400w\" sizes=\"(max-width: 960px) 100vw, 960px\" />",
        "byline": "<a href=\"https://www.microsoft.com/en-us/research/people/johannes/\" title=\"Go to researcher profile for Johannes Gehrke\" aria-label=\"Go to researcher profile for Johannes Gehrke\" data-bi-type=\"byline author\" data-bi-cN=\"Johannes Gehrke\">Johannes Gehrke</a> and <a href=\"https://www.microsoft.com/en-us/research/people/jaoneil/\" title=\"Go to researcher profile for Jacki O&#039;Neill\" aria-label=\"Go to researcher profile for Jacki O&#039;Neill\" data-bi-type=\"byline author\" data-bi-cN=\"Jacki O&#039;Neill\">Jacki O&#039;Neill</a>",
        "formattedDate": "May 16, 2024",
        "formattedExcerpt": "Jacki O&#039;Neill saw an opportunity to expand Microsoft research efforts to Africa. She now leads Microsoft Research Africa, Nairobi (formerly MARI). O&#039;Neill talks about the choices that got her there, the lab’s impact, and how living abroad is good for innovation.",
        "_links": {
            "self": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1021077"
                }
            ],
            "collection": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts"
                }
            ],
            "about": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/types/post"
                }
            ],
            "author": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/users/37583"
                }
            ],
            "replies": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/comments?post=1021077"
                }
            ],
            "version-history": [
                {
                    "count": 29,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1021077/revisions"
                }
            ],
            "predecessor-version": [
                {
                    "id": 1034418,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1021077/revisions/1034418"
                }
            ],
            "wp:featuredmedia": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/media/1021107"
                }
            ],
            "wp:attachment": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/media?parent=1021077"
                }
            ],
            "wp:term": [
                {
                    "taxonomy": "category",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/categories?post=1021077"
                },
                {
                    "taxonomy": "post_tag",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/tags?post=1021077"
                },
                {
                    "taxonomy": "msr-research-area",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/research-area?post=1021077"
                },
                {
                    "taxonomy": "msr-region",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-region?post=1021077"
                },
                {
                    "taxonomy": "msr-event-type",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-event-type?post=1021077"
                },
                {
                    "taxonomy": "msr-post-option",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-post-option?post=1021077"
                },
                {
                    "taxonomy": "msr-impact-theme",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-impact-theme?post=1021077"
                },
                {
                    "taxonomy": "msr-promo-type",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-promo-type?post=1021077"
                },
                {
                    "taxonomy": "msr-podcast-series",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-podcast-series?post=1021077"
                }
            ],
            "curies": [
                {
                    "name": "wp",
                    "href": "https://api.w.org/{rel}",
                    "templated": true
                }
            ]
        }
    },
    {
        "id": 1032900,
        "date": "2024-05-15T11:12:21",
        "date_gmt": "2024-05-15T18:12:21",
        "guid": {
            "rendered": "https://www.microsoft.com/en-us/research/?p=1032900"
        },
        "modified": "2024-05-17T11:50:56",
        "modified_gmt": "2024-05-17T18:50:56",
        "slug": "research-focus-week-of-may-13-2024",
        "status": "publish",
        "type": "post",
        "link": "https://www.microsoft.com/en-us/research/blog/research-focus-week-of-may-13-2024/",
        "title": {
            "rendered": "Research Focus: Week of May 13, 2024"
        },
        "content": {
            "rendered": "\n<figure class=\"wp-block-pullquote\"><blockquote><p><em class=\"\">Welcome to Research Focus, a series of blog posts that highlights notable publications, events, code/datasets, new hires and other milestones from across the research community at Microsoft.</em></p></blockquote></figure>\n\n\n\n<figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"576\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-1024x576.png\" alt=\"Research Focus: May 13, 2024\" class=\"wp-image-1033017\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-1280x720.png 1280w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1.png 1400w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /></figure>\n\n\n\n<h3 class=\"wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-a584a2137da4151ecbde93fba771f798\" id=\"new-research\">NEW RESEARCH</h3>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"injecting-new-knowledge-into-large-language-models-via-supervised-fine-tuning\">Injecting New Knowledge into Large Language Models via Supervised Fine-Tuning&nbsp;</h2>\n\n\n\n<p>Large language models (LLMs) have shown remarkable performance in generating text similar to that created by people, proving to be a valuable asset across various applications. However, adapting these models to incorporate new, out-of-domain knowledge remains a challenge, particularly for facts and events that occur after the model’s training knowledge cutoff date.</p>\n\n\n\n<p>In a recent paper: <a href=\"https://www.microsoft.com/en-us/research/publication/injecting-new-knowledge-into-large-language-models-via-supervised-fine-tuning/\" target=\"_blank\" rel=\"noreferrer noopener\">Injecting New Knowledge into Large Language Models via Supervised Fine-Tuning</a>, researchers from Microsoft investigate the effectiveness of supervised fine-tuning (SFT) as a method for knowledge injection in LLMs, specifically focusing on recent sporting events. They compare different dataset generation strategies—token-based and fact-based scaling—to create training data that helps the model learn new information. Their experiments on GPT-4 demonstrate that while token-based scaling can lead to improvements in Q&A accuracy, it may not provide uniform coverage of new knowledge. Fact-based scaling, on the other hand, offers a more systematic approach to ensure even coverage across all facts. The researchers present a novel dataset generation process that leads to more effective knowledge ingestion through SFT, and results show considerable performance improvements in Q&A tasks related to out-of-domain knowledge.&nbsp;</p>\n\n\n\n<div class=\"wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-2 wp-block-buttons-is-layout-flex\">\n<div class=\"wp-block-button is-style-outline\"><a data-bi-type=\"button\" class=\"wp-block-button__link wp-element-button\" href=\"https://www.microsoft.com/en-us/research/publication/injecting-new-knowledge-into-large-language-models-via-supervised-fine-tuning/\">Read the paper</a></div>\n</div>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity is-style-dots\"/>\n\n\n\n<h3 class=\"wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-a584a2137da4151ecbde93fba771f798\" id=\"new-research\">NEW RESEARCH</h3>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"hh\">A Reflection on Human-Notebook Experiences in the Era of AI</h2>\n\n\n\n<p>Computational notebooks provide an interactive way to work with data. They have been widely used by data professionals to write code, explore data, and generate visualizations, all in one document. Previous research has revealed unique pain points around the user experience in computational notebooks. However, as AI tools like ChatGPT or Copilot have emerged, it is unclear whether these pain points have been reduced or changed, or whether new pain points have arisen. Due to the fast pace of advances in AI technology, most of the development of new AI tools has been primarily driven by technology and not by user experience.</p>\n\n\n\n<p>In a recent paper: <a href=\"https://www.microsoft.com/en-us/research/publication/a-reflection-on-human-notebook-experiences-in-the-era-of-ai/\" target=\"_blank\" rel=\"noreferrer noopener\">A Reflection on Human-Notebook Experiences in the Era of AI</a>, researchers from Microsoft summarize literature on how new AI technology has impacted human-notebook interaction and human-computer interaction (HCI) paradigms, new challenges and user behavior around using AI assistants, and recent research on AI assistants in computational notebook scenarios. They outline gaps in existing literature and suggest a future focus on improving macro human-notebook experiences throughout a user’s workflow, measuring and quantifying the value of AI systems, and establishing a set of standards and best practices for AI tools.</p>\n\n\n\n<div class=\"wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-3 wp-block-buttons-is-layout-flex\">\n<div class=\"wp-block-button is-style-outline\"><a data-bi-type=\"button\" class=\"wp-block-button__link wp-element-button\" href=\"https://www.microsoft.com/en-us/research/publication/a-reflection-on-human-notebook-experiences-in-the-era-of-ai/\">Read the paper</a></div>\n</div>\n\n\n\n\t<div class=\"border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide\" data-bi-aN=\"promo\" data-bi-id=\"999693\">\n\t\t\n\n\t\t<p class=\"msr-promo__label text-gray-800 text-center text-uppercase\">\n\t\t<span class=\"px-4 bg-white display-inline-block font-weight-semibold small\">Spotlight: Event Series</span>\n\t</p>\n\t\n\t<div class=\"row pt-3 pb-4 align-items-center\">\n\t\t\t\t\t\t<div class=\"msr-promo__media col-12 col-md-5\">\n\t\t\t\t<a class=\"bg-gray-300\" href=\"https://researchforum.microsoft.com/?OCID=msr_researchforum_MCR_Blog_Promo\" aria-label=\"Microsoft Research Forum\" data-bi-cN=\"Microsoft Research Forum\" target=\"_blank\">\n\t\t\t\t\t<img decoding=\"async\" class=\"w-100 display-block\" src=\"https://www.microsoft.com/en-us/research/uploads/prod/2024/01/MRF-24_WebImage_1400x788.png\" alt=\"various abstract 3D shapes on a light blue background\" />\n\t\t\t\t</a>\n\t\t\t</div>\n\t\t\t\n\t\t\t<div class=\"msr-promo__content p-3 px-5 col-12 col-md\">\n\n\t\t\t\t\t\t\t\t\t<h2 class=\"h4\">Microsoft Research Forum</h2>\n\t\t\t\t\n\t\t\t\t\t\t\t\t<p class=\"large\">Join us for a continuous exchange of ideas about research in the era of general AI. Watch Episodes 1 & 2 on-demand.</p>\n\t\t\t\t\n\t\t\t\t\t\t\t\t<div class=\"wp-block-buttons justify-content-center justify-content-md-start\">\n\t\t\t\t\t<div class=\"wp-block-button\">\n\t\t\t\t\t\t<a href=\"https://researchforum.microsoft.com/?OCID=msr_researchforum_MCR_Blog_Promo\" class=\"btn btn-brand glyph-append glyph-append-chevron-right\" aria-label=\"Register for series\" data-bi-cN=\"Microsoft Research Forum\" target=\"_blank\">\n\t\t\t\t\t\t\tRegister for series\t\t\t\t\t\t</a>\n\t\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t\t\t\t</div><!--/.msr-promo__content-->\n\t</div><!--/.msr-promo__inner-wrap-->\n<span id=\"label-external-link\" class=\"sr-only\" aria-hidden=\"true\">Opens in a new tab</span>\t</div><!--/.msr-promo-->\n\t\n\n\n<h3 class=\"wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-a584a2137da4151ecbde93fba771f798\" id=\"new-research\">NEW RESEARCH</h3>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"hh\">Jacdac: Service-Based Prototyping of Embedded Systems</h2>\n\n\n\n<p>The traditional approach to programming embedded systems is monolithic: firmware on a microcontroller contains both application code and the drivers needed to communicate with sensors and actuators, using low-level protocols such as I2C, SPI, and RS232. In comparison, software development for the cloud has moved to a service-based development and operation paradigm: a service provides a discrete unit of functionality that can be accessed remotely by an application, or other service, but is independently managed and updated.</p>\n\n\n\n<p>In a recent paper: <a href=\"https://www.microsoft.com/en-us/research/publication/jacdac-pldi2024/\" target=\"_blank\" rel=\"noreferrer noopener\">Jacdac: Service-Based Prototyping of Embedded Systems<span class=\"sr-only\"> (opens in new tab)</span></a>, researchers from Microsoft propose, design, implement, and evaluate a service-based approach to prototyping embedded systems called <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://aka.ms/jacdac\" target=\"_blank\" rel=\"noreferrer noopener\">Jacdac<span class=\"sr-only\"> (opens in new tab)</span></a>. Jacdac defines a service specification language, designed especially for embedded systems, along with a host of specifications for a variety of sensors and actuators. With Jacdac, each sensor/actuator in a system is paired with a low-cost microcontroller that advertises the services that represent the functionality of the underlying hardware over an efficient and low-cost single-wire bus protocol. A separate microcontroller executes the user’s application program, which is a client of the Jacdac services on the bus.&nbsp;</p>\n\n\n\n<p>Three Jacdac kits, comprising over twenty modules, have been produced by third-party manufacturers: <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://www.kittenbot.cc/\" target=\"_blank\" rel=\"noreferrer noopener\">KittenBot<span class=\"sr-only\"> (opens in new tab)</span></a> and <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://forwardedu.com/\">Forward Education<span class=\"sr-only\"> (opens in new tab)</span></a>.</p>\n\n\n\n<div class=\"wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-4 wp-block-buttons-is-layout-flex\">\n<div class=\"wp-block-button is-style-outline\"><a data-bi-type=\"button\" class=\"wp-block-button__link wp-element-button\" href=\"https://www.microsoft.com/en-us/research/publication/jacdac-pldi2024/\">Read the paper</a></div>\n</div>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity is-style-dots\"/>\n\n\n\n<h3 class=\"wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-a584a2137da4151ecbde93fba771f798\" id=\"new-research\">NEW RESEARCH</h3>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"hh\">PARIKSHA: A Scalable, Democratic, Transparent Evaluation Platform for Assessing Indic Large Language Models</h2>\n\n\n\n<p>Evaluation of multilingual LLMs is challenging due to a variety of factors – the lack of benchmarks with sufficient linguistic diversity, contamination of popular benchmarks into LLM pre-training data, and the lack of local, cultural nuances in translated benchmarks. Hence, it is difficult to extensively evaluate LLMs in a multilingual setting, leading to lack of fair comparisons between models and difficulties in replicating the evaluation setup used by some models. Recently, several Indic (Indian language) LLMs have been created to help build more locally and culturally relevant LLMs.</p>\n\n\n\n<p>In a recent paper: <a href=\"https://www.microsoft.com/en-us/research/publication/pariksha-a-scalable-democratic-transparent-evaluation-platform-for-assessing-indic-large-language-models/\" target=\"_blank\" rel=\"noreferrer noopener\">PARIKSHA: A Scalable, Democratic, Transparent Evaluation Platform for Assessing Indic Large Language Models</a>, researchers from Microsoft present an evaluation framework, which is the first comprehensive evaluation of Indic LLMs using a combination of human and LLM-based evaluation. The researchers conduct a total of 90,000 human evaluations and 50,000 LLM-based evaluations of 29 models to present leaderboards for 10 Indic languages. Pariksha provides inclusive evaluation by engaging a community of workers that represent India’s large and diverse workforce and also serves as a research platform for improving the process of evaluation. For transparency on the process, the evaluation artifacts will be released. Conducting Pariksha at regular intervals, the researchers aim to enable models to improve over time with insights and artifacts from their evaluations.&nbsp;</p>\n\n\n\n<div class=\"wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-5 wp-block-buttons-is-layout-flex\">\n<div class=\"wp-block-button is-style-outline\"><a data-bi-type=\"button\" class=\"wp-block-button__link wp-element-button\" href=\"https://www.microsoft.com/en-us/research/publication/pariksha-a-scalable-democratic-transparent-evaluation-platform-for-assessing-indic-large-language-models/\">Read the paper</a></div>\n</div>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity is-style-dots\"/>\n\n\n\n<h3 class=\"wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-a584a2137da4151ecbde93fba771f798\" id=\"new-research\">NEW RESEARCH</h3>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"hh\">Tinker, Tailor, Configure, Customize: The Articulation Work of Customizing AI Fairness Checklists</h2>\n\n\n\n<p>Many responsible AI resources, such as toolkits, playbooks, and checklists, have been developed to support AI practitioners in identifying, measuring, and mitigating potential fairness-related harms. These resources are often designed to be general purpose, in order to address a variety of use cases, domains, and deployment contexts. However, this can lead to decontextualization, where such resources lack the level of relevance or specificity needed to use them.</p>\n\n\n\n<p>To understand how AI practitioners might contextualize one such resource, an AI fairness checklist, for their particular use cases, domains, and deployment contexts, researchers from Microsoft conducted a retrospective contextual inquiry with 13 AI practitioners from seven organizations. In a recent paper: <a href=\"https://www.microsoft.com/en-us/research/publication/tinker-tailor-configure-customize-the-articulation-work-of-customizing-ai-fairness-checklists/\" target=\"_blank\" rel=\"noreferrer noopener\">Tinker, Tailor, Configure, Customize: The Articulation Work of Customizing AI Fairness Checklists</a>, they identify how contextualizing this checklist introduces new forms of work for AI practitioners and other stakeholders, while opening up new sites for negotiation and contestation of values in AI. The researchers also identify how the contextualization process may help AI practitioners develop a shared language around AI fairness. They also identify dynamics related to ownership over this process that suggest larger issues of accountability in responsible AI work.&nbsp;</p>\n\n\n\n<div class=\"wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-6 wp-block-buttons-is-layout-flex\">\n<div class=\"wp-block-button is-style-outline\"><a data-bi-type=\"button\" class=\"wp-block-button__link wp-element-button\" href=\"https://www.microsoft.com/en-us/research/publication/tinker-tailor-configure-customize-the-articulation-work-of-customizing-ai-fairness-checklists/\">Read the paper</a></div>\n</div>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity is-style-dots\"/>\n\n\n\n<h3 class=\"wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-a584a2137da4151ecbde93fba771f798\" id=\"new-research\">NEW RESEARCH</h3>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"hh\">MS MARCO Web Search: A Large-scale Information-rich Web Dataset with Millions of Real Click Labels</h2>\n\n\n\n<p>LLMs are becoming indispensable tools for many creative and information related tasks, but they still come with limitations, including a tendency to fabricate content. State-of-the-art algorithms pair the LLM with an external, dynamically updated knowledge base to ground the LLM’s answers and provide up-to-date information. However, these techniques require large amounts of relevant, labeled training data that have not previously been publicly available.&nbsp;</p>\n\n\n\n<p>In a recent paper: <a href=\"https://www.microsoft.com/en-us/research/publication/ms-marco-web-search-a-large-scale-information-rich-web-dataset-with-millions-of-real-click-labels/\" target=\"_blank\" rel=\"noreferrer noopener\">MS MARCO Web Search: A Large-scale Information-rich Web Dataset with Millions of Real Click Labels</a> presented at the 2024 ACM Web Conference, researchers from Microsoft introduce a novel dataset that closely mimics real-world web document and query distribution. MS MARCO Web Search contains 10 million unique queries across 93 languages with millions of relevant labeled query-document pairs. It uses ClueWeb22’s 10 billion high-quality web pages as the document corpus and provides rich information for various kinds of downstream tasks.&nbsp;</p>\n\n\n\n<p>This dataset unlocks several new research directions that previous datasets cannot well support, including generic end-to-end neural indexer models, generic embedding models, and next generation information access systems with LLMs. MS MARCO Web Search offers a retrieval benchmark with three web scale retrieval challenge tasks, each with automatic evaluation and leaderboard. These tasks demand innovation in both machine learning and information retrieval systems. The researchers intend for MS MARCO Web Search to lay the groundwork for future advancements in AI and systems research.</p>\n\n\n\n<div class=\"wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-7 wp-block-buttons-is-layout-flex\">\n<div class=\"wp-block-button is-style-fill-github\"><a data-bi-type=\"button\" class=\"wp-block-button__link wp-element-button\" href=\"https://github.com/microsoft/MS-MARCO-Web-Search\">View dataset</a></div>\n\n\n\n<div class=\"wp-block-button is-style-outline\"><a data-bi-type=\"button\" class=\"wp-block-button__link wp-element-button\" href=\"https://www.microsoft.com/en-us/research/publication/ms-marco-web-search-a-large-scale-information-rich-web-dataset-with-millions-of-real-click-labels/\">Read the paper</a></div>\n</div>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity is-style-dots\"/>\n\n\n\n<h3 class=\"wp-block-heading h6 has-blue-color has-text-color has-link-color wp-elements-56323e1c55299b34125129c842d8b7cd\" id=\"new-research\">VIDEO</h3>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"ai-case-studies-for-natural-science-research-with-bonnie-kruft\">AI Case Studies for Natural Science Research with Bonnie Kruft</h2>\n\n\n\n<p>Among the stunning changes and disruptions driven by AI, one of the most significant is the impact on scientific discovery. In her presentation at <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://event.technologyreview.com/emtech-digital-us-2024/home\" target=\"_blank\" rel=\"noreferrer noopener\">EmTech Digital 2024<span class=\"sr-only\"> (opens in new tab)</span></a>, Bonnie Kruft, partner deputy director at Microsoft Research AI for Science, outlined some examples of how generative AI enables groundbreaking research in the natural sciences. Recent breakthroughs aided by AI include small molecular inhibitors for treating infectious disease, the discovery of new materials for energy storage, and new drug development.&nbsp;</p>\n\n\n\n<p>Catch a <a href=\"https://www.microsoft.com/en-us/research/video/ai-case-studies-for-natural-science-research-with-bonnie-kruft/\" target=\"_blank\" rel=\"noreferrer noopener\">replay of the presentation</a>, including a follow-up Q&A with the audience, and hear how researchers are reducing discovery times from years to months. The discussion explores safe and responsible AI practices, how large language models can work with science-based models, and what lies ahead for AI in science.&nbsp;</p>\n\n\n\n<div class=\"wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-8 wp-block-buttons-is-layout-flex\">\n<div class=\"wp-block-button is-style-outline\"><a data-bi-type=\"button\" class=\"wp-block-button__link wp-element-button\" href=\"https://www.microsoft.com/en-us/research/video/ai-case-studies-for-natural-science-research-with-bonnie-kruft/\">Watch the video</a></div>\n</div>\n\n\n\n<div style=\"padding-bottom:64px; padding-top:64px\" class=\"wp-block-msr-immersive-section alignfull row has-background has-lighter-gray-background-color has-text-color has-black-color wp-block-msr-immersive-section\">\n\t\n\t<div class=\"container\">\n\t\t<div class=\"wp-block-msr-immersive-section__inner\">\n\t\t\t<div class=\"msr-cards__card msr-cards__card--default col\">\n\t<div class=\"card has-spectrum-border-top__hover material-card h-100 p-0\" data-mount=\"click-group\">\n\n\t\t\n\t\t<div class=\"card-body bg-white p-4 pt-3\">\n\t\t\t\t\t\t\n\t\t\t\t\t</div>\n\t</div>\n</div>\t\t</div>\n\t</div>\n\n\t</div>\n<span id=\"label-external-link\" class=\"sr-only\" aria-hidden=\"true\">Opens in a new tab</span>",
            "protected": false
        },
        "excerpt": {
            "rendered": "<p>Welcome to Research Focus, a series of blog posts that highlights notable publications, events, code/datasets, new hires and other milestones from across the research community at Microsoft. Large language models (LLMs) have shown remarkable performance in generating text similar to that created by people, proving to be a valuable asset across various applications. However, adapting [&hellip;]</p>\n",
            "protected": false
        },
        "author": 42735,
        "featured_media": 1033017,
        "comment_status": "closed",
        "ping_status": "closed",
        "sticky": false,
        "template": "",
        "format": "standard",
        "meta": {
            "msr-url-field": "",
            "msr-podcast-episode": "",
            "msrModifiedDate": "",
            "msrModifiedDateEnabled": false,
            "ep_exclude_from_search": false,
            "footnotes": ""
        },
        "categories": [
            1
        ],
        "tags": [],
        "research-area": [
            13556,
            13563,
            13545,
            13554,
            13553,
            13560,
            13568
        ],
        "msr-region": [],
        "msr-event-type": [],
        "msr-post-option": [
            243984
        ],
        "msr-impact-theme": [],
        "msr-promo-type": [],
        "msr-podcast-series": [],
        "msr_event_details": {
            "start": "",
            "end": "",
            "location": ""
        },
        "podcast_url": "",
        "podcast_episode": "",
        "msr_research_lab": [
            199562,
            199565,
            199571,
            851467
        ],
        "msr_impact_theme": [],
        "related-publications": [],
        "related-downloads": [],
        "related-videos": [],
        "related-academic-programs": [],
        "related-groups": [
            144784,
            144812,
            372368,
            714067
        ],
        "related-projects": [
            1018536,
            950052,
            881235,
            807097,
            716050
        ],
        "related-events": [],
        "related-researchers": [
            {
                "type": "user_nicename",
                "value": "Leonardo Nunes",
                "user_id": 40759,
                "display_name": "Leonardo Nunes",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/lnunes/\" aria-label=\"Visit the profile page for Leonardo Nunes\">Leonardo Nunes</a>",
                "is_active": false,
                "last_first": "Nunes, Leonardo",
                "people_section": 0,
                "alias": "lnunes"
            },
            {
                "type": "user_nicename",
                "value": "Sara Malvar",
                "user_id": 40753,
                "display_name": "Sara Malvar",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/saramalvar/\" aria-label=\"Visit the profile page for Sara Malvar\">Sara Malvar</a>",
                "is_active": false,
                "last_first": "Malvar, Sara",
                "people_section": 0,
                "alias": "saramalvar"
            },
            {
                "type": "user_nicename",
                "value": "Bruno Silva",
                "user_id": 42309,
                "display_name": "Bruno Silva",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/brunosilva/\" aria-label=\"Visit the profile page for Bruno Silva\">Bruno Silva</a>",
                "is_active": false,
                "last_first": "Silva, Bruno",
                "people_section": 0,
                "alias": "brunosilva"
            },
            {
                "type": "user_nicename",
                "value": "Ranveer Chandra",
                "user_id": 33344,
                "display_name": "Ranveer Chandra",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/ranveer/\" aria-label=\"Visit the profile page for Ranveer Chandra\">Ranveer Chandra</a>",
                "is_active": false,
                "last_first": "Chandra, Ranveer",
                "people_section": 0,
                "alias": "ranveer"
            },
            {
                "type": "user_nicename",
                "value": "Serena Hillman",
                "user_id": 41143,
                "display_name": "Serena Hillman",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/sehillma/\" aria-label=\"Visit the profile page for Serena Hillman\">Serena Hillman</a>",
                "is_active": false,
                "last_first": "Hillman, Serena",
                "people_section": 0,
                "alias": "sehillma"
            },
            {
                "type": "user_nicename",
                "value": "Thomas Ball",
                "user_id": 33895,
                "display_name": "Thomas Ball",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/tball/\" aria-label=\"Visit the profile page for Thomas Ball\">Thomas Ball</a>",
                "is_active": false,
                "last_first": "Ball, Thomas",
                "people_section": 0,
                "alias": "tball"
            },
            {
                "type": "user_nicename",
                "value": "Peli de Halleux",
                "user_id": 32253,
                "display_name": "Peli de Halleux",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/jhalleux/\" aria-label=\"Visit the profile page for Peli de Halleux\">Peli de Halleux</a>",
                "is_active": false,
                "last_first": "de Halleux, Peli",
                "people_section": 0,
                "alias": "jhalleux"
            },
            {
                "type": "user_nicename",
                "value": "James Devine",
                "user_id": 41632,
                "display_name": "James Devine",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/devinejames/\" aria-label=\"Visit the profile page for James Devine\">James Devine</a>",
                "is_active": false,
                "last_first": "Devine, James",
                "people_section": 0,
                "alias": "devinejames"
            },
            {
                "type": "user_nicename",
                "value": "Michal Moskal",
                "user_id": 37431,
                "display_name": "Michal Moskal",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/mimoskal/\" aria-label=\"Visit the profile page for Michal Moskal\">Michal Moskal</a>",
                "is_active": false,
                "last_first": "Moskal, Michal",
                "people_section": 0,
                "alias": "mimoskal"
            },
            {
                "type": "user_nicename",
                "value": "Vivek Seshadri",
                "user_id": 36323,
                "display_name": "Vivek Seshadri",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/visesha/\" aria-label=\"Visit the profile page for Vivek Seshadri\">Vivek Seshadri</a>",
                "is_active": false,
                "last_first": "Seshadri, Vivek",
                "people_section": 0,
                "alias": "visesha"
            },
            {
                "type": "user_nicename",
                "value": "Manohar Swaminathan",
                "user_id": 35356,
                "display_name": "Manohar Swaminathan",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/swmanohmicrosoft-com/\" aria-label=\"Visit the profile page for Manohar Swaminathan\">Manohar Swaminathan</a>",
                "is_active": false,
                "last_first": "Swaminathan, Manohar",
                "people_section": 0,
                "alias": "swmanoh@microsoft.com"
            },
            {
                "type": "user_nicename",
                "value": "Sunayana Sitaram",
                "user_id": 37287,
                "display_name": "Sunayana Sitaram",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/susitara/\" aria-label=\"Visit the profile page for Sunayana Sitaram\">Sunayana Sitaram</a>",
                "is_active": false,
                "last_first": "Sitaram, Sunayana",
                "people_section": 0,
                "alias": "susitara"
            },
            {
                "type": "user_nicename",
                "value": "Hanna Wallach",
                "user_id": 34779,
                "display_name": "Hanna Wallach",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/wallach/\" aria-label=\"Visit the profile page for Hanna Wallach\">Hanna Wallach</a>",
                "is_active": false,
                "last_first": "Wallach, Hanna",
                "people_section": 0,
                "alias": "wallach"
            },
            {
                "type": "user_nicename",
                "value": "Jennifer Wortman Vaughan",
                "user_id": 32235,
                "display_name": "Jennifer Wortman Vaughan",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/jenn/\" aria-label=\"Visit the profile page for Jennifer Wortman Vaughan\">Jennifer Wortman Vaughan</a>",
                "is_active": false,
                "last_first": "Wortman Vaughan, Jennifer",
                "people_section": 0,
                "alias": "jenn"
            },
            {
                "type": "user_nicename",
                "value": "Qi Chen",
                "user_id": 36990,
                "display_name": "Qi Chen",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/cheqi/\" aria-label=\"Visit the profile page for Qi Chen\">Qi Chen</a>",
                "is_active": false,
                "last_first": "Chen, Qi",
                "people_section": 0,
                "alias": "cheqi"
            },
            {
                "type": "user_nicename",
                "value": "Xiubo Geng",
                "user_id": 39075,
                "display_name": "Xiubo Geng",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/xigeng/\" aria-label=\"Visit the profile page for Xiubo Geng\">Xiubo Geng</a>",
                "is_active": false,
                "last_first": "Geng, Xiubo",
                "people_section": 0,
                "alias": "xigeng"
            },
            {
                "type": "user_nicename",
                "value": "Corby Rosset",
                "user_id": 41997,
                "display_name": "Corby Rosset",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/corbyrosset/\" aria-label=\"Visit the profile page for Corby Rosset\">Corby Rosset</a>",
                "is_active": false,
                "last_first": "Rosset, Corby",
                "people_section": 0,
                "alias": "corbyrosset"
            },
            {
                "type": "user_nicename",
                "value": "Carolyn Buractaon",
                "user_id": 39327,
                "display_name": "Carolyn Buractaon",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/caburact/\" aria-label=\"Visit the profile page for Carolyn Buractaon\">Carolyn Buractaon</a>",
                "is_active": false,
                "last_first": "Buractaon, Carolyn",
                "people_section": 0,
                "alias": "caburact"
            },
            {
                "type": "user_nicename",
                "value": "Jingwen Lu",
                "user_id": 40021,
                "display_name": "Jingwen Lu",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/jinlu/\" aria-label=\"Visit the profile page for Jingwen Lu\">Jingwen Lu</a>",
                "is_active": false,
                "last_first": "Lu, Jingwen",
                "people_section": 0,
                "alias": "jinlu"
            },
            {
                "type": "user_nicename",
                "value": "Yeyun Gong",
                "user_id": 39186,
                "display_name": "Yeyun Gong",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/yegong/\" aria-label=\"Visit the profile page for Yeyun Gong\">Yeyun Gong</a>",
                "is_active": false,
                "last_first": "Gong, Yeyun",
                "people_section": 0,
                "alias": "yegong"
            },
            {
                "type": "user_nicename",
                "value": "Nick Craswell",
                "user_id": 33088,
                "display_name": "Nick Craswell",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/nickcr/\" aria-label=\"Visit the profile page for Nick Craswell\">Nick Craswell</a>",
                "is_active": false,
                "last_first": "Craswell, Nick",
                "people_section": 0,
                "alias": "nickcr"
            },
            {
                "type": "user_nicename",
                "value": "Xing Xie",
                "user_id": 34906,
                "display_name": "Xing Xie",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/xingx/\" aria-label=\"Visit the profile page for Xing Xie\">Xing Xie</a>",
                "is_active": false,
                "last_first": "Xie, Xing",
                "people_section": 0,
                "alias": "xingx"
            },
            {
                "type": "user_nicename",
                "value": "Fan Yang",
                "user_id": 31782,
                "display_name": "Fan Yang",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/fanyang/\" aria-label=\"Visit the profile page for Fan Yang\">Fan Yang</a>",
                "is_active": false,
                "last_first": "Yang, Fan",
                "people_section": 0,
                "alias": "fanyang"
            },
            {
                "type": "user_nicename",
                "value": "Bryan Tower",
                "user_id": 36653,
                "display_name": "Bryan Tower",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/brtower/\" aria-label=\"Visit the profile page for Bryan Tower\">Bryan Tower</a>",
                "is_active": false,
                "last_first": "Tower, Bryan",
                "people_section": 0,
                "alias": "brtower"
            },
            {
                "type": "user_nicename",
                "value": "Jason (Zengzhong) Li",
                "user_id": 40543,
                "display_name": "Jason (Zengzhong) Li",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/jasol/\" aria-label=\"Visit the profile page for Jason (Zengzhong) Li\">Jason (Zengzhong) Li</a>",
                "is_active": false,
                "last_first": "Li, Jason (Zengzhong)",
                "people_section": 0,
                "alias": "jasol"
            },
            {
                "type": "user_nicename",
                "value": "Rangan Majumder",
                "user_id": 38931,
                "display_name": "Rangan Majumder",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/ranganm/\" aria-label=\"Visit the profile page for Rangan Majumder\">Rangan Majumder</a>",
                "is_active": false,
                "last_first": "Majumder, Rangan",
                "people_section": 0,
                "alias": "ranganm"
            },
            {
                "type": "user_nicename",
                "value": "Jennifer Neville",
                "user_id": 40946,
                "display_name": "Jennifer Neville",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/jenneville/\" aria-label=\"Visit the profile page for Jennifer Neville\">Jennifer Neville</a>",
                "is_active": false,
                "last_first": "Neville, Jennifer",
                "people_section": 0,
                "alias": "jenneville"
            },
            {
                "type": "user_nicename",
                "value": "Harsha Simhadri",
                "user_id": 36146,
                "display_name": "Harsha Simhadri",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/harshasi/\" aria-label=\"Visit the profile page for Harsha Simhadri\">Harsha Simhadri</a>",
                "is_active": false,
                "last_first": "Simhadri, Harsha",
                "people_section": 0,
                "alias": "harshasi"
            },
            {
                "type": "user_nicename",
                "value": "Manik Varma",
                "user_id": 32791,
                "display_name": "Manik Varma",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/manik/\" aria-label=\"Visit the profile page for Manik Varma\">Manik Varma</a>",
                "is_active": false,
                "last_first": "Varma, Manik",
                "people_section": 0,
                "alias": "manik"
            },
            {
                "type": "user_nicename",
                "value": "Mao Yang",
                "user_id": 32798,
                "display_name": "Mao Yang",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/maoyang/\" aria-label=\"Visit the profile page for Mao Yang\">Mao Yang</a>",
                "is_active": false,
                "last_first": "Yang, Mao",
                "people_section": 0,
                "alias": "maoyang"
            },
            {
                "type": "user_nicename",
                "value": "Bonnie Kruft",
                "user_id": 41919,
                "display_name": "Bonnie Kruft",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/bonniekruft/\" aria-label=\"Visit the profile page for Bonnie Kruft\">Bonnie Kruft</a>",
                "is_active": false,
                "last_first": "Kruft, Bonnie",
                "people_section": 0,
                "alias": "bonniekruft"
            }
        ],
        "msr_type": "Post",
        "featured_image_thumbnail": "<img width=\"960\" height=\"540\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-960x540.png\" class=\"img-object-cover\" alt=\"Research Focus: May 13, 2024\" decoding=\"async\" loading=\"lazy\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1-1280x720.png 1280w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RF41-BlogHeroFeature-1400x788-1.png 1400w\" sizes=\"(max-width: 960px) 100vw, 960px\" />",
        "byline": "",
        "formattedDate": "May 15, 2024",
        "formattedExcerpt": "Welcome to Research Focus, a series of blog posts that highlights notable publications, events, code/datasets, new hires and other milestones from across the research community at Microsoft. Large language models (LLMs) have shown remarkable performance in generating text similar to that created by people, proving&hellip;",
        "_links": {
            "self": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1032900"
                }
            ],
            "collection": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts"
                }
            ],
            "about": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/types/post"
                }
            ],
            "author": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/users/42735"
                }
            ],
            "replies": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/comments?post=1032900"
                }
            ],
            "version-history": [
                {
                    "count": 25,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1032900/revisions"
                }
            ],
            "predecessor-version": [
                {
                    "id": 1035336,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1032900/revisions/1035336"
                }
            ],
            "wp:featuredmedia": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/media/1033017"
                }
            ],
            "wp:attachment": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/media?parent=1032900"
                }
            ],
            "wp:term": [
                {
                    "taxonomy": "category",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/categories?post=1032900"
                },
                {
                    "taxonomy": "post_tag",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/tags?post=1032900"
                },
                {
                    "taxonomy": "msr-research-area",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/research-area?post=1032900"
                },
                {
                    "taxonomy": "msr-region",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-region?post=1032900"
                },
                {
                    "taxonomy": "msr-event-type",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-event-type?post=1032900"
                },
                {
                    "taxonomy": "msr-post-option",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-post-option?post=1032900"
                },
                {
                    "taxonomy": "msr-impact-theme",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-impact-theme?post=1032900"
                },
                {
                    "taxonomy": "msr-promo-type",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-promo-type?post=1032900"
                },
                {
                    "taxonomy": "msr-podcast-series",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-podcast-series?post=1032900"
                }
            ],
            "curies": [
                {
                    "name": "wp",
                    "href": "https://api.w.org/{rel}",
                    "templated": true
                }
            ]
        }
    },
    {
        "id": 1033068,
        "date": "2024-05-15T09:00:00",
        "date_gmt": "2024-05-15T16:00:00",
        "guid": {
            "rendered": "https://www.microsoft.com/en-us/research/?p=1033068"
        },
        "modified": "2024-05-14T06:29:33",
        "modified_gmt": "2024-05-14T13:29:33",
        "slug": "microsoft-at-chi-2024-innovations-in-human-centered-design",
        "status": "publish",
        "type": "post",
        "link": "https://www.microsoft.com/en-us/research/blog/microsoft-at-chi-2024-innovations-in-human-centered-design/",
        "title": {
            "rendered": "Microsoft at CHI 2024: Innovations in human-centered design"
        },
        "content": {
            "rendered": "\n<figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1400\" height=\"788\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/CHI-2024-BlogHeroFeature-1400x788-1.png\" alt=\"Microsoft at CHI 2024\" class=\"wp-image-1033422\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/CHI-2024-BlogHeroFeature-1400x788-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/CHI-2024-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/CHI-2024-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/CHI-2024-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/CHI-2024-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/CHI-2024-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/CHI-2024-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/CHI-2024-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/CHI-2024-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/CHI-2024-BlogHeroFeature-1400x788-1-1280x720.png 1280w\" sizes=\"(max-width: 1400px) 100vw, 1400px\" /></figure>\n\n\n\n<p>The ways people engage with technology, through its design and functionality, determine its utility and acceptance in everyday use, setting the stage for widespread adoption. When computing tools and services respect the diversity of people’s experiences and abilities, technology is not only functional but also universally accessible. Human-computer interaction (HCI) plays a crucial role in this process, examining how technology integrates into our daily lives and exploring ways digital tools can be shaped to meet individual needs and enhance our interactions with the world.</p>\n\n\n\n<p>The <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://chi2024.acm.org/\" target=\"_blank\" rel=\"noreferrer noopener\">ACM CHI Conference on Human Factors in Computing Systems</a> is a premier forum that brings together researchers and experts in the field, and Microsoft is honored to support <a href=\"https://www.microsoft.com/en-us/research/event/microsoft-at-chi-2024/\" target=\"_blank\" rel=\"noreferrer noopener\">CHI 2024</a> as a returning sponsor. We&#8217;re pleased to announce that 33 papers by Microsoft researchers and their collaborators have been accepted this year, with four winning the Best Paper Award and seven receiving honorable mentions.</p>\n\n\n\n<p>This research aims to redefine how people work, collaborate, and play using technology, with a focus on design innovation to create more personalized, engaging, and effective interactions. Several projects emphasize customizing the user experience to better meet individual needs, such as exploring the potential of large language models (LLMs) to help reduce procrastination. Others investigate ways to boost realism in virtual and mixed reality environments, using touch to create a more immersive experience. There are also studies that address the challenges of understanding how people interact with technology. These include applying psychology and cognitive science to examine the use of generative AI and social media, with the goal of using the insights to guide future research and design directions. This post highlights these projects.</p>\n\n\n\n\t<div class=\"border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide\" data-bi-aN=\"promo\" data-bi-id=\"932112\">\n\t\t\n\n\t\t<p class=\"msr-promo__label text-gray-800 text-center text-uppercase\">\n\t\t<span class=\"px-4 bg-white display-inline-block font-weight-semibold small\">Microsoft Research Podcast</span>\n\t</p>\n\t\n\t<div class=\"row pt-3 pb-4 align-items-center\">\n\t\t\t\t\t\t<div class=\"msr-promo__media col-12 col-md-5\">\n\t\t\t\t<a class=\"bg-gray-300\" href=\"https://www.microsoft.com/en-us/research/podcast/ai-frontiers-ai-for-health-and-the-future-of-research-with-peter-lee/\" aria-label=\"AI Frontiers: AI for health and the future of research with Peter Lee\" data-bi-cN=\"AI Frontiers: AI for health and the future of research with Peter Lee\" target=\"_blank\">\n\t\t\t\t\t<img decoding=\"async\" class=\"w-100 display-block\" src=\"https://www.microsoft.com/en-us/research/uploads/prod/2023/03/PeterLee_podcast-2023Mar_hero_1400x788.png\" alt=\"Peter Lee wearing glasses and smiling at the camera with the Microsoft Research Podcast logo to the left\" />\n\t\t\t\t</a>\n\t\t\t</div>\n\t\t\t\n\t\t\t<div class=\"msr-promo__content p-3 px-5 col-12 col-md\">\n\n\t\t\t\t\t\t\t\t\t<h2 class=\"h4\">AI Frontiers: AI for health and the future of research with Peter Lee</h2>\n\t\t\t\t\n\t\t\t\t\t\t\t\t<p class=\"large\">Peter Lee, head of Microsoft Research, and Ashley Llorens, AI scientist and engineer, discuss the future of AI research and the potential for GPT-4 as a medical copilot.</p>\n\t\t\t\t\n\t\t\t\t\t\t\t\t<div class=\"wp-block-buttons justify-content-center justify-content-md-start\">\n\t\t\t\t\t<div class=\"wp-block-button\">\n\t\t\t\t\t\t<a href=\"https://www.microsoft.com/en-us/research/podcast/ai-frontiers-ai-for-health-and-the-future-of-research-with-peter-lee/\" class=\"btn btn-brand glyph-append glyph-append-chevron-right\" aria-label=\"Listen now\" data-bi-cN=\"AI Frontiers: AI for health and the future of research with Peter Lee\" target=\"_blank\">\n\t\t\t\t\t\t\tListen now\t\t\t\t\t\t</a>\n\t\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t\t\t\t</div><!--/.msr-promo__content-->\n\t</div><!--/.msr-promo__inner-wrap-->\n<span id=\"label-external-link\" class=\"sr-only\" aria-hidden=\"true\">Opens in a new tab</span>\t</div><!--/.msr-promo-->\n\t\n\n\n<h2 class=\"wp-block-heading\" id=\"best-paper-award-recipients\">Best Paper Award recipients</h2>\n\n\n\n<p><a href=\"https://www.microsoft.com/en-us/research/publication/dynavis-dynamically-synthesized-ui-widgets-for-visualization-editing/\"><strong>DynaVis: Dynamically Synthesized UI Widgets for Visualization Editing</strong></a>&nbsp;<br><em>Priyan Vaithilingam, Elena L. Glassman, </em><a href=\"https://www.microsoft.com/en-us/research/people/jinala/\"><em>Jeevana Priya Inala</em></a><em>, </em><a href=\"https://www.microsoft.com/en-us/research/people/chenwang/\"><em>Chenglong Wang</em></a>&nbsp;<br>GUIs used for editing visualizations can overwhelm users or limit their interactions. To address this, the authors introduce DynaVis, which combines natural language interfaces with dynamically synthesized UI widgets, enabling people to initiate and refine edits using natural language. &nbsp;</p>\n\n\n\n<p><a href=\"https://www.microsoft.com/en-us/research/publication/generative-echo-chamber-effects-of-llm-powered-search-systems-on-diverse-information-seeking/\"><strong>Generative Echo Chamber? Effects of LLM-Powered Search Systems on Diverse Information Seeking</strong></a><em> </em>&nbsp;<br><em>Nikhil Sharma, </em><a href=\"https://www.microsoft.com/en-us/research/people/veraliao/\"><em>Q. Vera Liao</em></a><em>, Ziang Xiao</em><strong> </strong>&nbsp;<br>Conversational search systems powered by LLMs potentially improve on traditional search methods, yet their influence on increasing selective exposure and fostering echo chambers remains underexplored. This research suggests that LLM-driven conversational search may enhance biased information querying, particularly when the LLM&#8217;s outputs reinforce user views, emphasizing significant implications for the development and regulation of these technologies. &nbsp;</p>\n\n\n\n<p><a href=\"https://www.microsoft.com/en-us/research/publication/piet-facilitating-color-authoring-for-motion-graphics-video/\"><strong>Piet: Facilitating Color Authoring for Motion Graphics Video</strong></a><strong> </strong>&nbsp;<br><em>Xinyu Shi, Yinghou Wang, </em><a href=\"https://www.microsoft.com/en-us/research/people/wangyun/\"><em>Yun Wang</em></a><em>, Jian Zhao</em>&nbsp;<br>Motion graphic (MG) videos use animated visuals and color to effectively communicate complex ideas, yet existing color authoring tools are lacking. This work introduces Piet, a tool prototype that offers an interactive palette and support for quick theme changes and controlled focus, significantly streamlining the color design process.</p>\n\n\n\n<p><a href=\"https://www.microsoft.com/en-us/research/publication/the-metacognitive-demands-and-opportunities-of-generative-ai/\"><strong>The Metacognitive Demands and Opportunities of Generative AI</strong></a>&nbsp;<br><em><a href=\"https://www.microsoft.com/en-us/research/people/levt/\">Lev Tankelevitch</a>, Viktor Kewenig, Auste Simkute, Ava Elizabeth Scott, </em><a href=\"https://www.microsoft.com/en-us/research/people/advait/\"><em>Advait Sarkar</em></a><em>, </em><a href=\"https://www.microsoft.com/en-us/research/people/asellen/\"><em>Abigail Sellen</em></a><em>, </em><a href=\"https://www.microsoft.com/en-us/research/people/serintel/\" target=\"_blank\" rel=\"noreferrer noopener\"><em>Sean Rintel</em></a>&nbsp;<br>Generative AI systems offer unprecedented opportunities for transforming professional and personal work, yet they present challenges around prompting, evaluating and relying on outputs, and optimizing workflows. This paper shows that metacognition—the psychological ability to monitor and control one’s thoughts and behavior—offers a valuable lens through which to understand and design for these usability challenges. &nbsp;</p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"honorable-mentions\">Honorable Mentions</h2>\n\n\n\n<p><strong><a href=\"https://www.microsoft.com/en-us/research/publication/big-or-small-its-all-in-your-head-visuo-haptic-illusion-of-size-change-using-finger-repositioning/\">B</a></strong><a href=\"https://www.microsoft.com/en-us/research/publication/big-or-small-its-all-in-your-head-visuo-haptic-illusion-of-size-change-using-finger-repositioning/\" target=\"_blank\" rel=\"noreferrer noopener\"><strong>ig or Small, It’s All in Your Head: Visuo-Haptic Illusion of Size-Change Using Finger-Repositioning</strong></a><br><em>Myung Jin Kim, Eyal Ofek, </em><a href=\"https://www.microsoft.com/en-us/research/people/mpahud/\"><em>Michel Pahud</em></a><em>, Mike J. Sinclair, Andrea Bianchi</em>&nbsp;<br>This research introduces a fixed-sized VR controller that uses finger repositioning to create a visuo-haptic illusion of dynamic size changes in handheld virtual objects, allowing users to perceive virtual objects as significantly smaller or larger than the actual device.&nbsp;</p>\n\n\n\n<p><a href=\"https://www.microsoft.com/en-us/research/publication/llmr-real-time-prompting-of-interactive-worlds-using-large-language-models-3/\"><strong>LLMR: Real-time Prompting of Interactive Worlds Using Large Language Models</strong></a>&nbsp;<br><em>Fernanda De La Torre, Cathy Mengying Fang, Han Huang, Andrzej Banburski-Fahey, </em><a href=\"https://www.microsoft.com/en-us/research/people/judithamores/\"><em>Judith Amores</em></a><em>, </em><a href=\"https://www.microsoft.com/en-us/research/people/jalani/\"><em>Jaron Lanier</em></a>&nbsp;<br>Large Language Model for Mixed Reality (LLMR) is a framework for the real-time creation and modification of interactive mixed reality experiences using LLMs. It uses novel strategies to tackle difficult cases where ideal training data is scarce or where the design goal requires the synthesis of internal dynamics, intuitive analysis, or advanced interactivity.&nbsp;</p>\n\n\n\n<p><a href=\"https://www.microsoft.com/en-us/research/publication/observer-effect-in-social-media-use/\"><strong>Observer Effect in Social Media Use</strong></a> <br><em>Koustuv Saha, Pranshu Gupta, Gloria Mark, </em><a href=\"https://www.microsoft.com/en-us/research/people/emrek/\"><em>Emre Kiciman</em></a><em>, Munmun De Choudhury</em> <br>This work investigates the observer effect in behavioral assessments on social media use. The observer effect is a phenomenon in which individuals alter their behavior due to awareness of being monitored. Conducted over an average of 82 months (about 7 years) retrospectively and five months prospectively using Facebook data, the study found that deviations in expected behavior and language post-enrollment in the study reflected individual psychological traits. The authors recommend ways to mitigate the observer effect in these scenarios.</p>\n\n\n\n<p><strong><a href=\"https://www.microsoft.com/en-us/research/publication/reading-between-the-lines-modeling-user-behavior-and-costs-in-ai-assisted-programming/\">Reading Between the Lines: Modeling User Behavior and Costs in AI-Assisted Programming</a></strong><a href=\"https://www.microsoft.com/en-us/research/people/gaganbansal/\">&nbsp;<br></a><em>Hussein Mozannar, </em><a href=\"https://www.microsoft.com/en-us/research/people/gaganbansal/\" target=\"_blank\" rel=\"noreferrer noopener\"><em>Gagan Bansal</em></a><em>, </em><a href=\"https://www.microsoft.com/en-us/research/people/adamfo/\"><em>Adam Fourney</em></a><em>, </em><a href=\"https://www.microsoft.com/en-us/research/people/horvitz/\"><em>Eric Horvitz</em></a>&nbsp;<br>By investigating how developers use GitHub Copilot, the authors created CUPS, a taxonomy of programmer activities during system interaction. This approach not only elucidates interaction patterns and inefficiencies but can also drive more effective metrics and UI design for code-recommendation systems with the goal of improving programmer productivity.&nbsp;</p>\n\n\n\n<p><a href=\"https://www.microsoft.com/en-us/research/publication/sharednerf-leveraging-photorealistic-and-view-dependent-rendering-for-real-time-and-remote-collaboration/\"><strong>SharedNeRF: Leveraging Photorealistic and View-dependent Rendering for Real-time and Remote Collaboration</strong></a>&nbsp;<br><em>Mose Sakashita, Bala Kumaravel, <a href=\"https://www.microsoft.com/en-us/research/people/nicmarquardt/\">Nicolai Marquardt</a>, <a href=\"https://www.microsoft.com/en-us/research/people/awilson/\">Andrew D. Wilson</a></em>&nbsp;<br>SharedNeRF, a system for synchronous remote collaboration, utilizes neural radiance field (NeRF) technology to provide photorealistic, viewpoint-specific renderings that are seamlessly integrated with point clouds to capture dynamic movements and changes in a shared space. A preliminary study demonstrated its effectiveness, as participants used this high-fidelity, multi-perspective visualization to successfully complete a flower arrangement task.&nbsp;</p>\n\n\n\n<p><a href=\"https://www.microsoft.com/en-us/research/publication/understanding-the-role-of-large-language-models-in-personalizing-and-scaffolding-strategies-to-combat-academic-procrastination/\"><strong>Understanding the Role of Large Language Models in Personalizing and Scaffolding Strategies to Combat Academic Procrastination</strong></a>&nbsp;<br><em>Ananya Bhattacharjee, Yuchen Zeng, Sarah Yi Xu, Dana Kulzhabayeva, Minyi Ma, Rachel Kornfield, Syed Ishtiaque Ahmed, Alex Mariakakis, </em><a href=\"https://www.microsoft.com/en-us/research/people/marycz/\"><em>Mary P. Czerwinski</em></a><em>, Anastasia Kuzminykh, Michael Liut, Joseph Jay Williams</em>&nbsp;<br>In this study, the authors explore the potential of LLMs for customizing academic procrastination interventions, employing a technology probe to generate personalized advice. Their findings emphasize the need for LLMs to offer structured, deadline-oriented advice and adaptive questioning techniques, providing key design insights for LLM-based tools while highlighting cautions against their use for therapeutic guidance.</p>\n\n\n\n<p><a href=\"https://www.microsoft.com/en-us/research/publication/where-are-we-so-far-understanding-data-storytelling-tools-from-the-perspective-of-human-ai-collaboration/\"><strong>Where Are We So Far? Understanding Data Storytelling Tools from the Perspective of Human-AI Collaboration</strong></a><strong>&nbsp;</strong><br><em>Haotian Li, </em><a href=\"https://www.microsoft.com/en-us/research/people/wangyun/\"><em>Yun Wang</em></a><em>, Huamin Qu</em> <br>This paper evaluates data storytelling tools using a dual framework to analyze the stages of the storytelling workflow—analysis, planning, implementation, communication—and the roles of humans and AI in each stage, such as creators, assistants, optimizers, and reviewers. The study identifies common collaboration patterns in existing tools, summarizes lessons from these patterns, and highlights future research opportunities for human-AI collaboration in data storytelling.</p>\n\n\n\n<hr class=\"wp-block-separator has-alpha-channel-opacity\"/>\n\n\n\n<p>Learn more about our work and contributions to CHI 2024, including our full <a href=\"https://www.microsoft.com/en-us/research/event/microsoft-at-chi-2024/publications/\">list of publications</a>, on our conference <a href=\"https://www.microsoft.com/en-us/research/event/microsoft-at-chi-2024/overview/\">webpage</a>.</p>\n<span id=\"label-external-link\" class=\"sr-only\" aria-hidden=\"true\">Opens in a new tab</span>",
            "protected": false
        },
        "excerpt": {
            "rendered": "<p>From immersive virtual experiences to interactive design tools, Microsoft Research is at the frontier of exploring how people engage with technology. Discover our latest breakthroughs in human-computer interaction research at CHI 2024.</p>\n",
            "protected": false
        },
        "author": 42735,
        "featured_media": 1033422,
        "comment_status": "closed",
        "ping_status": "closed",
        "sticky": false,
        "template": "",
        "format": "standard",
        "meta": {
            "msr-url-field": "",
            "msr-podcast-episode": "",
            "msrModifiedDate": "",
            "msrModifiedDateEnabled": false,
            "ep_exclude_from_search": false,
            "footnotes": ""
        },
        "categories": [
            1
        ],
        "tags": [],
        "research-area": [
            13554
        ],
        "msr-region": [],
        "msr-event-type": [],
        "msr-post-option": [
            243984
        ],
        "msr-impact-theme": [],
        "msr-promo-type": [],
        "msr-podcast-series": [],
        "msr_event_details": {
            "start": "",
            "end": "",
            "location": ""
        },
        "podcast_url": "",
        "podcast_episode": "",
        "msr_research_lab": [
            199560,
            199561,
            199565,
            437514,
            992148
        ],
        "msr_impact_theme": [],
        "related-publications": [],
        "related-downloads": [],
        "related-videos": [],
        "related-academic-programs": [],
        "related-groups": [],
        "related-projects": [],
        "related-events": [
            1019022
        ],
        "related-researchers": [
            {
                "type": "user_nicename",
                "value": "Jeevana Priya Inala",
                "user_id": 41377,
                "display_name": "Jeevana Priya Inala",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/jinala/\" aria-label=\"Visit the profile page for Jeevana Priya Inala\">Jeevana Priya Inala</a>",
                "is_active": false,
                "last_first": "Inala, Jeevana Priya",
                "people_section": 0,
                "alias": "jinala"
            },
            {
                "type": "user_nicename",
                "value": "Chenglong Wang",
                "user_id": 41251,
                "display_name": "Chenglong Wang",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/chenwang/\" aria-label=\"Visit the profile page for Chenglong Wang\">Chenglong Wang</a>",
                "is_active": false,
                "last_first": "Wang, Chenglong",
                "people_section": 0,
                "alias": "chenwang"
            },
            {
                "type": "user_nicename",
                "value": "Lev Tankelevitch",
                "user_id": 43209,
                "display_name": "Lev Tankelevitch",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/levt/\" aria-label=\"Visit the profile page for Lev Tankelevitch\">Lev Tankelevitch</a>",
                "is_active": false,
                "last_first": "Tankelevitch, Lev",
                "people_section": 0,
                "alias": "levt"
            },
            {
                "type": "user_nicename",
                "value": "Advait Sarkar",
                "user_id": 37146,
                "display_name": "Advait Sarkar",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/advait/\" aria-label=\"Visit the profile page for Advait Sarkar\">Advait Sarkar</a>",
                "is_active": false,
                "last_first": "Sarkar, Advait",
                "people_section": 0,
                "alias": "advait"
            },
            {
                "type": "user_nicename",
                "value": "Abigail Sellen",
                "user_id": 31112,
                "display_name": "Abigail Sellen",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/asellen/\" aria-label=\"Visit the profile page for Abigail Sellen\">Abigail Sellen</a>",
                "is_active": false,
                "last_first": "Sellen, Abigail",
                "people_section": 0,
                "alias": "asellen"
            },
            {
                "type": "user_nicename",
                "value": "Sean Rintel",
                "user_id": 33579,
                "display_name": "Sean Rintel",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/serintel/\" aria-label=\"Visit the profile page for Sean Rintel\">Sean Rintel</a>",
                "is_active": false,
                "last_first": "Rintel, Sean",
                "people_section": 0,
                "alias": "serintel"
            },
            {
                "type": "user_nicename",
                "value": "Q. Vera Liao",
                "user_id": 40912,
                "display_name": "Q. Vera Liao",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/veraliao/\" aria-label=\"Visit the profile page for Q. Vera Liao\">Q. Vera Liao</a>",
                "is_active": false,
                "last_first": "Liao, Q. Vera",
                "people_section": 0,
                "alias": "veraliao"
            },
            {
                "type": "user_nicename",
                "value": "Yun Wang",
                "user_id": 37827,
                "display_name": "Yun Wang",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/wangyun/\" aria-label=\"Visit the profile page for Yun Wang\">Yun Wang</a>",
                "is_active": false,
                "last_first": "Wang, Yun",
                "people_section": 0,
                "alias": "wangyun"
            },
            {
                "type": "user_nicename",
                "value": "Michel Pahud",
                "user_id": 33007,
                "display_name": "Michel Pahud",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/mpahud/\" aria-label=\"Visit the profile page for Michel Pahud\">Michel Pahud</a>",
                "is_active": false,
                "last_first": "Pahud, Michel",
                "people_section": 0,
                "alias": "mpahud"
            },
            {
                "type": "user_nicename",
                "value": "Judith Amores",
                "user_id": 42003,
                "display_name": "Judith Amores",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/judithamores/\" aria-label=\"Visit the profile page for Judith Amores\">Judith Amores</a>",
                "is_active": false,
                "last_first": "Amores, Judith",
                "people_section": 0,
                "alias": "judithamores"
            },
            {
                "type": "user_nicename",
                "value": "Jaron Lanier",
                "user_id": 32148,
                "display_name": "Jaron Lanier",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/jalani/\" aria-label=\"Visit the profile page for Jaron Lanier\">Jaron Lanier</a>",
                "is_active": false,
                "last_first": "Lanier, Jaron",
                "people_section": 0,
                "alias": "jalani"
            },
            {
                "type": "user_nicename",
                "value": "Emre Kiciman",
                "user_id": 31739,
                "display_name": "Emre Kiciman",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/emrek/\" aria-label=\"Visit the profile page for Emre Kiciman\">Emre Kiciman</a>",
                "is_active": false,
                "last_first": "Kiciman, Emre",
                "people_section": 0,
                "alias": "emrek"
            },
            {
                "type": "user_nicename",
                "value": "Gagan Bansal",
                "user_id": 41707,
                "display_name": "Gagan Bansal",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/gaganbansal/\" aria-label=\"Visit the profile page for Gagan Bansal\">Gagan Bansal</a>",
                "is_active": false,
                "last_first": "Bansal, Gagan",
                "people_section": 0,
                "alias": "gaganbansal"
            },
            {
                "type": "user_nicename",
                "value": "Adam Fourney",
                "user_id": 30820,
                "display_name": "Adam Fourney",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/adamfo/\" aria-label=\"Visit the profile page for Adam Fourney\">Adam Fourney</a>",
                "is_active": false,
                "last_first": "Fourney, Adam",
                "people_section": 0,
                "alias": "adamfo"
            },
            {
                "type": "user_nicename",
                "value": "Eric Horvitz",
                "user_id": 32033,
                "display_name": "Eric Horvitz",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/horvitz/\" aria-label=\"Visit the profile page for Eric Horvitz\">Eric Horvitz</a>",
                "is_active": false,
                "last_first": "Horvitz, Eric",
                "people_section": 0,
                "alias": "horvitz"
            },
            {
                "type": "user_nicename",
                "value": "Nicolai Marquardt",
                "user_id": 42630,
                "display_name": "Nicolai Marquardt",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/nicmarquardt/\" aria-label=\"Visit the profile page for Nicolai Marquardt\">Nicolai Marquardt</a>",
                "is_active": false,
                "last_first": "Marquardt, Nicolai",
                "people_section": 0,
                "alias": "nicmarquardt"
            },
            {
                "type": "user_nicename",
                "value": "Andy Wilson",
                "user_id": 31159,
                "display_name": "Andy Wilson",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/awilson/\" aria-label=\"Visit the profile page for Andy Wilson\">Andy Wilson</a>",
                "is_active": false,
                "last_first": "Wilson, Andy",
                "people_section": 0,
                "alias": "awilson"
            },
            {
                "type": "user_nicename",
                "value": "Mary Czerwinski",
                "user_id": 32824,
                "display_name": "Mary Czerwinski",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/marycz/\" aria-label=\"Visit the profile page for Mary Czerwinski\">Mary Czerwinski</a>",
                "is_active": false,
                "last_first": "Czerwinski, Mary",
                "people_section": 0,
                "alias": "marycz"
            }
        ],
        "msr_type": "Post",
        "featured_image_thumbnail": "<img width=\"960\" height=\"540\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/CHI-2024-BlogHeroFeature-1400x788-1-960x540.png\" class=\"img-object-cover\" alt=\"Microsoft at CHI 2024\" decoding=\"async\" loading=\"lazy\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/CHI-2024-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/CHI-2024-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/CHI-2024-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/CHI-2024-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/CHI-2024-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/CHI-2024-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/CHI-2024-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/CHI-2024-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/CHI-2024-BlogHeroFeature-1400x788-1-1280x720.png 1280w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/CHI-2024-BlogHeroFeature-1400x788-1.png 1400w\" sizes=\"(max-width: 960px) 100vw, 960px\" />",
        "byline": "",
        "formattedDate": "May 15, 2024",
        "formattedExcerpt": "From immersive virtual experiences to interactive design tools, Microsoft Research is at the frontier of exploring how people engage with technology. Discover our latest breakthroughs in human-computer interaction research at CHI 2024.",
        "_links": {
            "self": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1033068"
                }
            ],
            "collection": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts"
                }
            ],
            "about": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/types/post"
                }
            ],
            "author": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/users/42735"
                }
            ],
            "replies": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/comments?post=1033068"
                }
            ],
            "version-history": [
                {
                    "count": 20,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1033068/revisions"
                }
            ],
            "predecessor-version": [
                {
                    "id": 1033785,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1033068/revisions/1033785"
                }
            ],
            "wp:featuredmedia": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/media/1033422"
                }
            ],
            "wp:attachment": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/media?parent=1033068"
                }
            ],
            "wp:term": [
                {
                    "taxonomy": "category",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/categories?post=1033068"
                },
                {
                    "taxonomy": "post_tag",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/tags?post=1033068"
                },
                {
                    "taxonomy": "msr-research-area",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/research-area?post=1033068"
                },
                {
                    "taxonomy": "msr-region",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-region?post=1033068"
                },
                {
                    "taxonomy": "msr-event-type",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-event-type?post=1033068"
                },
                {
                    "taxonomy": "msr-post-option",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-post-option?post=1033068"
                },
                {
                    "taxonomy": "msr-impact-theme",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-impact-theme?post=1033068"
                },
                {
                    "taxonomy": "msr-promo-type",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-promo-type?post=1033068"
                },
                {
                    "taxonomy": "msr-podcast-series",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-podcast-series?post=1033068"
                }
            ],
            "curies": [
                {
                    "name": "wp",
                    "href": "https://api.w.org/{rel}",
                    "templated": true
                }
            ]
        }
    },
    {
        "id": 1032576,
        "date": "2024-05-14T09:00:17",
        "date_gmt": "2024-05-14T16:00:17",
        "guid": {
            "rendered": "https://www.microsoft.com/en-us/research/?p=1032576"
        },
        "modified": "2024-05-14T09:00:18",
        "modified_gmt": "2024-05-14T16:00:18",
        "slug": "rascal-novel-robotics-for-scalable-and-highly-available-automated-storage-and-retrieval",
        "status": "publish",
        "type": "post",
        "link": "https://www.microsoft.com/en-us/research/blog/rascal-novel-robotics-for-scalable-and-highly-available-automated-storage-and-retrieval/",
        "title": {
            "rendered": "RASCAL: Novel robotics for scalable and highly available automated storage and retrieval"
        },
        "content": {
            "rendered": "\n<p class=\"has-text-align-center\"><strong><em>This research paper was presented at the</em></strong>&nbsp;<br><a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://2024.ieee-icra.org/\" target=\"_blank\" rel=\"noreferrer noopener\"><strong><em>41<sup>st</sup> IEEE International Conference on Robotics and Automation</em></strong><span class=\"sr-only\"> (opens in new tab)</span></a><strong><em> (ICRA 2024), the premier international forum for robotics research.</em></strong></p>\n\n\n\n<figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1401\" height=\"788\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICRA_RASCAL2024-BlogHeroFeature-1400x788-1.png\" alt=\"White ICRA 2024 logo on teal background. On the right, the featured paper (RASCAL).\" class=\"wp-image-1032588\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICRA_RASCAL2024-BlogHeroFeature-1400x788-1.png 1401w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICRA_RASCAL2024-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICRA_RASCAL2024-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICRA_RASCAL2024-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICRA_RASCAL2024-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICRA_RASCAL2024-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICRA_RASCAL2024-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICRA_RASCAL2024-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICRA_RASCAL2024-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICRA_RASCAL2024-BlogHeroFeature-1400x788-1-1280x720.png 1280w\" sizes=\"(max-width: 1401px) 100vw, 1401px\" /></figure>\n\n\n\n<p>Over the past decade, robotics has revolutionized numerous industries that rely on storage systems, such as manufacturing and warehousing. In these contexts, robotics streamlines operations and increase efficiency, and automated storage and retrieval systems (ASRS) are at the heart of this technological shift, exemplifying the transition to smarter, computer-controlled logistics solutions. These systems quickly move items from storage to fulfilment stations, helping to increase speed and accuracy in the overall process. Yet despite these advances, current ASRS—whether rail-based, fixed, or free-roaming—continue to face challenges, often sacrificing scalability and availability for higher throughput capacity. For instance, the use of fixed robots in traditional tape storage libraries, typically used for archival storage, can lead to availability limitations, as the robots cannot pass each other, and a single robot failure can restrict access to a significant portion of the library.</p>\n\n\n\n<p>Our paper, published at ICRA 2024, introduces <a href=\"https://www.microsoft.com/en-us/research/publication/rascal/\">RASCAL: A Scalable, High-redundancy Robot for Automated Storage and Retrieval Systems</a>, which addresses these concerns. RASCAL is an untethered robot that improves the efficiency of vertical storage systems by operating across evenly spaced, parallel shelves and horizontal rails. Designed to maximize scalability and redundancy, it handles the storage and retrieval of small objects. RASCAL was inspired by the challenges of managing archival storage media in datacenters, and it’s the key component of <a href=\"https://www.microsoft.com/en-us/research/project/project-silica/\" target=\"_blank\" rel=\"noreferrer noopener\">Project Silica</a>’s storage and retrieval system. However, RASCAL’s modularity enables it to be used in other scenarios as well.&nbsp;</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"an-innovative-approach-to-archival-storage\">An innovative approach to archival storage</h3>\n\n\n\n<p>RASCAL&#8217;s design is based on four key principles:</p>\n\n\n\n<ul>\n<li><strong>Addressability</strong>: This allows any robot to access any item being stored on the shelves.&nbsp;</li>\n\n\n\n<li><strong>Scalability</strong>: The system can adjust retrieval capacity and storage space by adding or removing robots and shelving with negligible downtime.&nbsp;&nbsp;</li>\n\n\n\n<li><strong>Availability</strong>: A single robot failure minimally impacts access to items and routing, and it does not obstruct the operation of other robots.&nbsp;&nbsp;</li>\n\n\n\n<li><strong>Serviceability</strong>: Robots can easily be added or removed from the rails without the need for special training.&nbsp; &nbsp;</li>\n</ul>\n\n\n\n<p>RASCAL&#8217;s motion system supports horizontal and vertical movement along storage panels assembled from contiguous storage racks. The parallel rail system enables independent and flexible movement. These rails are designed to be <em>passive</em>—functioning without the need for active power or energy sources, relying instead on their physical structure and positioning to guide and support the robot’s movement along the storage panels. The robot can travel along and between these rails using various pathways to reach a given item. Video 1 shows how RASCAL operates multiple robots on a single storage panel.</p>\n\n\n\n<figure class=\"wp-block-embed aligncenter is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<iframe loading=\"lazy\" title=\"RASCAL full demo\" width=\"500\" height=\"281\" src=\"https://www.youtube-nocookie.com/embed/vKAGqDssWHo?feature=oembed&rel=0\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n</div><figcaption class=\"wp-element-caption\">Video 1. Multiple robots in action</figcaption></figure>\n\n\n\n<p>RASCAL utilizes a special rail geometry, allowing the robot to passively latch onto the rails with opposing wheels mounted on each end, as illustrated in Figure 1. This design ensures that the robot is securely held in place by gravity alone. The passive nature of this latching mechanism simplifies the process of adding or removing robots from the rails, as it does not require any tools or power.</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1400\" height=\"788\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RASCAL-Library_1400x788.jpg\" alt=\"Picture of a RASCAL prototype mounted on a Silica library. The library is composed of a series of connected storage racks that hold glass media. The storage panel's front has parallel rails mounted horizontally to allow the robot to move vertically and horizontally. RASCAL uses a pair of opposing wheels to latch onto these rails. \" class=\"wp-image-1032600\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RASCAL-Library_1400x788.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RASCAL-Library_1400x788-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RASCAL-Library_1400x788-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RASCAL-Library_1400x788-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RASCAL-Library_1400x788-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RASCAL-Library_1400x788-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RASCAL-Library_1400x788-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RASCAL-Library_1400x788-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RASCAL-Library_1400x788-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/RASCAL-Library_1400x788-1280x720.jpg 1280w\" sizes=\"(max-width: 1400px) 100vw, 1400px\" /><figcaption class=\"wp-element-caption\">Figure 1. The RASCAL prototype in a Silica library.</figcaption></figure>\n\n\n\n<p>The robot features two rotating assemblies known as <em>wings</em>, each equipped with wheels that allow it to move horizontally. The wings rotate in a choreographed sequence to enable ascent and descent. RASCAL climbs by unlatching one wing from its current rail while remaining attached to the other. It then rotates and secures its free wing to a new rail either two levels up or down. This is shown in Video 2.</p>\n\n\n\n<div style=\"padding-bottom:0; padding-top:0\" class=\"wp-block-msr-immersive-section alignfull row wp-block-msr-immersive-section\">\n\t\n\t<div class=\"container\">\n\t\t<div class=\"wp-block-msr-immersive-section__inner\">\n\t\t\t<div class=\"wp-block-columns is-layout-flex wp-container-core-columns-is-layout-1 wp-block-columns-is-layout-flex\">\n<div class=\"wp-block-column is-layout-flow wp-block-column-is-layout-flow\">\n<figure class=\"wp-block-embed aligncenter is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<iframe loading=\"lazy\" title=\"RASCAL climbing demo\" width=\"500\" height=\"281\" src=\"https://www.youtube-nocookie.com/embed/LhBlBMXO9tw?feature=oembed&rel=0\" frameborder=\"0\" allowfullscreen></iframe>\n</div><figcaption class=\"wp-element-caption\">Video 2. RASCAL’s novel climbing maneuver.</figcaption></figure>\n</div>\n\n\n\n<div class=\"wp-block-column is-layout-flow wp-block-column-is-layout-flow\">\n<figure class=\"wp-block-embed aligncenter is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<iframe loading=\"lazy\" title=\"RASCAL picking demo\" width=\"500\" height=\"281\" src=\"https://www.youtube-nocookie.com/embed/09n5b6cFlvw?feature=oembed&rel=0\" frameborder=\"0\" allowfullscreen></iframe>\n</div><figcaption class=\"wp-element-caption\">Video 3. RASCAL performing a pick operation.</figcaption></figure>\n</div>\n</div>\t\t</div>\n\t</div>\n\n\t</div>\n\n\n\n<p>Video 3 demonstrates RASCAL&#8217;s item-selection system, or <em>picker interface</em>, which is designed to handle various robotic tool attachments for precise pick-and-place operations. This interface can rotate in alternating directions during climbs, ensuring that the robotic tool attachment, or <em>end effector</em>, remains oriented towards the shelving while stationary, preventing the cables from tangling.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"advancing-robotics-and-automation\">Advancing robotics and automation</h3>\n\n\n\n<p>As digital economies grow, the need for efficient storage and retrieval systems becomes increasingly urgent. Breakthroughs in robotics technology are poised to drive productivity, efficiency, and innovation across numerous industries. Developments like RASCAL, with its flexible design and advanced capabilities, are leading the way for the next generation of robotics and automation.</p>\n\n\n\n\t<div class=\"border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide\" data-bi-aN=\"promo\" data-bi-id=\"956160\">\n\t\t\n\n\t\t<p class=\"msr-promo__label text-gray-800 text-center text-uppercase\">\n\t\t<span class=\"px-4 bg-white display-inline-block font-weight-semibold small\">Microsoft Research Podcast</span>\n\t</p>\n\t\n\t<div class=\"row pt-3 pb-4 align-items-center\">\n\t\t\t\t\t\t<div class=\"msr-promo__media col-12 col-md-5\">\n\t\t\t\t<a class=\"bg-gray-300\" href=\"https://www.microsoft.com/en-us/research/podcast/collaborators-renewable-energy-storage-with-bichlien-nguyen-and-david-kwabi/\" aria-label=\"Collaborators: Renewable energy storage with Bichlien Nguyen and David Kwabi\" data-bi-cN=\"Collaborators: Renewable energy storage with Bichlien Nguyen and David Kwabi\" target=\"_blank\">\n\t\t\t\t\t<img decoding=\"async\" class=\"w-100 display-block\" src=\"https://www.microsoft.com/en-us/research/uploads/prod/2023/06/collaboratorsEP2_hero_1400x788.jpg\" />\n\t\t\t\t</a>\n\t\t\t</div>\n\t\t\t\n\t\t\t<div class=\"msr-promo__content p-3 px-5 col-12 col-md\">\n\n\t\t\t\t\t\t\t\t\t<h2 class=\"h4\">Collaborators: Renewable energy storage with Bichlien Nguyen and David Kwabi</h2>\n\t\t\t\t\n\t\t\t\t\t\t\t\t<p class=\"large\">Dr. Bichlien Nguyen and Dr. David Kwabi explore their work in flow batteries and how machine learning can help more effectively search the vast organic chemistry space to identify compounds with properties just right for storing waterpower and other renewables.</p>\n\t\t\t\t\n\t\t\t\t\t\t\t\t<div class=\"wp-block-buttons justify-content-center justify-content-md-start\">\n\t\t\t\t\t<div class=\"wp-block-button\">\n\t\t\t\t\t\t<a href=\"https://www.microsoft.com/en-us/research/podcast/collaborators-renewable-energy-storage-with-bichlien-nguyen-and-david-kwabi/\" class=\"btn btn-brand glyph-append glyph-append-chevron-right\" aria-label=\"Listen now\" data-bi-cN=\"Collaborators: Renewable energy storage with Bichlien Nguyen and David Kwabi\" target=\"_blank\">\n\t\t\t\t\t\t\tListen now\t\t\t\t\t\t</a>\n\t\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t\t\t\t</div><!--/.msr-promo__content-->\n\t</div><!--/.msr-promo__inner-wrap-->\n<span id=\"label-external-link\" class=\"sr-only\" aria-hidden=\"true\">Opens in a new tab</span>\t</div><!--/.msr-promo-->\n\t<span id=\"label-external-link\" class=\"sr-only\" aria-hidden=\"true\">Opens in a new tab</span>",
            "protected": false
        },
        "excerpt": {
            "rendered": "<p>RASCAL is an untethered robot with a modular design, allowing it to move flexibly along and between evenly spaced storage shelves. Discover how it can address the availability and scalability challenges of existing automated storage and retrieval systems.</p>\n",
            "protected": false
        },
        "author": 42735,
        "featured_media": 1032588,
        "comment_status": "closed",
        "ping_status": "closed",
        "sticky": false,
        "template": "",
        "format": "standard",
        "meta": {
            "msr-url-field": "",
            "msr-podcast-episode": "",
            "msrModifiedDate": "",
            "msrModifiedDateEnabled": false,
            "ep_exclude_from_search": false,
            "footnotes": ""
        },
        "categories": [
            1
        ],
        "tags": [],
        "research-area": [
            13555
        ],
        "msr-region": [],
        "msr-event-type": [],
        "msr-post-option": [
            243984
        ],
        "msr-impact-theme": [],
        "msr-promo-type": [],
        "msr-podcast-series": [],
        "msr_event_details": {
            "start": "",
            "end": "",
            "location": ""
        },
        "podcast_url": "",
        "podcast_episode": "",
        "msr_research_lab": [
            199561
        ],
        "msr_impact_theme": [],
        "related-publications": [],
        "related-downloads": [],
        "related-videos": [],
        "related-academic-programs": [],
        "related-groups": [],
        "related-projects": [
            955254,
            433749
        ],
        "related-events": [],
        "related-researchers": [
            {
                "type": "user_nicename",
                "value": "Richard Black",
                "user_id": 33417,
                "display_name": "Richard Black",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/rjblack/\" aria-label=\"Visit the profile page for Richard Black\">Richard Black</a>",
                "is_active": false,
                "last_first": "Black, Richard",
                "people_section": 0,
                "alias": "rjblack"
            },
            {
                "type": "user_nicename",
                "value": "Marco Caballero",
                "user_id": 41281,
                "display_name": "Marco Caballero",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/t-mgutierrez/\" aria-label=\"Visit the profile page for Marco Caballero\">Marco Caballero</a>",
                "is_active": false,
                "last_first": "Caballero, Marco",
                "people_section": 0,
                "alias": "t-mgutierrez"
            },
            {
                "type": "user_nicename",
                "value": "Andromachi Chatzieleftheriou",
                "user_id": 37833,
                "display_name": "Andromachi Chatzieleftheriou",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/anchatzi/\" aria-label=\"Visit the profile page for Andromachi Chatzieleftheriou\">Andromachi Chatzieleftheriou</a>",
                "is_active": false,
                "last_first": "Chatzieleftheriou, Andromachi",
                "people_section": 0,
                "alias": "anchatzi"
            },
            {
                "type": "user_nicename",
                "value": "Ant Rowstron",
                "user_id": 31061,
                "display_name": "Ant Rowstron",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/antr/\" aria-label=\"Visit the profile page for Ant Rowstron\">Ant Rowstron</a>",
                "is_active": false,
                "last_first": "Rowstron, Ant",
                "people_section": 0,
                "alias": "antr"
            },
            {
                "type": "user_nicename",
                "value": "David Sweeney",
                "user_id": 31553,
                "display_name": "David Sweeney",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/dasweene/\" aria-label=\"Visit the profile page for David Sweeney\">David Sweeney</a>",
                "is_active": false,
                "last_first": "Sweeney, David",
                "people_section": 0,
                "alias": "dasweene"
            },
            {
                "type": "user_nicename",
                "value": "Hugh Williams",
                "user_id": 32055,
                "display_name": "Hugh Williams",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/hughwi/\" aria-label=\"Visit the profile page for Hugh Williams\">Hugh Williams</a>",
                "is_active": false,
                "last_first": "Williams, Hugh",
                "people_section": 0,
                "alias": "hughwi"
            }
        ],
        "msr_type": "Post",
        "featured_image_thumbnail": "<img width=\"960\" height=\"540\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICRA_RASCAL2024-BlogHeroFeature-1400x788-1-960x540.png\" class=\"img-object-cover\" alt=\"ICRA 2024 conference recap blog - RASCAL library\" decoding=\"async\" loading=\"lazy\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICRA_RASCAL2024-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICRA_RASCAL2024-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICRA_RASCAL2024-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICRA_RASCAL2024-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICRA_RASCAL2024-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICRA_RASCAL2024-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICRA_RASCAL2024-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICRA_RASCAL2024-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICRA_RASCAL2024-BlogHeroFeature-1400x788-1-1280x720.png 1280w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICRA_RASCAL2024-BlogHeroFeature-1400x788-1.png 1401w\" sizes=\"(max-width: 960px) 100vw, 960px\" />",
        "byline": "",
        "formattedDate": "May 14, 2024",
        "formattedExcerpt": "RASCAL is an untethered robot with a modular design, allowing it to move flexibly along and between evenly spaced storage shelves. Discover how it can address the availability and scalability challenges of existing automated storage and retrieval systems.",
        "_links": {
            "self": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1032576"
                }
            ],
            "collection": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts"
                }
            ],
            "about": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/types/post"
                }
            ],
            "author": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/users/42735"
                }
            ],
            "replies": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/comments?post=1032576"
                }
            ],
            "version-history": [
                {
                    "count": 33,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1032576/revisions"
                }
            ],
            "predecessor-version": [
                {
                    "id": 1033848,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1032576/revisions/1033848"
                }
            ],
            "wp:featuredmedia": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/media/1032588"
                }
            ],
            "wp:attachment": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/media?parent=1032576"
                }
            ],
            "wp:term": [
                {
                    "taxonomy": "category",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/categories?post=1032576"
                },
                {
                    "taxonomy": "post_tag",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/tags?post=1032576"
                },
                {
                    "taxonomy": "msr-research-area",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/research-area?post=1032576"
                },
                {
                    "taxonomy": "msr-region",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-region?post=1032576"
                },
                {
                    "taxonomy": "msr-event-type",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-event-type?post=1032576"
                },
                {
                    "taxonomy": "msr-post-option",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-post-option?post=1032576"
                },
                {
                    "taxonomy": "msr-impact-theme",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-impact-theme?post=1032576"
                },
                {
                    "taxonomy": "msr-promo-type",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-promo-type?post=1032576"
                },
                {
                    "taxonomy": "msr-podcast-series",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-podcast-series?post=1032576"
                }
            ],
            "curies": [
                {
                    "name": "wp",
                    "href": "https://api.w.org/{rel}",
                    "templated": true
                }
            ]
        }
    },
    {
        "id": 1031883,
        "date": "2024-05-13T09:00:00",
        "date_gmt": "2024-05-13T16:00:00",
        "guid": {
            "rendered": "https://www.microsoft.com/en-us/research/?p=1031883"
        },
        "modified": "2024-05-13T09:02:53",
        "modified_gmt": "2024-05-13T16:02:53",
        "slug": "mattersim-a-deep-learning-model-for-materials-under-real-world-conditions",
        "status": "publish",
        "type": "post",
        "link": "https://www.microsoft.com/en-us/research/blog/mattersim-a-deep-learning-model-for-materials-under-real-world-conditions/",
        "title": {
            "rendered": "MatterSim: A deep-learning model for materials under real-world conditions"
        },
        "content": {
            "rendered": "\n<figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1400\" height=\"788\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/NEWMatterSim2024-BlogHeroFeature-1400x788-1.png\" alt=\"The image features a complex network of interconnected nodes with a molecular structure, illuminated in blue against a dark background.\" class=\"wp-image-1033260\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/NEWMatterSim2024-BlogHeroFeature-1400x788-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/NEWMatterSim2024-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/NEWMatterSim2024-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/NEWMatterSim2024-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/NEWMatterSim2024-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/NEWMatterSim2024-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/NEWMatterSim2024-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/NEWMatterSim2024-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/NEWMatterSim2024-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/NEWMatterSim2024-BlogHeroFeature-1400x788-1-1280x720.png 1280w\" sizes=\"(max-width: 1400px) 100vw, 1400px\" /></figure>\n\n\n\n<p>In the quest for groundbreaking materials crucial to nanoelectronics, energy storage, and healthcare, a critical challenge looms: predicting a material’s properties before it is even created. This is no small feat, with any combination of 118 elements in the periodic table, and the range of temperatures and pressures under which materials are synthesized and operated. These factors drastically affect atomic interactions within materials, making accurate property prediction and behavior simulation exceedingly demanding.</p>\n\n\n\n<p>Here at Microsoft Research, we developed <a href=\"https://www.microsoft.com/en-us/research/publication/mattersim-a-deep-learning-atomistic-model-across-elements-temperatures-and-pressures/\">MatterSim</a>, a deep-learning model for accurate and efficient materials simulation and property prediction over a broad range of elements, temperatures, and pressures to enable the <em>in silico</em> materials design. MatterSim employs deep learning to understand atomic interactions&nbsp;from the very fundamental principles of quantum mechanics, across a comprehensive spectrum of elements and conditions—from 0 to 5,000 Kelvin (K), and from standard atmospheric pressure to 10,000,000 atmospheres. In our experiment, MatterSim efficiently handles simulations for a variety of materials, including metals, oxides, sulfides, halides, and their various states such as crystals, amorphous solids, and liquids. Additionally, it offers customization options for intricate prediction tasks by incorporating user-provided data.</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1400\" height=\"450\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/MatterSim-figure1-1400x450-1.png\" alt=\"Figure 1: There are two subfigures. On the left-hand side, atomic structures of 12 materials belonging to metals, oxides, sulfides, halides, and organic molecules are shown. On the right-hand side, the temperature and pressure ranges of materials' application and synthesis are plotted.\" class=\"wp-image-1031901\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/MatterSim-figure1-1400x450-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/MatterSim-figure1-1400x450-1-300x96.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/MatterSim-figure1-1400x450-1-1024x329.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/MatterSim-figure1-1400x450-1-768x247.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/MatterSim-figure1-1400x450-1-240x77.png 240w\" sizes=\"(max-width: 1400px) 100vw, 1400px\" /><figcaption class=\"wp-element-caption\">Figure 1. MatterSim can model materials properties and behaviors under realistic temperature and pressure conditions for wide ranges of applications.</figcaption></figure>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"simulating-materials-under-realistic-conditions-across-the-periodic-table\">Simulating materials under realistic conditions across the periodic table</h3>\n\n\n\n<p>MatterSim&#8217;s learning foundation is built on large-scale synthetic data, generated through a blend of active learning, generative models, and molecular dynamics simulations. This data generation strategy ensures extensive coverage of material space, enabling the model to predict energies, atomic forces, and stresses. It serves as a machine-learning force field with a level of accuracy compatible with first-principles predictions. Notably, MatterSim achieves a10-fold increase in accuracy for material property predictions at finite temperatures and pressures when compared to previous state-of-the-art models. Our research demonstrates its proficiency in simulating a vast array of material properties, including thermal, mechanical, and transport properties, and can even predict phase diagrams.</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1400\" height=\"451\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/MatterSim-figure2-1400x450-1.png\" alt=\"Figure 2: There are three subfigures. The panel on the left shows a comparison of the highest phonon frequency predicted by MatterSim and by first-principles methods. The two values are for each material is very close, leading to a nearly straight line in the parity plot. The middle panel depicts the same relation of free energies of around 50 materials and comparison between MatterSim and first-principles results. The right panel shows the phase diagram of MgO predicted using MatterSim. The x-axis denotes the temperature and the y-axis denotes the pressure. The pressure ranges of where MgO’s B1 phase is below 500 GPa and this range decreases with temperature increase. The blue lines show the prediction from MatterSim and fits well with the shaded region which is the result from experiment measurement.\" class=\"wp-image-1031904\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/MatterSim-figure2-1400x450-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/MatterSim-figure2-1400x450-1-300x97.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/MatterSim-figure2-1400x450-1-1024x330.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/MatterSim-figure2-1400x450-1-768x247.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/MatterSim-figure2-1400x450-1-240x77.png 240w\" sizes=\"(max-width: 1400px) 100vw, 1400px\" /><figcaption class=\"wp-element-caption\">Figure 2. MatterSim achieves high accuracy in predicting mechanical properties, vibrational properties, and phases diagrams of material comparable to quantum mechanics and experimental measurements. The figure shows the comparison between the predicted properties and the experimental measured results.&nbsp;</figcaption></figure>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"adapting-to-complex-design-tasks\">Adapting to complex design tasks</h3>\n\n\n\n<p>While trained on broad synthetic datasets, MatterSim is also adaptable for specific design requirements by incorporating additional data. The model utilizes active learning and fine-tuning to customize predictions with high data efficiency. For example, simulating water properties — a task seemingly straightforward but computationally intensive — is significantly optimized with MatterSim’s adaptive capability. The model requires only 3% of the data compared to traditional methods, to match experimental accuracy that would otherwise require 30 times more resources for a specialized model and exponentially more for first-principles methods.</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1400\" height=\"451\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/MatterSim-figure3-1400x450-1.png\" alt=\"Figure 3: There are two panels in this figure. The right panel shows the structure of Li2B12H12, a complex material system used for solid-state batteries. This system is used in the benchmark of the performance of MatterSim. The left panel panels show the comparison between number of data point needed to train a model from scratch and customize from MatterSim to achieve the same accuracy. MatterSim requires 3% and 10% of the data for the two tasks compared with training from scratch.\" class=\"wp-image-1031907\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/MatterSim-figure3-1400x450-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/MatterSim-figure3-1400x450-1-300x97.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/MatterSim-figure3-1400x450-1-1024x330.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/MatterSim-figure3-1400x450-1-768x247.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/MatterSim-figure3-1400x450-1-240x77.png 240w\" sizes=\"(max-width: 1400px) 100vw, 1400px\" /><figcaption class=\"wp-element-caption\">Figure 3. MatterSim achieves high data efficiency with 90%-97% data save for complex simulation tasks.</figcaption></figure>\n\n\n\n\t<div class=\"border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide\" data-bi-aN=\"promo\" data-bi-id=\"956142\">\n\t\t\n\n\t\t<p class=\"msr-promo__label text-gray-800 text-center text-uppercase\">\n\t\t<span class=\"px-4 bg-white display-inline-block font-weight-semibold small\">Microsoft Research Podcast</span>\n\t</p>\n\t\n\t<div class=\"row pt-3 pb-4 align-items-center\">\n\t\t\t\t\t\t<div class=\"msr-promo__media col-12 col-md-5\">\n\t\t\t\t<a class=\"bg-gray-300\" href=\"https://www.microsoft.com/en-us/research/podcast/collaborators-holoportation-communication-technology-with-spencer-fowers-and-kwame-darko/\" aria-label=\"Collaborators: Holoportation™ communication technology with Spencer Fowers and Kwame Darko\" data-bi-cN=\"Collaborators: Holoportation™ communication technology with Spencer Fowers and Kwame Darko\" target=\"_blank\">\n\t\t\t\t\t<img decoding=\"async\" class=\"w-100 display-block\" src=\"https://www.microsoft.com/en-us/research/uploads/prod/2023/06/collaborators_3DTelemed_1400x788.jpg\" />\n\t\t\t\t</a>\n\t\t\t</div>\n\t\t\t\n\t\t\t<div class=\"msr-promo__content p-3 px-5 col-12 col-md\">\n\n\t\t\t\t\t\t\t\t\t<h2 class=\"h4\">Collaborators: Holoportation™ communication technology with Spencer Fowers and Kwame Darko</h2>\n\t\t\t\t\n\t\t\t\t\t\t\t\t<p class=\"large\">Spencer Fowers and Kwame Darko break down how the technology behind Holoportation and the telecommunication device being built around it brings patients and doctors together when being in the same room isn’t an easy option and discuss the potential impact of the work.</p>\n\t\t\t\t\n\t\t\t\t\t\t\t\t<div class=\"wp-block-buttons justify-content-center justify-content-md-start\">\n\t\t\t\t\t<div class=\"wp-block-button\">\n\t\t\t\t\t\t<a href=\"https://www.microsoft.com/en-us/research/podcast/collaborators-holoportation-communication-technology-with-spencer-fowers-and-kwame-darko/\" class=\"btn btn-brand glyph-append glyph-append-chevron-right\" aria-label=\"Listen now\" data-bi-cN=\"Collaborators: Holoportation™ communication technology with Spencer Fowers and Kwame Darko\" target=\"_blank\">\n\t\t\t\t\t\t\tListen now\t\t\t\t\t\t</a>\n\t\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t\t\t\t</div><!--/.msr-promo__content-->\n\t</div><!--/.msr-promo__inner-wrap-->\n<span id=\"label-external-link\" class=\"sr-only\" aria-hidden=\"true\">Opens in a new tab</span>\t</div><!--/.msr-promo-->\n\t\n\n\n<h3 class=\"wp-block-heading\" id=\"bridging-the-gap-between-atomistic-models-and-real-world-measurements\">Bridging the gap between atomistic models and real-world measurements</h3>\n\n\n\n<p>Translating material properties from atomic structures is a complex task, often too intricate for current methods based on statistics, such as molecular dynamics. MatterSim addresses this by mapping these relationships directly through machine learning. It&nbsp;incorporates custom adaptor modules that refine the model to predict material properties from structural data, eliminating the need for intricate simulations. Benchmarking against <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://matbench.materialsproject.org/\" target=\"_blank\" rel=\"noreferrer noopener\">MatBench<span class=\"sr-only\"> (opens in new tab)</span></a>, a renowned material property prediction benchmark set, MatterSim demonstrates significant accuracy improvement and outperforms all specialized property-specific models, showcasing its robust capability in direct material property prediction from domain-specific data.</p>\n\n\n\n<h3 class=\"wp-block-heading\" id=\"looking-ahead\">Looking ahead&nbsp;</h3>\n\n\n\n<p>As MatterSim research advances, the emphasis is on experimental validation to reinforce its potential role in pivotal sectors, including the design of catalysts for sustainability, energy storage breakthroughs, and nanotechnology advancements. The planned integration of MatterSim with <a href=\"https://www.microsoft.com/en-us/research/blog/distributional-graphormer-toward-equilibrium-distribution-prediction-for-molecular-systems/\" target=\"_blank\" rel=\"noreferrer noopener\">generative AI</a> models and reinforcement learning heralds a new era in the systematic pursuit of novel materials. This synergy is expected to revolutionize the field, streamlining <a href=\"https://www.microsoft.com/en-us/research/blog/mattergen-property-guided-materials-design/\" target=\"_blank\" rel=\"noreferrer noopener\">guided creation of materials</a> tailored for diverse applications ranging from semiconductor technologies to biomedical engineering. Such progress promises to expedite material development and bolster sustainable industrial practices, thereby fostering technological advancements that will benefit society.&nbsp;</p>\n<span id=\"label-external-link\" class=\"sr-only\" aria-hidden=\"true\">Opens in a new tab</span>",
            "protected": false
        },
        "excerpt": {
            "rendered": "<p>Property prediction for materials under realistic conditions has been a long-standing challenge within the digital transformation of materials design. MatterSim investigates atomic interactions from the very fundamental principles of quantum mechanics.</p>\n",
            "protected": false
        },
        "author": 42735,
        "featured_media": 1033260,
        "comment_status": "closed",
        "ping_status": "closed",
        "sticky": false,
        "template": "",
        "format": "standard",
        "meta": {
            "msr-url-field": "",
            "msr-podcast-episode": "",
            "msrModifiedDate": "",
            "msrModifiedDateEnabled": false,
            "ep_exclude_from_search": false,
            "footnotes": ""
        },
        "categories": [
            1
        ],
        "tags": [],
        "research-area": [
            13556
        ],
        "msr-region": [],
        "msr-event-type": [],
        "msr-post-option": [
            243984
        ],
        "msr-impact-theme": [],
        "msr-promo-type": [],
        "msr-podcast-series": [],
        "msr_event_details": {
            "start": "",
            "end": "",
            "location": ""
        },
        "podcast_url": "",
        "podcast_episode": "",
        "msr_research_lab": [
            199560
        ],
        "msr_impact_theme": [],
        "related-publications": [],
        "related-downloads": [],
        "related-videos": [],
        "related-academic-programs": [],
        "related-groups": [],
        "related-projects": [],
        "related-events": [],
        "related-researchers": [
            {
                "type": "user_nicename",
                "value": "Han Yang",
                "user_id": 42288,
                "display_name": "Han Yang",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/hanyang/\" aria-label=\"Visit the profile page for Han Yang\">Han Yang</a>",
                "is_active": false,
                "last_first": "Yang, Han",
                "people_section": 0,
                "alias": "hanyang"
            },
            {
                "type": "user_nicename",
                "value": "Jielan Li",
                "user_id": 43308,
                "display_name": "Jielan Li",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/jielanli/\" aria-label=\"Visit the profile page for Jielan Li\">Jielan Li</a>",
                "is_active": false,
                "last_first": "Li, Jielan",
                "people_section": 0,
                "alias": "jielanli"
            },
            {
                "type": "user_nicename",
                "value": "Hongxia Hao",
                "user_id": 42498,
                "display_name": "Hongxia Hao",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/hongxiahao/\" aria-label=\"Visit the profile page for Hongxia Hao\">Hongxia Hao</a>",
                "is_active": false,
                "last_first": "Hao, Hongxia",
                "people_section": 0,
                "alias": "hongxiahao"
            },
            {
                "type": "user_nicename",
                "value": "Ziheng Lu",
                "user_id": 41422,
                "display_name": "Ziheng Lu",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/zihenglu/\" aria-label=\"Visit the profile page for Ziheng Lu\">Ziheng Lu</a>",
                "is_active": false,
                "last_first": "Lu, Ziheng",
                "people_section": 0,
                "alias": "zihenglu"
            }
        ],
        "msr_type": "Post",
        "featured_image_thumbnail": "<img width=\"960\" height=\"540\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/NEWMatterSim2024-BlogHeroFeature-1400x788-1-960x540.png\" class=\"img-object-cover\" alt=\"The image features a complex network of interconnected nodes with a molecular structure, illuminated in blue against a dark background.\" decoding=\"async\" loading=\"lazy\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/NEWMatterSim2024-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/NEWMatterSim2024-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/NEWMatterSim2024-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/NEWMatterSim2024-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/NEWMatterSim2024-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/NEWMatterSim2024-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/NEWMatterSim2024-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/NEWMatterSim2024-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/NEWMatterSim2024-BlogHeroFeature-1400x788-1-1280x720.png 1280w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/NEWMatterSim2024-BlogHeroFeature-1400x788-1.png 1400w\" sizes=\"(max-width: 960px) 100vw, 960px\" />",
        "byline": "<a href=\"https://www.microsoft.com/en-us/research/people/hanyang/\" title=\"Go to researcher profile for Han Yang\" aria-label=\"Go to researcher profile for Han Yang\" data-bi-type=\"byline author\" data-bi-cN=\"Han Yang\">Han Yang</a>, <a href=\"https://www.microsoft.com/en-us/research/people/jielanli/\" title=\"Go to researcher profile for Jielan Li\" aria-label=\"Go to researcher profile for Jielan Li\" data-bi-type=\"byline author\" data-bi-cN=\"Jielan Li\">Jielan Li</a>, <a href=\"https://www.microsoft.com/en-us/research/people/hongxiahao/\" title=\"Go to researcher profile for Hongxia Hao\" aria-label=\"Go to researcher profile for Hongxia Hao\" data-bi-type=\"byline author\" data-bi-cN=\"Hongxia Hao\">Hongxia Hao</a>, and <a href=\"https://www.microsoft.com/en-us/research/people/zihenglu/\" title=\"Go to researcher profile for Ziheng Lu\" aria-label=\"Go to researcher profile for Ziheng Lu\" data-bi-type=\"byline author\" data-bi-cN=\"Ziheng Lu\">Ziheng Lu</a>",
        "formattedDate": "May 13, 2024",
        "formattedExcerpt": "Property prediction for materials under realistic conditions has been a long-standing challenge within the digital transformation of materials design. MatterSim investigates atomic interactions from the very fundamental principles of quantum mechanics.",
        "_links": {
            "self": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1031883"
                }
            ],
            "collection": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts"
                }
            ],
            "about": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/types/post"
                }
            ],
            "author": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/users/42735"
                }
            ],
            "replies": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/comments?post=1031883"
                }
            ],
            "version-history": [
                {
                    "count": 19,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1031883/revisions"
                }
            ],
            "predecessor-version": [
                {
                    "id": 1033374,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1031883/revisions/1033374"
                }
            ],
            "wp:featuredmedia": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/media/1033260"
                }
            ],
            "wp:attachment": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/media?parent=1031883"
                }
            ],
            "wp:term": [
                {
                    "taxonomy": "category",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/categories?post=1031883"
                },
                {
                    "taxonomy": "post_tag",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/tags?post=1031883"
                },
                {
                    "taxonomy": "msr-research-area",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/research-area?post=1031883"
                },
                {
                    "taxonomy": "msr-region",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-region?post=1031883"
                },
                {
                    "taxonomy": "msr-event-type",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-event-type?post=1031883"
                },
                {
                    "taxonomy": "msr-post-option",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-post-option?post=1031883"
                },
                {
                    "taxonomy": "msr-impact-theme",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-impact-theme?post=1031883"
                },
                {
                    "taxonomy": "msr-promo-type",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-promo-type?post=1031883"
                },
                {
                    "taxonomy": "msr-podcast-series",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-podcast-series?post=1031883"
                }
            ],
            "curies": [
                {
                    "name": "wp",
                    "href": "https://api.w.org/{rel}",
                    "templated": true
                }
            ]
        }
    },
    {
        "id": 1022580,
        "date": "2024-05-13T09:00:00",
        "date_gmt": "2024-05-13T16:00:00",
        "guid": {
            "rendered": "https://www.microsoft.com/en-us/research/?p=1022580"
        },
        "modified": "2024-05-14T14:20:22",
        "modified_gmt": "2024-05-14T21:20:22",
        "slug": "enhanced-autoscaling-with-vasim-vertical-autoscaling-simulator-toolkit",
        "status": "publish",
        "type": "post",
        "link": "https://www.microsoft.com/en-us/research/blog/enhanced-autoscaling-with-vasim-vertical-autoscaling-simulator-toolkit/",
        "title": {
            "rendered": "Enhanced autoscaling with VASIM: Vertical Autoscaling Simulator Toolkit"
        },
        "content": {
            "rendered": "\n<p class=\"has-text-align-center\"><em><strong>This research was presented as a demonstration at the</strong></em><strong><em> </em></strong><a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://icde2024.github.io/\" target=\"_blank\" rel=\"noreferrer noopener\"><strong><em>40<sup>th</sup> IEEE International Conference on Data Engineering</em></strong><span class=\"sr-only\"> (opens in new tab)</span></a><strong><em> (ICDE 2024), one of the premier conferences on data and information engineering.</em></strong></p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1400\" height=\"788\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM-BlogHeroFeature-1400x788-1.jpg\" alt=\"ICDE conference logo, in white, on the left side of the graphic. To the right, the first page of the accepted paper, \"VASIM: Vertical Autoscaling Simulator Toolkit.” \n\nBackground: blue to purple to pink gradient. \" class=\"wp-image-1022622\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w\" sizes=\"(max-width: 1400px) 100vw, 1400px\" /></figure>\n\n\n\n<p>Since the inception of cloud computing, autoscaling has been an essential technique for optimizing resources and performance. By dynamically adjusting the number of computing resources allocated to a service based on current demand, autoscaling ensures that the service can handle the load efficiently while optimizing costs. However, developing and fine-tuning autoscaling algorithms, which govern this process, present significant challenges. The complexity and cost associated with testing these algorithms can lead to inefficient resource management and impede the development of more effective autoscaling strategies.</p>\n\n\n\n<div class=\"annotations \" data-bi-aN=\"margin-callout\">\n\t<ul class=\"annotations__list card depth-16 bg-body p-4 annotations__list--right\">\n\t\t<li class=\"annotations__list-item\">\n\t\t\t\t\t\t<span class=\"annotations__type d-block text-uppercase font-weight-semibold text-neutral-300 small\">Publication</span>\n\t\t\t<a href=\"https://www.microsoft.com/en-us/research/publication/vasim-vertical-autoscaling-simulator-toolkit/\" target=\"_self\" class=\"annotations__link font-weight-semibold text-decoration-none\" data-bi-type=\"annotated-link\" aria-label=\"VASIM: Vertical Autoscaling Simulator Toolkit\" data-bi-aN=\"margin-callout\" data-bi-cN=\"VASIM: Vertical Autoscaling Simulator Toolkit\">\n\t\t\t\tVASIM: Vertical Autoscaling Simulator Toolkit&nbsp;<span class=\"glyph-append glyph-append-chevron-right glyph-append-xsmall\"></span>\n\t\t\t</a>\n\t\t\t\t\t</li>\n\t</ul>\n</div>\n\n\n\n<p>In our paper, “<a href=\"https://www.microsoft.com/en-us/research/publication/vasim-vertical-autoscaling-simulator-toolkit/\">VASIM: Vertical Autoscaling Simulator Toolkit</a>,” presented at ICDE 2024, we introduce a tool designed to address the complexities involved in assessing autoscaling algorithms. While existing simulation tools cover a range of capabilities, such as energy efficiency and fault tolerance, VASIM stands out by evaluating the critical recommender component within the algorithm and suggesting optimal resource scaling actions based on usage data, balancing performance and cost. This enables developers to iterate more rapidly, enhancing algorithmic performance, and improving resource efficiency and cost savings.</p>\n\n\n\n<p>VASIM&#8217;s user-friendly interface simplifies the evaluation of autoscaling policies, as illustrated in Figure 1. First steps entail uploading historical data and defining autoscaling policies, including the algorithm and its parameters, shown in the left panel. The Simulation Run feature enables the modification of algorithm parameters, imported via a configuration file, and the execution of simulations based on the selected trace. A results screen displays the CPU limits determined by the selected policies as well as the actual CPU usage tailored to these limits. Additionally, VASIM provides fundamental metrics like throttling incidents, number of scaling operations, and amount of unused capacity, or <em>slack</em>, for the current simulation.</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><a data-bi-bhvr=\"14\"  data-bi-cn=\"[On the left] Image of VASIM user interface. On the left panel, it has options to select from “Simulation Run”, “Simulation Tuning”, “Simulation Tuning History”. Option “Simulation Run” is selected. Below user has loaded a trace from csv file on disk (c_26742_perf_event_log.csv), algorithm C, metadata config json file from disk. Button “Visualize workload” was clicked and loaded trace is displayed. \n\n[On the right] On the right panel, user picked other parameters for simulation run (lag – how often recommender gives decision and initial core count) and algorithm parameter from json are shown for edit. \n\nImage of VASIM UI when simulation was run for selected algorithm, trace and parameter setting. It shows a graph with cpu usage in blue and the limit calculated by selected algorithm in red. It is different from the trace plot that was shown before because calculated limits were below cpu utilization, so the latter was cut off. On top of the plot it shows metrics of the simulation like average slack, average insufficient CPU, sum slack, sum insufficient CPU, number of scalings, number of times of insufficient CPU etc.  \" href=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM_Fig1.png\"><img loading=\"lazy\" decoding=\"async\" width=\"2000\" height=\"666\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM_Fig1.png\" alt=\"[On the left] Image of VASIM user interface. On the left panel, it has options to select from “Simulation Run”, “Simulation Tuning”, “Simulation Tuning History”. Option “Simulation Run” is selected. Below user has loaded a trace from csv file on disk (c_26742_perf_event_log.csv), algorithm C, metadata config json file from disk. Button “Visualize workload” was clicked and loaded trace is displayed. \n\n[On the right] On the right panel, user picked other parameters for simulation run (lag – how often recommender gives decision and initial core count) and algorithm parameter from json are shown for edit. \n\nImage of VASIM UI when simulation was run for selected algorithm, trace and parameter setting. It shows a graph with cpu usage in blue and the limit calculated by selected algorithm in red. It is different from the trace plot that was shown before because calculated limits were below cpu utilization, so the latter was cut off. On top of the plot it shows metrics of the simulation like average slack, average insufficient CPU, sum slack, sum insufficient CPU, number of scalings, number of times of insufficient CPU etc.  \" class=\"wp-image-1022595\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM_Fig1.png 2000w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM_Fig1-300x100.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM_Fig1-1024x341.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM_Fig1-768x256.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM_Fig1-1536x511.png 1536w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM_Fig1-240x80.png 240w\" sizes=\"(max-width: 2000px) 100vw, 2000px\" /></a><figcaption class=\"wp-element-caption\">Figure 1. The VASIM user interface comprises a run simulation pane on the left and a results pane on the right.</figcaption></figure>\n\n\n\n<p>VASIM achieves several important goals:</p>\n\n\n\n<p><strong>Resource efficiency and cost reduction</strong>. VASIM reduces costs by removing the need to test scaling operations in real-time, which would be resource intensive. This enables developers to adjust algorithms iteratively in a controlled, cost-efficient environment, accelerating development cycles. Because the tool allows users to upload CPU performance history and algorithm parameters, it delivers the results of scaling operations across the entire workload in minutes rather than hours. </p>\n\n\n\n<p><strong>Multi-objective optimization</strong>. It’s challenging to develop an autoscaling method that handles conflicting parameters. VASIM makes this easier by applying <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://en.wikipedia.org/wiki/Pareto_front\" target=\"_blank\" rel=\"noreferrer noopener\">Pareto optimization techniques<span class=\"sr-only\"> (opens in new tab)</span></a>, helping developers to find a balance among key metrics. Figure 2 depicts scatter plots for two metrics: average slack and average insufficient CPU. It also shows three optimization objectives: the optimal amount of slack, throttling, and number of scaling operations.</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1224\" height=\"450\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM_Fig2.png\" alt=\"[On the left] A graph that plots the average slack on the Y axis and the average insufficient cpu on the X axis. It shows that the more average insufficient cpu decreases, the more average slack increases. There are six points in red that are pareto frontier points, all on the very edge of the graph but not too close to each other, showing some possible choices of configuration. \n\n[On the right] A 3D scatter plot displays the total slack on the X axis, cpu total throttle on the Y axis, and the amount of scalings in Z axis. It shows that as you aim to lower total slack and throttle, the amount of scalings increases.\" class=\"wp-image-1022601\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM_Fig2.png 1224w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM_Fig2-300x110.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM_Fig2-1024x376.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM_Fig2-768x282.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM_Fig2-240x88.png 240w\" sizes=\"(max-width: 1224px) 100vw, 1224px\" /><figcaption class=\"wp-element-caption\">Figure 2. The 2D diagram on the left shows a scatter plot of tuning with Pareto points. The 3D graph on the right shows a scatter plot with the three objectives.</figcaption></figure>\n\n\n\n<p><strong>Recommender algorithm testing</strong>. VASIM simplifies the process of testing and evaluating recommendation algorithms across diverse workloads. With all tuning jobs running in parallel, computation occurs more quickly, allowing users to efficiently adjust their recommender parameters as necessary. To assess the algorithm’s generalizability, we ran VASIM against 11 <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://github.com/alibaba/clusterdata\" target=\"_blank\" rel=\"noreferrer noopener\">available open cluster traces<span class=\"sr-only\"> (opens in new tab)</span></a> for benchmarking and internal product workload traces. This enabled us to evaluate the algorithms’ robustness across a variety of workload types, including cyclical, bursty, and monotonic variations, demonstrating their reliability across different scenarios.</p>\n\n\n\n<p><strong>Versatility and </strong><strong>a</strong><strong>daptability</strong>. VASIM provides users with the flexibility to modify components, experiment with recommendation strategies, and evaluate the impact of changes in a controlled and customizable environment. Figure 3 shows the results of a simulation run on the same algorithm and historical performance data but with different parameters. This versatility ensures that infrastructure engineers can tailor the system to meet their needs, enhancing the overall effectiveness of their autoscaling strategies.</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"897\" height=\"856\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure3.png\" alt=\"These graphs display VASIM running an identical algorithm on the same historical data but with varying parameters, affecting slack, throttling, and the frequency of scaling events. The objective is to maintain a minimal gap between the peak and the lowest resource utilization levels (the top of the bottom line and the bottom of the top line, respectively), and to reduce the space between the response lag indicated by the trailing edges to the left of the lines. Simultaneously, it's important to minimize the occurrence of scaling events to prevent disruptions in workload execution.\" class=\"wp-image-1031514\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure3.png 897w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure3-300x286.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure3-768x733.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/Figure3-189x180.png 189w\" sizes=\"(max-width: 897px) 100vw, 897px\" /><figcaption class=\"wp-element-caption\">Figure 3. These graphs show VASIM running an identical algorithm on the same historical data but with varying parameters, affecting slack, throttling, and the frequency of scaling events. The objective is to maintain a minimal gap between the peak and the lowest resource utilization levels—the top of the bottom line and the bottom of the top line, respectively. The goal is also to reduce the space between the response lag indicated by the trailing edges to the left of the lines. Simultaneously, it’s important to minimize the occurrence of scaling events to prevent disruptions in workload execution.</figcaption></figure>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"optimizing-scalability-and-costs-in-kubernetes-environments\">Optimizing scalability and costs in Kubernetes environments</h2>\n\n\n\n<p>Our research on <a href=\"https://www.microsoft.com/en-us/research/publication/caasper-vertical-autoscaling/\">vertically autoscaling monolithic applications with a container-as-a-service algorithm<span class=\"sr-only\"> (opens in new tab)</span></a> helped us to better understand the tradeoffs between cost and availability that different algorithm variations introduce. Because VASIM is similar to standard autoscaling architecture (as in the <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler\" target=\"_blank\" rel=\"noreferrer noopener\">Kubernetes Vertical Pod Autoscaler<span class=\"sr-only\"> (opens in new tab)</span></a> [VPA]) it allows us to test autoscaling algorithms for pods, applications, and virtual machine (VM) capacity. This is possible because these systems share similar components, including resource updaters, controllers, and recommenders. Despite differences in specific systems, their underlying architectures are sufficiently similar, enabling VASIM to effectively mimic them, as shown in Figure 4.</p>\n\n\n\n<h5 id=\"\" class=\"wp-block-heading\">&nbsp;</h5>\n\n\n\n<figure class=\"wp-block-image aligncenter size-large is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"588\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM_Fig4-1024x588.png\" alt=\"The image depicts how VASIM works. It has a Simulation Controller in the middle, which asks Recommender for decisions using one of the algorithms, Simulation Scaler with a scale function, Cloud State Provider to get traces and use them for time simulation, Analyzer to get metrics after each run. Params Tuning Controller tells Simulation Controller to run for every tuning setting and calls Analyzer to get pareto front to find tradeoff between multiple goals after multiple configs were evaluated. Recommender also needs data from Cloud State Provider to access historical data.  \" class=\"wp-image-1022616\" style=\"width:600px;height:auto\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM_Fig4-1024x588.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM_Fig4-300x172.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM_Fig4-768x441.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM_Fig4-1536x882.png 1536w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM_Fig4-240x138.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM_Fig4.png 2000w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /><figcaption class=\"wp-element-caption\">Figure 4. VASIM architecture mimics the main components of general autoscaling architectures, allowing users to parametrize those modules to fit their specific needs.</figcaption></figure>\n\n\n\n<h5 id=\"\" class=\"wp-block-heading\">&nbsp;</h5>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"implications-and-looking-ahead\">Implications and looking ahead</h2>\n\n\n\n<p>Looking forward, we plan to broaden the scope of VASIM&#8217;s support beyond just CPUs to include a wide range of resources, such as memory, disk I/O, and network bandwidth. This expansion will provide future users with a comprehensive understanding of system performance and enable them to make more accurate decisions regarding system management and resource optimization. Additionally, a deeper understanding of system performance will help inform proactive optimization strategies focused on maximizing system efficiency and performance.</p>\n<span id=\"label-external-link\" class=\"sr-only\" aria-hidden=\"true\">Opens in a new tab</span>",
            "protected": false
        },
        "excerpt": {
            "rendered": "<p>Autoscaling can optimize cloud resource usage and costs by adjusting to demand. VASIM shows that simplifying testing and refinement of autoscaling algorithms can enable rapid development and evaluation of more efficient & cost-effective autoscaling strategies. </p>\n",
            "protected": false
        },
        "author": 37583,
        "featured_media": 1022622,
        "comment_status": "closed",
        "ping_status": "closed",
        "sticky": false,
        "template": "",
        "format": "standard",
        "meta": {
            "msr-url-field": "",
            "msr-podcast-episode": "",
            "msrModifiedDate": "",
            "msrModifiedDateEnabled": false,
            "ep_exclude_from_search": false,
            "footnotes": ""
        },
        "categories": [
            1
        ],
        "tags": [],
        "research-area": [
            13563,
            13560
        ],
        "msr-region": [],
        "msr-event-type": [],
        "msr-post-option": [
            243984
        ],
        "msr-impact-theme": [],
        "msr-promo-type": [],
        "msr-podcast-series": [],
        "msr_event_details": {
            "start": "",
            "end": "",
            "location": ""
        },
        "podcast_url": "",
        "podcast_episode": "",
        "msr_research_lab": [],
        "msr_impact_theme": [],
        "related-publications": [],
        "related-downloads": [],
        "related-videos": [],
        "related-academic-programs": [],
        "related-groups": [
            684024
        ],
        "related-projects": [],
        "related-events": [],
        "related-researchers": [
            {
                "type": "user_nicename",
                "value": "Anna Pavlenko",
                "user_id": 40009,
                "display_name": "Anna Pavlenko",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/annapa/\" aria-label=\"Visit the profile page for Anna Pavlenko\">Anna Pavlenko</a>",
                "is_active": false,
                "last_first": "Pavlenko, Anna",
                "people_section": 0,
                "alias": "annapa"
            },
            {
                "type": "user_nicename",
                "value": "Karla Saur",
                "user_id": 39991,
                "display_name": "Karla Saur",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/kasaur/\" aria-label=\"Visit the profile page for Karla Saur\">Karla Saur</a>",
                "is_active": false,
                "last_first": "Saur, Karla",
                "people_section": 0,
                "alias": "kasaur"
            },
            {
                "type": "user_nicename",
                "value": "Yiwen Zhu",
                "user_id": 39438,
                "display_name": "Yiwen Zhu",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/yiwzh/\" aria-label=\"Visit the profile page for Yiwen Zhu\">Yiwen Zhu</a>",
                "is_active": false,
                "last_first": "Zhu, Yiwen",
                "people_section": 0,
                "alias": "yiwzh"
            },
            {
                "type": "user_nicename",
                "value": "Brian Kroth",
                "user_id": 40024,
                "display_name": "Brian Kroth",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/bpkroth/\" aria-label=\"Visit the profile page for Brian Kroth\">Brian Kroth</a>",
                "is_active": false,
                "last_first": "Kroth, Brian",
                "people_section": 0,
                "alias": "bpkroth"
            },
            {
                "type": "user_nicename",
                "value": "Joyce Cahoon",
                "user_id": 40012,
                "display_name": "Joyce Cahoon",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/jcahoon/\" aria-label=\"Visit the profile page for Joyce Cahoon\">Joyce Cahoon</a>",
                "is_active": false,
                "last_first": "Cahoon, Joyce",
                "people_section": 0,
                "alias": "jcahoon"
            },
            {
                "type": "user_nicename",
                "value": "Jesús Camacho Rodríguez",
                "user_id": 40693,
                "display_name": "Jesús Camacho Rodríguez",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/jesusca/\" aria-label=\"Visit the profile page for Jesús Camacho Rodríguez\">Jesús Camacho Rodríguez</a>",
                "is_active": false,
                "last_first": "Camacho Rodríguez, Jesús",
                "people_section": 0,
                "alias": "jesusca"
            }
        ],
        "msr_type": "Post",
        "featured_image_thumbnail": "<img width=\"960\" height=\"540\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM-BlogHeroFeature-1400x788-1-960x540.jpg\" class=\"img-object-cover\" alt=\"ICDE logo in white to the left of the first page of the &quot;VASIM: Vertical Autoscaling Simulator Toolkit&quot; accepted paper.\" decoding=\"async\" loading=\"lazy\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/VASIM-BlogHeroFeature-1400x788-1.jpg 1400w\" sizes=\"(max-width: 960px) 100vw, 960px\" />",
        "byline": "",
        "formattedDate": "May 13, 2024",
        "formattedExcerpt": "Autoscaling can optimize cloud resource usage and costs by adjusting to demand. VASIM shows that simplifying testing and refinement of autoscaling algorithms can enable rapid development and evaluation of more efficient &amp; cost-effective autoscaling strategies.",
        "_links": {
            "self": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1022580"
                }
            ],
            "collection": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts"
                }
            ],
            "about": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/types/post"
                }
            ],
            "author": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/users/37583"
                }
            ],
            "replies": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/comments?post=1022580"
                }
            ],
            "version-history": [
                {
                    "count": 29,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1022580/revisions"
                }
            ],
            "predecessor-version": [
                {
                    "id": 1031517,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1022580/revisions/1031517"
                }
            ],
            "wp:featuredmedia": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/media/1022622"
                }
            ],
            "wp:attachment": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/media?parent=1022580"
                }
            ],
            "wp:term": [
                {
                    "taxonomy": "category",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/categories?post=1022580"
                },
                {
                    "taxonomy": "post_tag",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/tags?post=1022580"
                },
                {
                    "taxonomy": "msr-research-area",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/research-area?post=1022580"
                },
                {
                    "taxonomy": "msr-region",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-region?post=1022580"
                },
                {
                    "taxonomy": "msr-event-type",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-event-type?post=1022580"
                },
                {
                    "taxonomy": "msr-post-option",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-post-option?post=1022580"
                },
                {
                    "taxonomy": "msr-impact-theme",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-impact-theme?post=1022580"
                },
                {
                    "taxonomy": "msr-promo-type",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-promo-type?post=1022580"
                },
                {
                    "taxonomy": "msr-podcast-series",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-podcast-series?post=1022580"
                }
            ],
            "curies": [
                {
                    "name": "wp",
                    "href": "https://api.w.org/{rel}",
                    "templated": true
                }
            ]
        }
    },
    {
        "id": 1030206,
        "date": "2024-05-08T09:00:00",
        "date_gmt": "2024-05-08T16:00:00",
        "guid": {
            "rendered": "https://www.microsoft.com/en-us/research/?p=1030206"
        },
        "modified": "2024-05-08T10:52:37",
        "modified_gmt": "2024-05-08T17:52:37",
        "slug": "llm-profiling-guides-kv-cache-optimization",
        "status": "publish",
        "type": "post",
        "link": "https://www.microsoft.com/en-us/research/blog/llm-profiling-guides-kv-cache-optimization/",
        "title": {
            "rendered": "LLM profiling guides KV cache optimization"
        },
        "content": {
            "rendered": "\n<p class=\"has-text-align-center\"><strong><em>This research paper was presented at the </em></strong><a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://iclr.cc/\" target=\"_blank\" rel=\"noreferrer noopener\"><strong><em>12<sup>th</sup> International Conference on Learning Representations</em></strong><span class=\"sr-only\"> (opens in new tab)</span></a><strong><em> (ICLR 2024), the premier conference dedicated to the advancement of deep learning.</em></strong></p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1401\" height=\"788\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ModelDiscard-BlogHeroFeature-1400x788-1.png\" alt=\"White ICLR logo to the left of the first page of the accepted paper, “Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs” on a purple background.\" class=\"wp-image-1030227\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ModelDiscard-BlogHeroFeature-1400x788-1.png 1401w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ModelDiscard-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ModelDiscard-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ModelDiscard-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ModelDiscard-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ModelDiscard-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ModelDiscard-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ModelDiscard-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ModelDiscard-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ModelDiscard-BlogHeroFeature-1400x788-1-1280x720.png 1280w\" sizes=\"(max-width: 1401px) 100vw, 1401px\" /></figure>\n\n\n\n<p>Large language models (LLMs) rely on complex internal mechanisms that require more memory than what is typically available to operate on standard devices. One such mechanism is the key-value (KV) cache, which stores and retrieves previously computed data, helping the model generate responses quickly without needing to recalculate information it has already processed. This method uses a substantial amount of memory because it keeps a large amount of this data readily accessible to enhance the model&#8217;s speed and efficiency. Consequently, the KV cache can become prohibitively large as the complexity of the tasks increases, sometimes requiring up to 320 GB for a single operation. To address this, we developed FastGen, a novel method aimed at reducing the memory demands for LLMs.</p>\n\n\n\n<div class=\"annotations \" data-bi-aN=\"margin-callout\">\n\t<ul class=\"annotations__list card depth-16 bg-body p-4 annotations__list--right\">\n\t\t<li class=\"annotations__list-item\">\n\t\t\t\t\t\t<span class=\"annotations__type d-block text-uppercase font-weight-semibold text-neutral-300 small\">Publication</span>\n\t\t\t<a href=\"https://www.microsoft.com/en-us/research/publication/model-tells-you-what-to-discard-adaptive-kv-cache-compression-for-llms/\" target=\"_self\" class=\"annotations__link font-weight-semibold text-decoration-none\" data-bi-type=\"annotated-link\" aria-label=\"Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs\" data-bi-aN=\"margin-callout\" data-bi-cN=\"Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs\">\n\t\t\t\tModel Tells You What to Discard: Adaptive KV Cache Compression for LLMs&nbsp;<span class=\"glyph-append glyph-append-chevron-right glyph-append-xsmall\"></span>\n\t\t\t</a>\n\t\t\t\t\t</li>\n\t</ul>\n</div>\n\n\n\n<p>Our paper, “<a href=\"https://www.microsoft.com/en-us/research/publication/model-tells-you-what-to-discard-adaptive-kv-cache-compression-for-llms/\" target=\"_blank\" rel=\"noreferrer noopener\">Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs<span class=\"sr-only\"> (opens in new tab)</span></a>,” presented at ICLR 2024, we describe how FastGen optimizes the way LLMs store and access data, potentially cutting memory use by half while preserving their efficiency. This approach represents a significant step toward making sophisticated AI tools more accessible and affordable for broader applications. We are delighted to share that this paper has been given an Honorable Mention for the <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://blog.iclr.cc/2024/05/06/iclr-2024-outstanding-paper-awards/\" target=\"_blank\" rel=\"noreferrer noopener\">Outstanding Paper Award<span class=\"sr-only\"> (opens in new tab)</span></a>.</p>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"observations-of-the-kv-cache\">Observations of the KV cache</h2>\n\n\n\n<p>The development of FastGen is underpinned by our observations of how the KV cache functions. We first observed that not all the data in the KV cache is needed for LLMs to complete their required tasks, as shown in Figure 1. By providing the KV cache with the mechanism to discard unnecessary data, it is possible to significantly cut memory use. For example, some LLM modules don’t require broad contexts to process input. For this, it is possible to construct a KV cache that removes data that contains less important long-range contexts, such as several sentences or paragraphs. Also, some LLM modules primarily attend only to special tokens, such as punctuation, for which it is possible to create a KV cache that retains only those tokens. Finally, some LLM modules broadly need all tokens, and for these we can employ the standard KV cache and store all words.&nbsp;&nbsp;</p>\n\n\n\n<p>Another key observation in our study is that attention modules in different layers and positions in the LLM behave differently and need different preferences for their KV cache, as shown on the right in Figure 1.&nbsp;</p>\n\n\n\n\t<div class=\"border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide\" data-bi-aN=\"promo\" data-bi-id=\"999693\">\n\t\t\n\n\t\t<p class=\"msr-promo__label text-gray-800 text-center text-uppercase\">\n\t\t<span class=\"px-4 bg-white display-inline-block font-weight-semibold small\">Spotlight: Event Series</span>\n\t</p>\n\t\n\t<div class=\"row pt-3 pb-4 align-items-center\">\n\t\t\t\t\t\t<div class=\"msr-promo__media col-12 col-md-5\">\n\t\t\t\t<a class=\"bg-gray-300\" href=\"https://researchforum.microsoft.com/?OCID=msr_researchforum_MCR_Blog_Promo\" aria-label=\"Microsoft Research Forum\" data-bi-cN=\"Microsoft Research Forum\" target=\"_blank\">\n\t\t\t\t\t<img decoding=\"async\" class=\"w-100 display-block\" src=\"https://www.microsoft.com/en-us/research/uploads/prod/2024/01/MRF-24_WebImage_1400x788.png\" alt=\"various abstract 3D shapes on a light blue background\" />\n\t\t\t\t</a>\n\t\t\t</div>\n\t\t\t\n\t\t\t<div class=\"msr-promo__content p-3 px-5 col-12 col-md\">\n\n\t\t\t\t\t\t\t\t\t<h2 class=\"h4\">Microsoft Research Forum</h2>\n\t\t\t\t\n\t\t\t\t\t\t\t\t<p class=\"large\">Join us for a continuous exchange of ideas about research in the era of general AI. Watch Episodes 1 & 2 on-demand.</p>\n\t\t\t\t\n\t\t\t\t\t\t\t\t<div class=\"wp-block-buttons justify-content-center justify-content-md-start\">\n\t\t\t\t\t<div class=\"wp-block-button\">\n\t\t\t\t\t\t<a href=\"https://researchforum.microsoft.com/?OCID=msr_researchforum_MCR_Blog_Promo\" class=\"btn btn-brand glyph-append glyph-append-chevron-right\" aria-label=\"Register for series\" data-bi-cN=\"Microsoft Research Forum\" target=\"_blank\">\n\t\t\t\t\t\t\tRegister for series\t\t\t\t\t\t</a>\n\t\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t\t\t\t</div><!--/.msr-promo__content-->\n\t</div><!--/.msr-promo__inner-wrap-->\n<span id=\"label-external-link\" class=\"sr-only\" aria-hidden=\"true\">Opens in a new tab</span>\t</div><!--/.msr-promo-->\n\t\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1401\" height=\"450\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICLR-Figure1-1400x-450-1.png\" alt=\"Graphs depicting the different structures of the KV cache. The graph on the left contains common structures. The circle graphs on the right contain compositions of three modules that are in the same layer, but the way they store data is different.\" class=\"wp-image-1030860\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICLR-Figure1-1400x-450-1.png 1401w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICLR-Figure1-1400x-450-1-300x96.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICLR-Figure1-1400x-450-1-1024x329.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICLR-Figure1-1400x-450-1-768x247.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ICLR-Figure1-1400x-450-1-240x77.png 240w\" sizes=\"(max-width: 1401px) 100vw, 1401px\" /><figcaption class=\"wp-element-caption\">Figure 1: These graphs depict the different structures of the KV cache. The graph on the left contains common structures. The circle graphs on the right contain compositions of three modules that are in the same layer, but the way they store data is different.</figcaption></figure>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"fastgen-accounts-for-the-diversity-of-kv-cache-structures\">FastGen accounts for the diversity of KV cache structures</h2>\n\n\n\n<p>Because different KV caches have different structures, they need to be handled differently. We based the development of the FastGen algorithm on our observations, enabling it to categorize and optimize the data that is stored in a given KV cache. FastGen first analyzes the specific behaviors of different modules to understand their structures, a method called <em>profiling</em>. It then uses the results to adjust how data is stored in real-time, making the process more efficient. Our tests show that FastGen can reduce the amount of memory by 50% without sacrificing quality. Additional experiments, discussed in detail in our <a href=\"https://www.microsoft.com/en-us/research/publication/model-tells-you-what-to-discard-adaptive-kv-cache-compression-for-llms/\" target=\"_blank\" rel=\"noreferrer noopener\">paper</a>, confirm that the profiling process is crucial and significantly improves the efficiency of the KV cache.&nbsp;&nbsp;</p>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"the-broader-picture\">The broader picture</h2>\n\n\n\n<p>Fueled by unprecedented advances in data handling and computational capabilities, LLM pretraining has emerged as a cornerstone of deep learning, transforming natural language processing tasks and continuously challenging our understanding of learning and cognition.</p>\n\n\n\n<p>However, greater capabilities can bring challenges. As models scale larger, customizing them for specific tasks can become more resource-intensive. At Microsoft Research, we are exploring different approaches to more efficient model editing. A critical strategy involves targeted model profiling, which identifies essential components of a model that align with predefined goals. This profiling informs precise model modifications, optimizing resource use and effectiveness.</p>\n\n\n\n<p>The two research projects we are presenting at ICLR 2024 support these goals. Both adopt the profile-then-edit paradigm to address different problems. FastGen reduces memory consumption. Our related work, <a href=\"https://www.microsoft.com/en-us/research/publication/tell-your-model-where-to-attend-post-hoc-attention-steering-for-llms/\" target=\"_blank\" rel=\"noreferrer noopener\">Post-hoc Attention Steering for LLMs (PASTA)</a>, focuses on better controllability. These approaches are designed to be resource-efficient, as they do not require tuning or back propagation. Looking ahead, our goal is to further develop these techniques to improve the resource-efficiency of LLM applications, making them more accessible to a wider audience.&nbsp;&nbsp;</p>\n<span id=\"label-external-link\" class=\"sr-only\" aria-hidden=\"true\">Opens in a new tab</span>",
            "protected": false
        },
        "excerpt": {
            "rendered": "<p>LLMs rely on memory-intensive mechanisms like the key-value (KV) cache to store and quickly retrieve data. FastGen optimizes KV cache usage, reducing LLM memory demands by up to 50% while maintaining performance.</p>\n",
            "protected": false
        },
        "author": 37583,
        "featured_media": 1030227,
        "comment_status": "closed",
        "ping_status": "closed",
        "sticky": false,
        "template": "",
        "format": "standard",
        "meta": {
            "msr-url-field": "",
            "msr-podcast-episode": "",
            "msrModifiedDate": "",
            "msrModifiedDateEnabled": false,
            "ep_exclude_from_search": false,
            "footnotes": ""
        },
        "categories": [
            1
        ],
        "tags": [],
        "research-area": [
            13556
        ],
        "msr-region": [],
        "msr-event-type": [],
        "msr-post-option": [
            243984
        ],
        "msr-impact-theme": [],
        "msr-promo-type": [],
        "msr-podcast-series": [],
        "msr_event_details": {
            "start": "",
            "end": "",
            "location": ""
        },
        "podcast_url": "",
        "podcast_episode": "",
        "msr_research_lab": [],
        "msr_impact_theme": [],
        "related-publications": [],
        "related-downloads": [],
        "related-videos": [],
        "related-academic-programs": [],
        "related-groups": [],
        "related-projects": [],
        "related-events": [
            1014303
        ],
        "related-researchers": [
            {
                "type": "user_nicename",
                "value": "Liyuan Liu",
                "user_id": 43302,
                "display_name": "Liyuan Liu",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/lucliu/\" aria-label=\"Visit the profile page for Liyuan Liu\">Liyuan Liu</a>",
                "is_active": false,
                "last_first": "Liu, Liyuan",
                "people_section": 0,
                "alias": "lucliu"
            },
            {
                "type": "user_nicename",
                "value": "Jianfeng Gao",
                "user_id": 32246,
                "display_name": "Jianfeng Gao",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/jfgao/\" aria-label=\"Visit the profile page for Jianfeng Gao\">Jianfeng Gao</a>",
                "is_active": false,
                "last_first": "Gao, Jianfeng",
                "people_section": 0,
                "alias": "jfgao"
            }
        ],
        "msr_type": "Post",
        "featured_image_thumbnail": "<img width=\"960\" height=\"540\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ModelDiscard-BlogHeroFeature-1400x788-1-960x540.png\" class=\"img-object-cover\" alt=\"White ICLR logo to the left of the first page of the accepted paper, “Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs” on a purple background.\" decoding=\"async\" loading=\"lazy\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ModelDiscard-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ModelDiscard-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ModelDiscard-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ModelDiscard-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ModelDiscard-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ModelDiscard-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ModelDiscard-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ModelDiscard-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ModelDiscard-BlogHeroFeature-1400x788-1-1280x720.png 1280w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/05/ModelDiscard-BlogHeroFeature-1400x788-1.png 1401w\" sizes=\"(max-width: 960px) 100vw, 960px\" />",
        "byline": "<a href=\"https://www.microsoft.com/en-us/research/people/lucliu/\" title=\"Go to researcher profile for Liyuan Liu\" aria-label=\"Go to researcher profile for Liyuan Liu\" data-bi-type=\"byline author\" data-bi-cN=\"Liyuan Liu\">Liyuan Liu</a> and <a href=\"https://www.microsoft.com/en-us/research/people/jfgao/\" title=\"Go to researcher profile for Jianfeng Gao\" aria-label=\"Go to researcher profile for Jianfeng Gao\" data-bi-type=\"byline author\" data-bi-cN=\"Jianfeng Gao\">Jianfeng Gao</a>",
        "formattedDate": "May 8, 2024",
        "formattedExcerpt": "LLMs rely on memory-intensive mechanisms like the key-value (KV) cache to store and quickly retrieve data. FastGen optimizes KV cache usage, reducing LLM memory demands by up to 50% while maintaining performance.",
        "_links": {
            "self": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1030206"
                }
            ],
            "collection": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts"
                }
            ],
            "about": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/types/post"
                }
            ],
            "author": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/users/37583"
                }
            ],
            "replies": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/comments?post=1030206"
                }
            ],
            "version-history": [
                {
                    "count": 31,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1030206/revisions"
                }
            ],
            "predecessor-version": [
                {
                    "id": 1032420,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1030206/revisions/1032420"
                }
            ],
            "wp:featuredmedia": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/media/1030227"
                }
            ],
            "wp:attachment": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/media?parent=1030206"
                }
            ],
            "wp:term": [
                {
                    "taxonomy": "category",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/categories?post=1030206"
                },
                {
                    "taxonomy": "post_tag",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/tags?post=1030206"
                },
                {
                    "taxonomy": "msr-research-area",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/research-area?post=1030206"
                },
                {
                    "taxonomy": "msr-region",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-region?post=1030206"
                },
                {
                    "taxonomy": "msr-event-type",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-event-type?post=1030206"
                },
                {
                    "taxonomy": "msr-post-option",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-post-option?post=1030206"
                },
                {
                    "taxonomy": "msr-impact-theme",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-impact-theme?post=1030206"
                },
                {
                    "taxonomy": "msr-promo-type",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-promo-type?post=1030206"
                },
                {
                    "taxonomy": "msr-podcast-series",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-podcast-series?post=1030206"
                }
            ],
            "curies": [
                {
                    "name": "wp",
                    "href": "https://api.w.org/{rel}",
                    "templated": true
                }
            ]
        }
    },
    {
        "id": 1027098,
        "date": "2024-05-07T09:00:00",
        "date_gmt": "2024-05-07T16:00:00",
        "guid": {
            "rendered": "https://www.microsoft.com/en-us/research/blog/loftq-reimagining-llm-fine-tuning-with-smarter-initialization/"
        },
        "modified": "2024-05-01T07:52:24",
        "modified_gmt": "2024-05-01T14:52:24",
        "slug": "loftq-reimagining-llm-fine-tuning-with-smarter-initialization",
        "status": "publish",
        "type": "post",
        "link": "https://www.microsoft.com/en-us/research/blog/loftq-reimagining-llm-fine-tuning-with-smarter-initialization/",
        "title": {
            "rendered": "LoftQ: Reimagining LLM fine-tuning with smarter initialization"
        },
        "content": {
            "rendered": "\n<p class=\"has-text-align-center\"><strong><em>This research paper was presented at the </em></strong><a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://iclr.cc/Conferences/2024\" target=\"_blank\" rel=\"noreferrer noopener\"><strong><em>12<sup>th</sup> International Conference on Learning Representations</em></strong><span class=\"sr-only\"> (opens in new tab)</span></a><strong><em> (ICLR 2024), the premier conference dedicated to the advancement of deep learning.</em></strong></p>\n\n\n\n<figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1401\" height=\"788\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1.png\" alt=\"Teal background with ICLR logo on the right (head and face) with LoftQ paper on the right.\" class=\"wp-image-1027119\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1.png 1401w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-1280x720.png 1280w\" sizes=\"(max-width: 1401px) 100vw, 1401px\" /></figure>\n\n\n\n<div class=\"annotations \" data-bi-aN=\"margin-callout\">\n\t<ul class=\"annotations__list card depth-16 bg-body p-4 annotations__list--right\">\n\t\t<li class=\"annotations__list-item\">\n\t\t\t\t\t\t<span class=\"annotations__type d-block text-uppercase font-weight-semibold text-neutral-300 small\">Publication</span>\n\t\t\t<a href=\"https://www.microsoft.com/en-us/research/publication/loftq-lora-fine-tuning-aware-quantization-for-large-language-models/\" target=\"_self\" class=\"annotations__link font-weight-semibold text-decoration-none\" data-bi-type=\"annotated-link\" aria-label=\"LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models\" data-bi-aN=\"margin-callout\" data-bi-cN=\"LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models\">\n\t\t\t\tLoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models&nbsp;<span class=\"glyph-append glyph-append-chevron-right glyph-append-xsmall\"></span>\n\t\t\t</a>\n\t\t\t\t\t</li>\n\t</ul>\n</div>\n\n\n\n<p>Large language models (LLMs) use extensive datasets and advanced algorithms to generate nuanced, context-sensitive content. However, their development requires substantial computational resources. To address this, we developed LoftQ, an innovative technique that streamlines the fine-tuning process—which is used to adapt pre-trained language models to perform well in specialized applications, such as analyzing medical documents. During fine-tuning, the model undergoes additional training on a smaller, task-specific dataset. This results in improved performance, such as more accurate predictions, better understanding of domain-specific language, and more relevant responses in the context of the specialized area.</p>\n\n\n\n<p>LoftQ’s strength lies in its ability to combine quantization and adaptive initialization during fine-tuning. Quantization reduces the precision of model parameters, lowering memory and computation needs. This not only accelerates processing but also reduces power consumption. Adaptive initialization closely aligns the model’s parameters to its optimal pre-trained state, preserving its capabilities while minimizing resource use. Our paper, “<a href=\"https://www.microsoft.com/en-us/research/publication/loftq-lora-fine-tuning-aware-quantization-for-large-language-models/\" target=\"_blank\" rel=\"noreferrer noopener\">LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models</a>,” presented at ICLR 2024, details how this method can help make AI technologies more efficient and sustainable.&nbsp;</p>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"how-loftq-works\">How LoftQ works&nbsp;</h2>\n\n\n\n<p>LoftQ builds on the principles of <a href=\"https://www.microsoft.com/en-us/research/publication/lora-low-rank-adaptation-of-large-language-models/\" target=\"_blank\" rel=\"noreferrer noopener\">LoRA<span class=\"sr-only\"> (opens in new tab)</span></a> and <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://github.com/artidoro/qlora\" target=\"_blank\" rel=\"noreferrer noopener\">QLoRA<span class=\"sr-only\"> (opens in new tab)</span></a>. LoRA is a method that greatly reduces the number of parameters needed for training, decreasing the memory requirements for fine-tuning. QLoRA is a fine-tuning approach that uses 4-bit quantized, frozen weights and low rank adapters, significantly reducing memory requirements while maintaining high performance. This is illustrated in Table 1, which shows the amount of memory needed for fine-tuning an LLM with 7 billion parameters as well as the memory requirements for LoRA and QLoRA. LoRA achieves a fourfold reduction in memory usage, and QLoRA further reduces it by twofold.</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"3053\" height=\"1210\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/finetuning-1.png\" alt=\"LoftQ - Table 1: This table shows the GPU memory usage for a 7-billion parameter LLM, with the following configurations: full fine-tuning on the left, LoRA in the middle, and QLoRA on the right.\" class=\"wp-image-1029312\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/finetuning-1.png 3053w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/finetuning-1-300x119.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/finetuning-1-1024x406.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/finetuning-1-768x304.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/finetuning-1-1536x609.png 1536w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/finetuning-1-2048x812.png 2048w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/finetuning-1-240x95.png 240w\" sizes=\"(max-width: 3053px) 100vw, 3053px\" /><figcaption class=\"wp-element-caption\">Table 1: This table shows the GPU memory usage for a 7-billion parameter LLM with the following configurations: full fine-tuning on the left, LoRA in the middle, and QLoRA on the right.</figcaption></figure>\n\n\n\n<p>Unlike LoRA, QLoRA comes with a tradeoff, where some quality of the pretrained model is sacrificed due to the quantization of weights. LoftQ recognizes this and optimizes the initialization of quantization and low-rank adaptation matrices. That is, LoftQ seeks to identify a combination of a quantized matrix and a low rank matrix such that their sum closely approximates the original pretrained weight. This is done for every matrix that would be adapted in the model.</p>\n\n\n\n<p>The LoftQ algorithm alternates between two primary steps. First it quantizes (simplifies) the weights, and then it finds the best low-rank factors that approximate the quantization between the pretrained weight and the low-rank weight.&nbsp;The process repeats for a few steps. This method enables the fine-tuning process to start from a more effective initial state, which preserves accuracy while using less computational power and much more simplified weights.</p>\n\n\n\n<p>LoftQ requires a one-time setup to simplify and prepare these weights, allowing a fixed portion of the model’s parameters (e.g., 5 percent) to be adjusted. Once established, this configuration can be repeatedly applied as the model transitions between various tasks and settings. </p>\n\n\n\n<h2 class=\"wp-block-heading\" id=\"evaluating-loftq\">Evaluating LoftQ&nbsp;</h2>\n\n\n\n<p>Tests using various types of LLMs, including those with different combinations of encoding and decoding capabilities like the Llama-2, show that models initialized with LoftQ consistently achieve strong performance, often matching or surpassing those configured with QLoRA.</p>\n\n\n\n<p>In practical terms, comparing the performance of LoftQ and QLoRA on different tasks using the Llama-2 model family yields distinct results, which are highlighted in Table 2. For the WikiText-2 dataset, which measures the model’s perplexity (lower is better), and the GSM8K dataset, which tests the model’s ability to solve basic math problems (higher is better), we demonstrate the effectiveness of varying degrees of weight simplification—averaging 3, 2.5, and 2.25 bits per weight. Our <a href=\"https://www.microsoft.com/en-us/research/publication/loftq-lora-fine-tuning-aware-quantization-for-large-language-models/\" target=\"_blank\" rel=\"noreferrer noopener\">paper</a> discusses the results in more detail.&nbsp;</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"1605\" height=\"1196\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ_llama2_table2.png\" alt=\"LoftQ - Table 2. This table compares LoftQ and QLoRA during the fine-tuning of two Llama-2 models on the Wikitext-2 and GSM8K datasets.\" class=\"wp-image-1027116\" style=\"width:731px;height:auto\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ_llama2_table2.png 1605w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ_llama2_table2-300x224.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ_llama2_table2-1024x763.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ_llama2_table2-768x572.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ_llama2_table2-1536x1145.png 1536w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ_llama2_table2-80x60.png 80w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ_llama2_table2-240x180.png 240w\" sizes=\"(max-width: 1605px) 100vw, 1605px\" /><figcaption class=\"wp-element-caption\">Table 2. This table compares LoftQ and QLoRA during the fine-tuning of two Llama-2 models on the Wikitext-2 and GSM8K datasets.</figcaption></figure>\n\n\n\n\t<div class=\"border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide\" data-bi-aN=\"promo\" data-bi-id=\"999693\">\n\t\t\n\n\t\t<p class=\"msr-promo__label text-gray-800 text-center text-uppercase\">\n\t\t<span class=\"px-4 bg-white display-inline-block font-weight-semibold small\">Spotlight: Event Series</span>\n\t</p>\n\t\n\t<div class=\"row pt-3 pb-4 align-items-center\">\n\t\t\t\t\t\t<div class=\"msr-promo__media col-12 col-md-5\">\n\t\t\t\t<a class=\"bg-gray-300\" href=\"https://researchforum.microsoft.com/?OCID=msr_researchforum_MCR_Blog_Promo\" aria-label=\"Microsoft Research Forum\" data-bi-cN=\"Microsoft Research Forum\" target=\"_blank\">\n\t\t\t\t\t<img decoding=\"async\" class=\"w-100 display-block\" src=\"https://www.microsoft.com/en-us/research/uploads/prod/2024/01/MRF-24_WebImage_1400x788.png\" alt=\"various abstract 3D shapes on a light blue background\" />\n\t\t\t\t</a>\n\t\t\t</div>\n\t\t\t\n\t\t\t<div class=\"msr-promo__content p-3 px-5 col-12 col-md\">\n\n\t\t\t\t\t\t\t\t\t<h2 class=\"h4\">Microsoft Research Forum</h2>\n\t\t\t\t\n\t\t\t\t\t\t\t\t<p class=\"large\">Join us for a continuous exchange of ideas about research in the era of general AI. Watch Episodes 1 & 2 on-demand.</p>\n\t\t\t\t\n\t\t\t\t\t\t\t\t<div class=\"wp-block-buttons justify-content-center justify-content-md-start\">\n\t\t\t\t\t<div class=\"wp-block-button\">\n\t\t\t\t\t\t<a href=\"https://researchforum.microsoft.com/?OCID=msr_researchforum_MCR_Blog_Promo\" class=\"btn btn-brand glyph-append glyph-append-chevron-right\" aria-label=\"Register for series\" data-bi-cN=\"Microsoft Research Forum\" target=\"_blank\">\n\t\t\t\t\t\t\tRegister for series\t\t\t\t\t\t</a>\n\t\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t\t\t\t</div><!--/.msr-promo__content-->\n\t</div><!--/.msr-promo__inner-wrap-->\n<span id=\"label-external-link\" class=\"sr-only\" aria-hidden=\"true\">Opens in a new tab</span>\t</div><!--/.msr-promo-->\n\t\n\n\n<h2 class=\"wp-block-heading\" id=\"implications-and-looking-forward\">Implications and looking forward&nbsp;</h2>\n\n\n\n<p>LoftQ promises to advance the field of AI by accelerating research and facilitating the creation of cutting-edge tools while supporting sustainable development. While initially focused on LLMs, LoftQ’s flexible design also supports fine-tuning in other types of models, such those for vision and speech technologies. As our research progresses, we expect to make further enhancements that will boost performance on downstream tasks. We hope these improvements will lead to broader adoption across various AI applications. We’re excited about the breadth of this technology’s applicability and encourage the AI community to explore its benefits. LoftQ is available as open source through the <a class=\"msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall\" href=\"https://github.com/huggingface/peft/blob/56773b9a92b141111d65fe3548d0c30233358868/examples/loftq_finetuning/README.md\" target=\"_blank\" rel=\"noreferrer noopener\">Hugging Face PEFT library<span class=\"sr-only\"> (opens in new tab)</span></a>.</p>\n<span id=\"label-external-link\" class=\"sr-only\" aria-hidden=\"true\">Opens in a new tab</span>",
            "protected": false
        },
        "excerpt": {
            "rendered": "<p>LoftQ boosts LLM efficiency by streamlining the fine-tuning process, reducing computational demands while preserving high performance. Innovations like this can help make AI technology more energy-efficient.</p>\n",
            "protected": false
        },
        "author": 42735,
        "featured_media": 1027119,
        "comment_status": "closed",
        "ping_status": "closed",
        "sticky": false,
        "template": "",
        "format": "standard",
        "meta": {
            "msr-url-field": "",
            "msr-podcast-episode": "",
            "msrModifiedDate": "",
            "msrModifiedDateEnabled": false,
            "ep_exclude_from_search": false,
            "footnotes": ""
        },
        "categories": [
            1
        ],
        "tags": [],
        "research-area": [
            13556
        ],
        "msr-region": [],
        "msr-event-type": [],
        "msr-post-option": [
            243984
        ],
        "msr-impact-theme": [],
        "msr-promo-type": [],
        "msr-podcast-series": [],
        "msr_event_details": {
            "start": "",
            "end": "",
            "location": ""
        },
        "podcast_url": "",
        "podcast_episode": "",
        "msr_research_lab": [],
        "msr_impact_theme": [],
        "related-publications": [],
        "related-downloads": [],
        "related-videos": [],
        "related-academic-programs": [],
        "related-groups": [],
        "related-projects": [],
        "related-events": [
            1014303
        ],
        "related-researchers": [
            {
                "type": "user_nicename",
                "value": "Nikos Karampatziakis",
                "user_id": 33104,
                "display_name": "Nikos Karampatziakis",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/nikosk/\" aria-label=\"Visit the profile page for Nikos Karampatziakis\">Nikos Karampatziakis</a>",
                "is_active": false,
                "last_first": "Karampatziakis, Nikos",
                "people_section": 0,
                "alias": "nikosk"
            },
            {
                "type": "user_nicename",
                "value": "Chen Liang",
                "user_id": 43239,
                "display_name": "Chen Liang",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/chenliang1/\" aria-label=\"Visit the profile page for Chen Liang\">Chen Liang</a>",
                "is_active": false,
                "last_first": "Liang, Chen",
                "people_section": 0,
                "alias": "chenliang1"
            },
            {
                "type": "user_nicename",
                "value": "Weizhu Chen",
                "user_id": 34863,
                "display_name": "Weizhu Chen",
                "author_link": "<a href=\"https://www.microsoft.com/en-us/research/people/wzchen/\" aria-label=\"Visit the profile page for Weizhu Chen\">Weizhu Chen</a>",
                "is_active": false,
                "last_first": "Chen, Weizhu",
                "people_section": 0,
                "alias": "wzchen"
            },
            {
                "type": "guest",
                "value": "yixiao-li",
                "user_id": "1027107",
                "display_name": "Yixiao Li",
                "author_link": "<a href=\"https://yxli2123.github.io/\" aria-label=\"Visit the profile page for Yixiao Li\">Yixiao Li</a>",
                "is_active": true,
                "last_first": "Li, Yixiao",
                "people_section": 0,
                "alias": "yixiao-li"
            },
            {
                "type": "guest",
                "value": "yifan-yu-2",
                "user_id": "1027137",
                "display_name": "Yifan Yu",
                "author_link": "<a href=\"https://www.linkedin.com/in/yifan-yu-0495011b4/\" aria-label=\"Visit the profile page for Yifan Yu\">Yifan Yu</a>",
                "is_active": true,
                "last_first": "Yu, Yifan",
                "people_section": 0,
                "alias": "yifan-yu-2"
            },
            {
                "type": "guest",
                "value": "tuo-zhao",
                "user_id": "782632",
                "display_name": "Tuo Zhao",
                "author_link": "<a href=\"https://www2.isye.gatech.edu/~tzhao80/\" aria-label=\"Visit the profile page for Tuo Zhao\">Tuo Zhao</a>",
                "is_active": true,
                "last_first": "Zhao, Tuo",
                "people_section": 0,
                "alias": "tuo-zhao"
            }
        ],
        "msr_type": "Post",
        "featured_image_thumbnail": "<img width=\"960\" height=\"540\" src=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-960x540.png\" class=\"img-object-cover\" alt=\"LoftQ paper at ICLR 2024\" decoding=\"async\" loading=\"lazy\" srcset=\"https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1-1280x720.png 1280w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/04/LoftQ-BlogHeroFeature-1400x788-1.png 1401w\" sizes=\"(max-width: 960px) 100vw, 960px\" />",
        "byline": "",
        "formattedDate": "May 7, 2024",
        "formattedExcerpt": "LoftQ boosts LLM efficiency by streamlining the fine-tuning process, reducing computational demands while preserving high performance. Innovations like this can help make AI technology more energy-efficient.",
        "_links": {
            "self": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1027098"
                }
            ],
            "collection": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts"
                }
            ],
            "about": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/types/post"
                }
            ],
            "author": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/users/42735"
                }
            ],
            "replies": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/comments?post=1027098"
                }
            ],
            "version-history": [
                {
                    "count": 38,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1027098/revisions"
                }
            ],
            "predecessor-version": [
                {
                    "id": 1029315,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/posts/1027098/revisions/1029315"
                }
            ],
            "wp:featuredmedia": [
                {
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/media/1027119"
                }
            ],
            "wp:attachment": [
                {
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/media?parent=1027098"
                }
            ],
            "wp:term": [
                {
                    "taxonomy": "category",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/categories?post=1027098"
                },
                {
                    "taxonomy": "post_tag",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/tags?post=1027098"
                },
                {
                    "taxonomy": "msr-research-area",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/research-area?post=1027098"
                },
                {
                    "taxonomy": "msr-region",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-region?post=1027098"
                },
                {
                    "taxonomy": "msr-event-type",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-event-type?post=1027098"
                },
                {
                    "taxonomy": "msr-post-option",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-post-option?post=1027098"
                },
                {
                    "taxonomy": "msr-impact-theme",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-impact-theme?post=1027098"
                },
                {
                    "taxonomy": "msr-promo-type",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-promo-type?post=1027098"
                },
                {
                    "taxonomy": "msr-podcast-series",
                    "embeddable": true,
                    "href": "https://www.microsoft.com/en-us/research/wp-json/wp/v2/msr-podcast-series?post=1027098"
                }
            ],
            "curies": [
                {
                    "name": "wp",
                    "href": "https://api.w.org/{rel}",
                    "templated": true
                }
            ]
        }
    }
]