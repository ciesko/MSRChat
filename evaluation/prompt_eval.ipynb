{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fm27HLB7UYJC"
      },
      "outputs": [],
      "source": [
        "from functions import *\n",
        "import pandas as pd\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1125
        },
        "id": "7O_FUGKBWyfk",
        "outputId": "eae6289d-c44e-4f7e-ceca-07c7f14ed657"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./prompt_library.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m,sheet_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorized\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "file_path = os.environ.get(\"FILE_PATH\", \"./prompt_library.xlsx\")\n",
        "sheet_name = os.environ.get(\"SHEET_NAME\", \"categorized\")\n",
        "dataset = pd.read_excel(file_path,sheet_name=sheet_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rPg6Qr7LYPoU",
        "outputId": "e5641710-1bcc-438d-f9fb-723795336de1"
      },
      "outputs": [],
      "source": [
        "limit = 5 #no. of questions to prompt\n",
        "dataset.head(limit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "h506yP1Qn000"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question 0 processed succesfully\n",
            "Question 1 processed succesfully\n",
            "Question 2 processed succesfully\n",
            "Question 3 processed succesfully\n",
            "Question 4 processed succesfully\n"
          ]
        }
      ],
      "source": [
        "# Process each row and store the results in a new DataFrame\n",
        "results = []\n",
        "for index, row in dataset.iterrows():\n",
        "    try:\n",
        "        if index >= limit:\n",
        "            break\n",
        "        prompt = row[\"Prompt\"]\n",
        "        answer, response_time = process_prompt(prompt)\n",
        "\n",
        "        accuracy = evaluate_response(prompt, answer, EvaluationType.ACCURACY)\n",
        "        relevance = evaluate_response(prompt, answer, EvaluationType.RELEVANCE)\n",
        "        results.append((prompt,answer,response_time,accuracy,relevance))\n",
        "\n",
        "        print(f\"Question {index} processed succesfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error Question {index} processed unsuccesfully: {e}\")\n",
        "        continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UqBPzWy_Geck"
      },
      "outputs": [],
      "source": [
        "# Create a new DataFrame from the results\n",
        "output_dataset = pd.DataFrame(results, columns=['Question', 'Answer', 'Response Time (s)', 'Accuracy','Relevance'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7ztF3XQEG5a9"
      },
      "outputs": [],
      "source": [
        "# Write the new DataFrame to a new Excel file\n",
        "output_file_path = 'output_data.xlsx'\n",
        "output_dataset.to_excel(output_file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1338
        },
        "id": "hy0-BN3tHTuT",
        "outputId": "f43dada1-8eb3-46eb-823f-d2809799d6b8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>Response Time (s)</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Can you identify the main AI and machine learn...</td>\n",
              "      <td>The documents provided highlight several AI an...</td>\n",
              "      <td>86.714674</td>\n",
              "      <td>I would rate the output a 4.\\n\\nThe response i...</td>\n",
              "      <td>I would rate the output a 4.\\n\\nThe response i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How did Microsoft researchers address issues o...</td>\n",
              "      <td>Microsoft researchers addressed issues of bias...</td>\n",
              "      <td>84.063624</td>\n",
              "      <td>The response provided is accurate in summarizi...</td>\n",
              "      <td>I would rate the response a 4.\\n\\nThe response...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How did Microsoft's research at NeurIPS 2023 c...</td>\n",
              "      <td>Microsoft's research at NeurIPS 2023 contribut...</td>\n",
              "      <td>61.018703</td>\n",
              "      <td>I would rate the output a 4.\\n\\nThe response i...</td>\n",
              "      <td>I would rate the relevance of the output as a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How do Microsoft's papers at NeurIPS contribut...</td>\n",
              "      <td>The requested information is not available in ...</td>\n",
              "      <td>18.117342</td>\n",
              "      <td>The output is accurate. The user's question is...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How do Microsoft's NeurIPS 2023 submissions ad...</td>\n",
              "      <td>Microsoft's submissions to NeurIPS 2023 showca...</td>\n",
              "      <td>72.670112</td>\n",
              "      <td>I would rate the output a 4.\\n\\nThe response i...</td>\n",
              "      <td>I would rate the relevance of the output to th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Question  \\\n",
              "0  Can you identify the main AI and machine learn...   \n",
              "1  How did Microsoft researchers address issues o...   \n",
              "2  How did Microsoft's research at NeurIPS 2023 c...   \n",
              "3  How do Microsoft's papers at NeurIPS contribut...   \n",
              "4  How do Microsoft's NeurIPS 2023 submissions ad...   \n",
              "\n",
              "                                              Answer  Response Time (s)  \\\n",
              "0  The documents provided highlight several AI an...          86.714674   \n",
              "1  Microsoft researchers addressed issues of bias...          84.063624   \n",
              "2  Microsoft's research at NeurIPS 2023 contribut...          61.018703   \n",
              "3  The requested information is not available in ...          18.117342   \n",
              "4  Microsoft's submissions to NeurIPS 2023 showca...          72.670112   \n",
              "\n",
              "                                            Accuracy  \\\n",
              "0  I would rate the output a 4.\\n\\nThe response i...   \n",
              "1  The response provided is accurate in summarizi...   \n",
              "2  I would rate the output a 4.\\n\\nThe response i...   \n",
              "3  The output is accurate. The user's question is...   \n",
              "4  I would rate the output a 4.\\n\\nThe response i...   \n",
              "\n",
              "                                           Relevance  \n",
              "0  I would rate the output a 4.\\n\\nThe response i...  \n",
              "1  I would rate the response a 4.\\n\\nThe response...  \n",
              "2  I would rate the relevance of the output as a ...  \n",
              "3                                                  1  \n",
              "4  I would rate the relevance of the output to th...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6gvobzrHKnm",
        "outputId": "f5c83923-4302-4902-a1ed-57b4f7f90866"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing complete. Results saved to output_data.xlsx\n"
          ]
        }
      ],
      "source": [
        "print(f\"Processing complete. Results saved to {output_file_path}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
